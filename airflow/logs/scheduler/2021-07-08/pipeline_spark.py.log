[2021-07-08 15:42:55,848] {scheduler_job.py:182} INFO - Started process (PID=9668) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:42:55,850] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:42:55,851] {logging_mixin.py:104} INFO - [2021-07-08 15:42:55,851] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:42:56,015] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:42:59,129] {logging_mixin.py:104} INFO - [2021-07-08 15:42:59,128] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:42:59,141] {logging_mixin.py:104} INFO - [2021-07-08 15:42:59,140] {dag.py:1852} INFO - Creating ORM DAG for Pipeline_Spark_Orchestrator
[2021-07-08 15:42:59,145] {logging_mixin.py:104} INFO - [2021-07-08 15:42:59,145] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:42:59,157] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 3.318 seconds
[2021-07-08 15:43:15,083] {scheduler_job.py:182} INFO - Started process (PID=9716) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:15,084] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:43:15,085] {logging_mixin.py:104} INFO - [2021-07-08 15:43:15,085] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:15,211] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:15,216] {logging_mixin.py:104} INFO - [2021-07-08 15:43:15,216] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:43:15,228] {logging_mixin.py:104} INFO - [2021-07-08 15:43:15,228] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:43:15,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 15:43:45,351] {scheduler_job.py:182} INFO - Started process (PID=9770) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:45,352] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:43:45,352] {logging_mixin.py:104} INFO - [2021-07-08 15:43:45,352] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:45,445] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:45,454] {logging_mixin.py:104} INFO - [2021-07-08 15:43:45,454] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:43:45,462] {logging_mixin.py:104} INFO - [2021-07-08 15:43:45,462] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:43:45,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 15:43:49,492] {scheduler_job.py:182} INFO - Started process (PID=9781) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:49,492] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:43:49,493] {logging_mixin.py:104} INFO - [2021-07-08 15:43:49,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:49,586] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:43:49,594] {logging_mixin.py:104} INFO - [2021-07-08 15:43:49,594] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:43:49,604] {logging_mixin.py:104} INFO - [2021-07-08 15:43:49,604] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:43:49,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 15:44:04,256] {scheduler_job.py:182} INFO - Started process (PID=9824) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:04,257] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:44:04,257] {logging_mixin.py:104} INFO - [2021-07-08 15:44:04,257] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:04,350] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:04,502] {logging_mixin.py:104} INFO - [2021-07-08 15:44:04,502] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:44:04,511] {logging_mixin.py:104} INFO - [2021-07-08 15:44:04,511] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:44:04,521] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.267 seconds
[2021-07-08 15:44:12,297] {scheduler_job.py:182} INFO - Started process (PID=9825) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:12,300] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:44:12,301] {logging_mixin.py:104} INFO - [2021-07-08 15:44:12,301] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:12,400] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:12,403] {logging_mixin.py:104} INFO - [2021-07-08 15:44:12,403] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:44:12,414] {logging_mixin.py:104} INFO - [2021-07-08 15:44:12,414] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:44:12,425] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 15:44:43,051] {scheduler_job.py:182} INFO - Started process (PID=9888) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:43,052] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:44:43,054] {logging_mixin.py:104} INFO - [2021-07-08 15:44:43,054] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:43,149] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:44:43,157] {logging_mixin.py:104} INFO - [2021-07-08 15:44:43,157] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:44:43,167] {logging_mixin.py:104} INFO - [2021-07-08 15:44:43,167] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-06 00:00:00+00:00
[2021-07-08 15:44:43,174] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 15:45:13,676] {scheduler_job.py:182} INFO - Started process (PID=9951) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:13,677] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:45:13,678] {logging_mixin.py:104} INFO - [2021-07-08 15:45:13,678] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:13,769] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:13,776] {logging_mixin.py:104} INFO - [2021-07-08 15:45:13,776] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:45:13,785] {logging_mixin.py:104} INFO - [2021-07-08 15:45:13,785] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:45:13,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 15:45:44,673] {scheduler_job.py:182} INFO - Started process (PID=10014) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:44,674] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:45:44,674] {logging_mixin.py:104} INFO - [2021-07-08 15:45:44,674] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:44,776] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:45:44,786] {logging_mixin.py:104} INFO - [2021-07-08 15:45:44,786] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:45:44,797] {logging_mixin.py:104} INFO - [2021-07-08 15:45:44,797] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:45:44,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 15:46:15,049] {scheduler_job.py:182} INFO - Started process (PID=10068) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:15,051] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:46:15,052] {logging_mixin.py:104} INFO - [2021-07-08 15:46:15,052] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:15,145] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:15,153] {logging_mixin.py:104} INFO - [2021-07-08 15:46:15,153] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:46:15,161] {logging_mixin.py:104} INFO - [2021-07-08 15:46:15,161] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:46:15,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 15:46:45,505] {scheduler_job.py:182} INFO - Started process (PID=10131) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:45,506] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:46:45,507] {logging_mixin.py:104} INFO - [2021-07-08 15:46:45,507] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:45,617] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:46:45,628] {logging_mixin.py:104} INFO - [2021-07-08 15:46:45,628] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:46:45,638] {logging_mixin.py:104} INFO - [2021-07-08 15:46:45,638] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:46:45,647] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 15:47:04,411] {scheduler_job.py:182} INFO - Started process (PID=10169) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:04,412] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:47:04,413] {logging_mixin.py:104} INFO - [2021-07-08 15:47:04,412] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:04,505] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:04,513] {logging_mixin.py:104} INFO - [2021-07-08 15:47:04,513] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:47:04,524] {logging_mixin.py:104} INFO - [2021-07-08 15:47:04,524] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:47:04,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 15:47:34,949] {scheduler_job.py:182} INFO - Started process (PID=10225) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:34,950] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:47:34,950] {logging_mixin.py:104} INFO - [2021-07-08 15:47:34,950] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:35,057] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:47:35,068] {logging_mixin.py:104} INFO - [2021-07-08 15:47:35,067] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:47:35,081] {logging_mixin.py:104} INFO - [2021-07-08 15:47:35,081] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:47:35,092] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 15:48:05,451] {scheduler_job.py:182} INFO - Started process (PID=10289) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:05,453] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:48:05,454] {logging_mixin.py:104} INFO - [2021-07-08 15:48:05,454] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:05,561] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:05,569] {logging_mixin.py:104} INFO - [2021-07-08 15:48:05,569] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:48:05,581] {logging_mixin.py:104} INFO - [2021-07-08 15:48:05,581] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:48:05,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 15:48:14,284] {scheduler_job.py:182} INFO - Started process (PID=10314) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:14,285] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:48:14,286] {logging_mixin.py:104} INFO - [2021-07-08 15:48:14,286] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:14,401] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:14,412] {logging_mixin.py:104} INFO - [2021-07-08 15:48:14,412] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:48:14,426] {logging_mixin.py:104} INFO - [2021-07-08 15:48:14,426] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:48:14,439] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.157 seconds
[2021-07-08 15:48:45,108] {scheduler_job.py:182} INFO - Started process (PID=10368) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:45,110] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:48:45,111] {logging_mixin.py:104} INFO - [2021-07-08 15:48:45,111] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:45,201] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:48:45,209] {logging_mixin.py:104} INFO - [2021-07-08 15:48:45,209] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:48:45,219] {logging_mixin.py:104} INFO - [2021-07-08 15:48:45,218] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:48:45,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 15:49:15,519] {scheduler_job.py:182} INFO - Started process (PID=10432) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:15,520] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:49:15,522] {logging_mixin.py:104} INFO - [2021-07-08 15:49:15,521] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:15,617] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:15,627] {logging_mixin.py:104} INFO - [2021-07-08 15:49:15,627] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:49:15,642] {logging_mixin.py:104} INFO - [2021-07-08 15:49:15,642] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:49:15,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 15:49:19,673] {scheduler_job.py:182} INFO - Started process (PID=10433) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:19,674] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:49:19,675] {logging_mixin.py:104} INFO - [2021-07-08 15:49:19,675] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:19,766] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:19,918] {logging_mixin.py:104} INFO - [2021-07-08 15:49:19,918] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:49:19,926] {logging_mixin.py:104} INFO - [2021-07-08 15:49:19,926] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:49:19,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.265 seconds
[2021-07-08 15:49:25,696] {scheduler_job.py:182} INFO - Started process (PID=10449) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:25,698] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:49:25,699] {logging_mixin.py:104} INFO - [2021-07-08 15:49:25,699] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:25,795] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:25,799] {logging_mixin.py:104} INFO - [2021-07-08 15:49:25,798] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:49:25,812] {logging_mixin.py:104} INFO - [2021-07-08 15:49:25,812] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:49:25,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 15:49:56,517] {scheduler_job.py:182} INFO - Started process (PID=10506) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:56,519] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:49:56,520] {logging_mixin.py:104} INFO - [2021-07-08 15:49:56,520] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:56,688] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:49:56,864] {logging_mixin.py:104} INFO - [2021-07-08 15:49:56,864] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:49:56,873] {logging_mixin.py:104} INFO - [2021-07-08 15:49:56,873] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:49:56,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.369 seconds
[2021-07-08 15:50:27,058] {scheduler_job.py:182} INFO - Started process (PID=10574) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:27,060] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:50:27,061] {logging_mixin.py:104} INFO - [2021-07-08 15:50:27,060] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:27,178] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:27,189] {logging_mixin.py:104} INFO - [2021-07-08 15:50:27,189] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:50:27,204] {logging_mixin.py:104} INFO - [2021-07-08 15:50:27,204] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:50:27,212] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.158 seconds
[2021-07-08 15:50:57,961] {scheduler_job.py:182} INFO - Started process (PID=10639) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:57,963] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:50:57,964] {logging_mixin.py:104} INFO - [2021-07-08 15:50:57,964] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:58,072] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:50:58,081] {logging_mixin.py:104} INFO - [2021-07-08 15:50:58,081] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:50:58,093] {logging_mixin.py:104} INFO - [2021-07-08 15:50:58,093] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:50:58,101] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 15:51:28,353] {scheduler_job.py:182} INFO - Started process (PID=10692) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:28,354] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:51:28,355] {logging_mixin.py:104} INFO - [2021-07-08 15:51:28,355] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:28,444] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:28,452] {logging_mixin.py:104} INFO - [2021-07-08 15:51:28,452] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:51:28,462] {logging_mixin.py:104} INFO - [2021-07-08 15:51:28,462] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:51:28,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 15:51:59,024] {scheduler_job.py:182} INFO - Started process (PID=10755) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:59,025] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:51:59,026] {logging_mixin.py:104} INFO - [2021-07-08 15:51:59,026] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:59,116] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:51:59,126] {logging_mixin.py:104} INFO - [2021-07-08 15:51:59,125] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:51:59,135] {logging_mixin.py:104} INFO - [2021-07-08 15:51:59,135] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:51:59,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 15:52:29,457] {scheduler_job.py:182} INFO - Started process (PID=10818) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:29,458] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:52:29,459] {logging_mixin.py:104} INFO - [2021-07-08 15:52:29,459] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:29,547] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:29,558] {logging_mixin.py:104} INFO - [2021-07-08 15:52:29,558] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:52:29,570] {logging_mixin.py:104} INFO - [2021-07-08 15:52:29,569] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:52:29,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 15:52:59,792] {scheduler_job.py:182} INFO - Started process (PID=10872) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:59,793] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:52:59,794] {logging_mixin.py:104} INFO - [2021-07-08 15:52:59,794] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:59,882] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:52:59,891] {logging_mixin.py:104} INFO - [2021-07-08 15:52:59,891] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:52:59,900] {logging_mixin.py:104} INFO - [2021-07-08 15:52:59,900] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:52:59,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 15:53:30,108] {scheduler_job.py:182} INFO - Started process (PID=10937) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:53:30,109] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:53:30,110] {logging_mixin.py:104} INFO - [2021-07-08 15:53:30,110] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:53:30,205] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:53:30,214] {logging_mixin.py:104} INFO - [2021-07-08 15:53:30,214] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:53:30,224] {logging_mixin.py:104} INFO - [2021-07-08 15:53:30,224] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:53:30,232] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 15:54:00,805] {scheduler_job.py:182} INFO - Started process (PID=11001) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:00,807] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:54:00,807] {logging_mixin.py:104} INFO - [2021-07-08 15:54:00,807] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:00,934] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:00,948] {logging_mixin.py:104} INFO - [2021-07-08 15:54:00,948] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:54:00,961] {logging_mixin.py:104} INFO - [2021-07-08 15:54:00,961] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:54:00,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-07-08 15:54:31,627] {scheduler_job.py:182} INFO - Started process (PID=11059) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:31,628] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:54:31,629] {logging_mixin.py:104} INFO - [2021-07-08 15:54:31,629] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:31,741] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:54:31,751] {logging_mixin.py:104} INFO - [2021-07-08 15:54:31,751] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:54:31,761] {logging_mixin.py:104} INFO - [2021-07-08 15:54:31,761] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:54:31,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 15:55:02,042] {scheduler_job.py:182} INFO - Started process (PID=11124) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:02,044] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:55:02,046] {logging_mixin.py:104} INFO - [2021-07-08 15:55:02,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:02,215] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:02,230] {logging_mixin.py:104} INFO - [2021-07-08 15:55:02,230] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:55:02,246] {logging_mixin.py:104} INFO - [2021-07-08 15:55:02,246] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:55:02,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.224 seconds
[2021-07-08 15:55:32,301] {scheduler_job.py:182} INFO - Started process (PID=11178) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:32,302] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:55:32,302] {logging_mixin.py:104} INFO - [2021-07-08 15:55:32,302] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:32,454] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:55:32,466] {logging_mixin.py:104} INFO - [2021-07-08 15:55:32,466] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:55:32,478] {logging_mixin.py:104} INFO - [2021-07-08 15:55:32,478] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:55:32,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-07-08 15:56:02,856] {scheduler_job.py:182} INFO - Started process (PID=11243) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:02,858] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:56:02,859] {logging_mixin.py:104} INFO - [2021-07-08 15:56:02,859] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:02,997] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:03,013] {logging_mixin.py:104} INFO - [2021-07-08 15:56:03,013] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:56:03,026] {logging_mixin.py:104} INFO - [2021-07-08 15:56:03,025] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:56:03,035] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.183 seconds
[2021-07-08 15:56:33,773] {scheduler_job.py:182} INFO - Started process (PID=11296) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:33,774] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:56:33,775] {logging_mixin.py:104} INFO - [2021-07-08 15:56:33,775] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:33,990] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:56:34,013] {logging_mixin.py:104} INFO - [2021-07-08 15:56:34,013] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:56:34,036] {logging_mixin.py:104} INFO - [2021-07-08 15:56:34,036] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:56:34,051] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.281 seconds
[2021-07-08 15:57:04,527] {scheduler_job.py:182} INFO - Started process (PID=11359) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:04,528] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:57:04,529] {logging_mixin.py:104} INFO - [2021-07-08 15:57:04,529] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:04,647] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:04,657] {logging_mixin.py:104} INFO - [2021-07-08 15:57:04,657] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:57:04,669] {logging_mixin.py:104} INFO - [2021-07-08 15:57:04,668] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:57:04,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 15:57:35,223] {scheduler_job.py:182} INFO - Started process (PID=11412) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:35,224] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 15:57:35,225] {logging_mixin.py:104} INFO - [2021-07-08 15:57:35,225] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:35,365] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 15:57:35,375] {logging_mixin.py:104} INFO - [2021-07-08 15:57:35,375] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 15:57:35,387] {logging_mixin.py:104} INFO - [2021-07-08 15:57:35,386] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 15:57:35,395] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.175 seconds
[2021-07-08 17:02:56,248] {scheduler_job.py:182} INFO - Started process (PID=24) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:02:56,249] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:02:56,250] {logging_mixin.py:104} INFO - [2021-07-08 17:02:56,250] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:02:56,419] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:02:56,434] {logging_mixin.py:104} INFO - [2021-07-08 17:02:56,434] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:02:56,454] {logging_mixin.py:104} INFO - [2021-07-08 17:02:56,454] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:02:56,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-07-08 17:03:27,466] {scheduler_job.py:182} INFO - Started process (PID=82) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:27,468] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:03:27,469] {logging_mixin.py:104} INFO - [2021-07-08 17:03:27,468] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:27,609] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:27,618] {logging_mixin.py:104} INFO - [2021-07-08 17:03:27,618] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:03:27,630] {logging_mixin.py:104} INFO - [2021-07-08 17:03:27,630] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:03:27,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-07-08 17:03:58,396] {scheduler_job.py:182} INFO - Started process (PID=146) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:58,397] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:03:58,397] {logging_mixin.py:104} INFO - [2021-07-08 17:03:58,397] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:58,496] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:03:58,506] {logging_mixin.py:104} INFO - [2021-07-08 17:03:58,506] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:03:58,517] {logging_mixin.py:104} INFO - [2021-07-08 17:03:58,517] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:03:58,526] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 17:04:29,304] {scheduler_job.py:182} INFO - Started process (PID=211) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:29,305] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:04:29,306] {logging_mixin.py:104} INFO - [2021-07-08 17:04:29,306] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:29,409] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:29,420] {logging_mixin.py:104} INFO - [2021-07-08 17:04:29,420] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:04:29,437] {logging_mixin.py:104} INFO - [2021-07-08 17:04:29,437] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:04:29,447] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 17:04:59,682] {scheduler_job.py:182} INFO - Started process (PID=264) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:59,683] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:04:59,683] {logging_mixin.py:104} INFO - [2021-07-08 17:04:59,683] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:59,841] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:04:59,852] {logging_mixin.py:104} INFO - [2021-07-08 17:04:59,852] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:04:59,866] {logging_mixin.py:104} INFO - [2021-07-08 17:04:59,866] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:04:59,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 17:05:30,658] {scheduler_job.py:182} INFO - Started process (PID=328) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:05:30,666] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:05:30,667] {logging_mixin.py:104} INFO - [2021-07-08 17:05:30,667] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:05:30,750] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:05:30,758] {logging_mixin.py:104} INFO - [2021-07-08 17:05:30,758] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:05:30,769] {logging_mixin.py:104} INFO - [2021-07-08 17:05:30,769] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:05:30,776] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 17:06:01,596] {scheduler_job.py:182} INFO - Started process (PID=393) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:01,597] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:06:01,598] {logging_mixin.py:104} INFO - [2021-07-08 17:06:01,598] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:01,683] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:01,691] {logging_mixin.py:104} INFO - [2021-07-08 17:06:01,691] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:06:01,704] {logging_mixin.py:104} INFO - [2021-07-08 17:06:01,704] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:06:01,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 17:06:32,406] {scheduler_job.py:182} INFO - Started process (PID=447) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:32,408] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:06:32,408] {logging_mixin.py:104} INFO - [2021-07-08 17:06:32,408] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:32,519] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:06:32,527] {logging_mixin.py:104} INFO - [2021-07-08 17:06:32,527] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:06:32,538] {logging_mixin.py:104} INFO - [2021-07-08 17:06:32,538] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:06:32,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 17:07:02,884] {scheduler_job.py:182} INFO - Started process (PID=510) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:02,885] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:07:02,885] {logging_mixin.py:104} INFO - [2021-07-08 17:07:02,885] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:02,973] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:02,984] {logging_mixin.py:104} INFO - [2021-07-08 17:07:02,984] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:07:02,996] {logging_mixin.py:104} INFO - [2021-07-08 17:07:02,996] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:07:03,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 17:07:33,536] {scheduler_job.py:182} INFO - Started process (PID=574) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:33,537] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:07:33,537] {logging_mixin.py:104} INFO - [2021-07-08 17:07:33,537] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:33,662] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:07:33,673] {logging_mixin.py:104} INFO - [2021-07-08 17:07:33,673] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:07:33,689] {logging_mixin.py:104} INFO - [2021-07-08 17:07:33,688] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:07:33,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.165 seconds
[2021-07-08 17:08:04,491] {scheduler_job.py:182} INFO - Started process (PID=627) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:04,493] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:08:04,493] {logging_mixin.py:104} INFO - [2021-07-08 17:08:04,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:04,593] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:04,601] {logging_mixin.py:104} INFO - [2021-07-08 17:08:04,601] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:08:04,614] {logging_mixin.py:104} INFO - [2021-07-08 17:08:04,614] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:08:04,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 17:08:18,022] {scheduler_job.py:182} INFO - Started process (PID=681) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:18,023] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:08:18,023] {logging_mixin.py:104} INFO - [2021-07-08 17:08:18,023] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:18,109] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:18,271] {logging_mixin.py:104} INFO - [2021-07-08 17:08:18,271] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:08:18,282] {logging_mixin.py:104} INFO - [2021-07-08 17:08:18,282] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:08:18,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.277 seconds
[2021-07-08 17:08:23,192] {scheduler_job.py:182} INFO - Started process (PID=682) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:23,193] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:08:23,193] {logging_mixin.py:104} INFO - [2021-07-08 17:08:23,193] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:23,325] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:23,328] {logging_mixin.py:104} INFO - [2021-07-08 17:08:23,328] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:08:23,344] {logging_mixin.py:104} INFO - [2021-07-08 17:08:23,343] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:08:23,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-07-08 17:08:54,055] {scheduler_job.py:182} INFO - Started process (PID=745) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:54,057] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:08:54,058] {logging_mixin.py:104} INFO - [2021-07-08 17:08:54,057] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:54,144] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:54,151] {logging_mixin.py:104} INFO - [2021-07-08 17:08:54,151] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:08:54,162] {logging_mixin.py:104} INFO - [2021-07-08 17:08:54,162] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:08:54,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:08:59,163] {scheduler_job.py:182} INFO - Started process (PID=746) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:59,164] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:08:59,165] {logging_mixin.py:104} INFO - [2021-07-08 17:08:59,164] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:59,297] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:08:59,305] {logging_mixin.py:104} INFO - [2021-07-08 17:08:59,305] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:08:59,317] {logging_mixin.py:104} INFO - [2021-07-08 17:08:59,317] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:08:59,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-07-08 17:09:09,843] {scheduler_job.py:182} INFO - Started process (PID=772) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:09,844] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:09:09,845] {logging_mixin.py:104} INFO - [2021-07-08 17:09:09,845] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:09,956] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:09,966] {logging_mixin.py:104} INFO - [2021-07-08 17:09:09,966] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:09:09,984] {logging_mixin.py:104} INFO - [2021-07-08 17:09:09,984] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:09:09,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 17:09:40,579] {scheduler_job.py:182} INFO - Started process (PID=837) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:40,581] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:09:40,582] {logging_mixin.py:104} INFO - [2021-07-08 17:09:40,582] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:40,677] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:09:40,685] {logging_mixin.py:104} INFO - [2021-07-08 17:09:40,685] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:09:40,701] {logging_mixin.py:104} INFO - [2021-07-08 17:09:40,701] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:09:40,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 17:10:11,247] {scheduler_job.py:182} INFO - Started process (PID=904) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:11,249] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:10:11,250] {logging_mixin.py:104} INFO - [2021-07-08 17:10:11,250] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:11,372] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:11,383] {logging_mixin.py:104} INFO - [2021-07-08 17:10:11,383] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:10:11,403] {logging_mixin.py:104} INFO - [2021-07-08 17:10:11,403] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:10:11,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-07-08 17:10:41,994] {scheduler_job.py:182} INFO - Started process (PID=959) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:41,995] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:10:41,995] {logging_mixin.py:104} INFO - [2021-07-08 17:10:41,995] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:42,084] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:42,092] {logging_mixin.py:104} INFO - [2021-07-08 17:10:42,092] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:10:42,104] {logging_mixin.py:104} INFO - [2021-07-08 17:10:42,104] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:10:42,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 17:10:56,017] {scheduler_job.py:182} INFO - Started process (PID=987) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:56,019] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:10:56,020] {logging_mixin.py:104} INFO - [2021-07-08 17:10:56,020] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:56,106] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:10:56,113] {logging_mixin.py:104} INFO - [2021-07-08 17:10:56,113] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:10:56,125] {logging_mixin.py:104} INFO - [2021-07-08 17:10:56,125] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:10:56,135] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 17:11:26,952] {scheduler_job.py:182} INFO - Started process (PID=1052) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:26,954] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:11:26,955] {logging_mixin.py:104} INFO - [2021-07-08 17:11:26,955] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:27,038] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:27,046] {logging_mixin.py:104} INFO - [2021-07-08 17:11:27,046] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:11:27,057] {logging_mixin.py:104} INFO - [2021-07-08 17:11:27,057] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:11:27,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 17:11:57,629] {scheduler_job.py:182} INFO - Started process (PID=1115) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:57,630] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:11:57,631] {logging_mixin.py:104} INFO - [2021-07-08 17:11:57,630] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:57,713] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:11:57,720] {logging_mixin.py:104} INFO - [2021-07-08 17:11:57,720] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:11:57,733] {logging_mixin.py:104} INFO - [2021-07-08 17:11:57,733] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:11:57,741] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 17:12:28,517] {scheduler_job.py:182} INFO - Started process (PID=1178) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:28,518] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:12:28,518] {logging_mixin.py:104} INFO - [2021-07-08 17:12:28,518] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:28,604] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:28,613] {logging_mixin.py:104} INFO - [2021-07-08 17:12:28,613] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:12:28,626] {logging_mixin.py:104} INFO - [2021-07-08 17:12:28,626] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:12:28,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 17:12:59,204] {scheduler_job.py:182} INFO - Started process (PID=1231) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:59,205] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:12:59,205] {logging_mixin.py:104} INFO - [2021-07-08 17:12:59,205] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:59,291] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:12:59,300] {logging_mixin.py:104} INFO - [2021-07-08 17:12:59,299] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:12:59,313] {logging_mixin.py:104} INFO - [2021-07-08 17:12:59,313] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:12:59,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 17:13:29,971] {scheduler_job.py:182} INFO - Started process (PID=1296) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:13:29,972] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:13:29,972] {logging_mixin.py:104} INFO - [2021-07-08 17:13:29,972] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:13:30,058] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:13:30,066] {logging_mixin.py:104} INFO - [2021-07-08 17:13:30,065] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:13:30,076] {logging_mixin.py:104} INFO - [2021-07-08 17:13:30,076] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:13:30,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:14:00,189] {scheduler_job.py:182} INFO - Started process (PID=1359) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:00,190] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:14:00,191] {logging_mixin.py:104} INFO - [2021-07-08 17:14:00,191] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:00,282] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:00,290] {logging_mixin.py:104} INFO - [2021-07-08 17:14:00,290] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:14:00,302] {logging_mixin.py:104} INFO - [2021-07-08 17:14:00,302] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:14:00,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 17:14:30,984] {scheduler_job.py:182} INFO - Started process (PID=1412) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:30,986] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:14:30,987] {logging_mixin.py:104} INFO - [2021-07-08 17:14:30,987] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:31,239] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:14:31,253] {logging_mixin.py:104} INFO - [2021-07-08 17:14:31,252] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:14:31,276] {logging_mixin.py:104} INFO - [2021-07-08 17:14:31,276] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:14:31,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.325 seconds
[2021-07-08 17:15:02,173] {scheduler_job.py:182} INFO - Started process (PID=1476) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:02,175] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:15:02,176] {logging_mixin.py:104} INFO - [2021-07-08 17:15:02,176] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:02,295] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:02,306] {logging_mixin.py:104} INFO - [2021-07-08 17:15:02,306] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:15:02,320] {logging_mixin.py:104} INFO - [2021-07-08 17:15:02,319] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:15:02,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.158 seconds
[2021-07-08 17:15:32,997] {scheduler_job.py:182} INFO - Started process (PID=1540) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:32,998] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:15:32,998] {logging_mixin.py:104} INFO - [2021-07-08 17:15:32,998] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:33,098] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:15:33,107] {logging_mixin.py:104} INFO - [2021-07-08 17:15:33,107] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:15:33,119] {logging_mixin.py:104} INFO - [2021-07-08 17:15:33,119] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:15:33,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 17:16:03,193] {scheduler_job.py:182} INFO - Started process (PID=1595) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:03,195] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:16:03,195] {logging_mixin.py:104} INFO - [2021-07-08 17:16:03,195] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:03,295] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:03,305] {logging_mixin.py:104} INFO - [2021-07-08 17:16:03,305] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:16:03,319] {logging_mixin.py:104} INFO - [2021-07-08 17:16:03,319] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:16:03,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 17:16:33,744] {scheduler_job.py:182} INFO - Started process (PID=1659) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:33,746] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:16:33,747] {logging_mixin.py:104} INFO - [2021-07-08 17:16:33,747] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:33,832] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:16:33,840] {logging_mixin.py:104} INFO - [2021-07-08 17:16:33,840] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:16:33,850] {logging_mixin.py:104} INFO - [2021-07-08 17:16:33,850] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:16:33,857] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:17:04,164] {scheduler_job.py:182} INFO - Started process (PID=1721) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:04,165] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:17:04,166] {logging_mixin.py:104} INFO - [2021-07-08 17:17:04,166] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:04,254] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:04,261] {logging_mixin.py:104} INFO - [2021-07-08 17:17:04,261] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:17:04,272] {logging_mixin.py:104} INFO - [2021-07-08 17:17:04,272] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:17:04,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:17:34,642] {scheduler_job.py:182} INFO - Started process (PID=1776) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:34,644] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:17:34,645] {logging_mixin.py:104} INFO - [2021-07-08 17:17:34,645] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:34,728] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:17:34,736] {logging_mixin.py:104} INFO - [2021-07-08 17:17:34,736] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:17:34,746] {logging_mixin.py:104} INFO - [2021-07-08 17:17:34,746] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:17:34,753] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:18:05,431] {scheduler_job.py:182} INFO - Started process (PID=1839) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:05,433] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:18:05,434] {logging_mixin.py:104} INFO - [2021-07-08 17:18:05,433] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:05,535] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:05,543] {logging_mixin.py:104} INFO - [2021-07-08 17:18:05,543] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:18:05,555] {logging_mixin.py:104} INFO - [2021-07-08 17:18:05,555] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:18:05,565] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 17:18:35,909] {scheduler_job.py:182} INFO - Started process (PID=1892) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:35,910] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:18:35,911] {logging_mixin.py:104} INFO - [2021-07-08 17:18:35,911] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:36,006] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:18:36,014] {logging_mixin.py:104} INFO - [2021-07-08 17:18:36,014] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:18:36,028] {logging_mixin.py:104} INFO - [2021-07-08 17:18:36,028] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:18:36,037] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 17:19:06,502] {scheduler_job.py:182} INFO - Started process (PID=1956) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:06,504] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:19:06,504] {logging_mixin.py:104} INFO - [2021-07-08 17:19:06,504] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:06,585] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:06,592] {logging_mixin.py:104} INFO - [2021-07-08 17:19:06,592] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:19:06,602] {logging_mixin.py:104} INFO - [2021-07-08 17:19:06,602] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:19:06,618] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:19:36,916] {scheduler_job.py:182} INFO - Started process (PID=2019) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:36,917] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:19:36,918] {logging_mixin.py:104} INFO - [2021-07-08 17:19:36,918] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:37,006] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:19:37,013] {logging_mixin.py:104} INFO - [2021-07-08 17:19:37,013] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:19:37,024] {logging_mixin.py:104} INFO - [2021-07-08 17:19:37,024] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:19:37,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 17:20:07,333] {scheduler_job.py:182} INFO - Started process (PID=2072) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:07,335] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:20:07,336] {logging_mixin.py:104} INFO - [2021-07-08 17:20:07,336] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:07,461] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:07,471] {logging_mixin.py:104} INFO - [2021-07-08 17:20:07,471] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:20:07,482] {logging_mixin.py:104} INFO - [2021-07-08 17:20:07,482] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:20:07,498] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-07-08 17:20:37,629] {scheduler_job.py:182} INFO - Started process (PID=2135) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:37,630] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:20:37,631] {logging_mixin.py:104} INFO - [2021-07-08 17:20:37,631] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:37,722] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:20:37,730] {logging_mixin.py:104} INFO - [2021-07-08 17:20:37,730] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:20:37,742] {logging_mixin.py:104} INFO - [2021-07-08 17:20:37,741] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:20:37,749] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 17:21:08,259] {scheduler_job.py:182} INFO - Started process (PID=2199) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:08,261] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:21:08,262] {logging_mixin.py:104} INFO - [2021-07-08 17:21:08,262] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:08,344] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:08,352] {logging_mixin.py:104} INFO - [2021-07-08 17:21:08,352] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:21:08,362] {logging_mixin.py:104} INFO - [2021-07-08 17:21:08,362] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:21:08,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 17:21:38,480] {scheduler_job.py:182} INFO - Started process (PID=2252) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:38,481] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:21:38,482] {logging_mixin.py:104} INFO - [2021-07-08 17:21:38,482] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:38,589] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:21:38,599] {logging_mixin.py:104} INFO - [2021-07-08 17:21:38,599] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:21:38,613] {logging_mixin.py:104} INFO - [2021-07-08 17:21:38,612] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:21:38,623] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 17:22:09,024] {scheduler_job.py:182} INFO - Started process (PID=2315) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:09,026] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:22:09,027] {logging_mixin.py:104} INFO - [2021-07-08 17:22:09,027] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:09,126] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:09,135] {logging_mixin.py:104} INFO - [2021-07-08 17:22:09,135] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:22:09,148] {logging_mixin.py:104} INFO - [2021-07-08 17:22:09,147] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:22:09,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 17:22:39,490] {scheduler_job.py:182} INFO - Started process (PID=2379) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:39,492] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:22:39,493] {logging_mixin.py:104} INFO - [2021-07-08 17:22:39,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:39,639] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:22:39,648] {logging_mixin.py:104} INFO - [2021-07-08 17:22:39,648] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:22:39,662] {logging_mixin.py:104} INFO - [2021-07-08 17:22:39,661] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:22:39,669] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-07-08 17:23:10,007] {scheduler_job.py:182} INFO - Started process (PID=2432) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:10,008] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:23:10,009] {logging_mixin.py:104} INFO - [2021-07-08 17:23:10,008] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:10,095] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:10,102] {logging_mixin.py:104} INFO - [2021-07-08 17:23:10,102] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:23:10,113] {logging_mixin.py:104} INFO - [2021-07-08 17:23:10,113] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:23:10,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:23:40,538] {scheduler_job.py:182} INFO - Started process (PID=2497) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:40,539] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:23:40,539] {logging_mixin.py:104} INFO - [2021-07-08 17:23:40,539] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:40,630] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:23:40,638] {logging_mixin.py:104} INFO - [2021-07-08 17:23:40,638] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:23:40,649] {logging_mixin.py:104} INFO - [2021-07-08 17:23:40,649] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:23:40,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 17:24:11,087] {scheduler_job.py:182} INFO - Started process (PID=2561) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:11,088] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:24:11,088] {logging_mixin.py:104} INFO - [2021-07-08 17:24:11,088] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:11,172] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:11,179] {logging_mixin.py:104} INFO - [2021-07-08 17:24:11,179] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:24:11,189] {logging_mixin.py:104} INFO - [2021-07-08 17:24:11,189] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:24:11,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 17:24:41,613] {scheduler_job.py:182} INFO - Started process (PID=2614) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:41,614] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:24:41,615] {logging_mixin.py:104} INFO - [2021-07-08 17:24:41,615] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:41,716] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:24:41,726] {logging_mixin.py:104} INFO - [2021-07-08 17:24:41,726] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:24:41,739] {logging_mixin.py:104} INFO - [2021-07-08 17:24:41,739] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:24:41,748] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 17:25:12,218] {scheduler_job.py:182} INFO - Started process (PID=2680) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:12,219] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:25:12,220] {logging_mixin.py:104} INFO - [2021-07-08 17:25:12,220] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:12,310] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:12,319] {logging_mixin.py:104} INFO - [2021-07-08 17:25:12,319] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:25:12,331] {logging_mixin.py:104} INFO - [2021-07-08 17:25:12,330] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:25:12,338] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 17:25:42,976] {scheduler_job.py:182} INFO - Started process (PID=2744) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:42,977] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:25:42,977] {logging_mixin.py:104} INFO - [2021-07-08 17:25:42,977] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:43,071] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:25:43,079] {logging_mixin.py:104} INFO - [2021-07-08 17:25:43,079] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:25:43,090] {logging_mixin.py:104} INFO - [2021-07-08 17:25:43,090] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:25:43,098] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 17:26:13,469] {scheduler_job.py:182} INFO - Started process (PID=2798) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:13,470] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:26:13,471] {logging_mixin.py:104} INFO - [2021-07-08 17:26:13,471] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:13,588] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:13,598] {logging_mixin.py:104} INFO - [2021-07-08 17:26:13,598] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:26:13,614] {logging_mixin.py:104} INFO - [2021-07-08 17:26:13,614] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:26:13,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.157 seconds
[2021-07-08 17:26:43,777] {scheduler_job.py:182} INFO - Started process (PID=2860) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:43,778] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:26:43,779] {logging_mixin.py:104} INFO - [2021-07-08 17:26:43,779] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:43,880] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:26:43,890] {logging_mixin.py:104} INFO - [2021-07-08 17:26:43,890] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:26:43,903] {logging_mixin.py:104} INFO - [2021-07-08 17:26:43,903] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:26:43,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 17:27:14,612] {scheduler_job.py:182} INFO - Started process (PID=2924) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:14,613] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:27:14,615] {logging_mixin.py:104} INFO - [2021-07-08 17:27:14,614] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:14,704] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:14,712] {logging_mixin.py:104} INFO - [2021-07-08 17:27:14,712] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:27:14,722] {logging_mixin.py:104} INFO - [2021-07-08 17:27:14,722] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:27:14,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 17:27:44,904] {scheduler_job.py:182} INFO - Started process (PID=2978) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:44,906] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:27:44,907] {logging_mixin.py:104} INFO - [2021-07-08 17:27:44,907] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:44,991] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:27:44,999] {logging_mixin.py:104} INFO - [2021-07-08 17:27:44,999] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:27:45,009] {logging_mixin.py:104} INFO - [2021-07-08 17:27:45,009] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:27:45,016] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:28:15,360] {scheduler_job.py:182} INFO - Started process (PID=3041) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:15,361] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:28:15,362] {logging_mixin.py:104} INFO - [2021-07-08 17:28:15,362] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:15,457] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:15,466] {logging_mixin.py:104} INFO - [2021-07-08 17:28:15,466] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:28:15,480] {logging_mixin.py:104} INFO - [2021-07-08 17:28:15,480] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:28:15,488] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 17:28:45,645] {scheduler_job.py:182} INFO - Started process (PID=3104) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:45,647] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:28:45,648] {logging_mixin.py:104} INFO - [2021-07-08 17:28:45,648] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:45,733] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:28:45,740] {logging_mixin.py:104} INFO - [2021-07-08 17:28:45,740] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:28:45,752] {logging_mixin.py:104} INFO - [2021-07-08 17:28:45,752] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:28:45,760] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 17:29:14,098] {scheduler_job.py:182} INFO - Started process (PID=3158) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:14,100] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:29:14,101] {logging_mixin.py:104} INFO - [2021-07-08 17:29:14,101] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:14,190] {logging_mixin.py:104} INFO - [2021-07-08 17:29:14,189] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 90, in <module>
    python_callable=aws_step_function,
NameError: name 'aws_step_function' is not defined
[2021-07-08 17:29:14,191] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:14,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.103 seconds
[2021-07-08 17:29:17,116] {scheduler_job.py:182} INFO - Started process (PID=3159) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:17,117] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:29:17,118] {logging_mixin.py:104} INFO - [2021-07-08 17:29:17,118] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:17,204] {logging_mixin.py:104} INFO - [2021-07-08 17:29:17,204] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 90, in <module>
    python_callable=aws_step_function,
NameError: name 'aws_step_function' is not defined
[2021-07-08 17:29:17,205] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:17,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.097 seconds
[2021-07-08 17:29:21,224] {scheduler_job.py:182} INFO - Started process (PID=3170) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:21,225] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:29:21,226] {logging_mixin.py:104} INFO - [2021-07-08 17:29:21,226] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:21,309] {logging_mixin.py:104} INFO - [2021-07-08 17:29:21,309] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 90, in <module>
    python_callable=aws_step_function,
NameError: name 'aws_step_function' is not defined
[2021-07-08 17:29:21,310] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:21,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.092 seconds
[2021-07-08 17:29:37,736] {scheduler_job.py:182} INFO - Started process (PID=3213) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:37,738] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:29:37,739] {logging_mixin.py:104} INFO - [2021-07-08 17:29:37,739] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:37,831] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:38,426] {logging_mixin.py:104} INFO - [2021-07-08 17:29:38,426] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:29:38,436] {logging_mixin.py:104} INFO - [2021-07-08 17:29:38,436] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:29:38,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.714 seconds
[2021-07-08 17:29:54,515] {scheduler_job.py:182} INFO - Started process (PID=3234) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:54,516] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:29:54,517] {logging_mixin.py:104} INFO - [2021-07-08 17:29:54,517] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:54,605] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:29:54,608] {logging_mixin.py:104} INFO - [2021-07-08 17:29:54,608] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:29:54,621] {logging_mixin.py:104} INFO - [2021-07-08 17:29:54,621] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:29:54,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 17:30:09,003] {scheduler_job.py:182} INFO - Started process (PID=3277) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:09,006] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:30:09,007] {logging_mixin.py:104} INFO - [2021-07-08 17:30:09,007] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:09,089] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:09,097] {logging_mixin.py:104} INFO - [2021-07-08 17:30:09,097] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:30:09,107] {logging_mixin.py:104} INFO - [2021-07-08 17:30:09,107] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:30:09,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 17:30:39,639] {scheduler_job.py:182} INFO - Started process (PID=3341) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:39,640] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:30:39,640] {logging_mixin.py:104} INFO - [2021-07-08 17:30:39,640] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:39,734] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:30:39,742] {logging_mixin.py:104} INFO - [2021-07-08 17:30:39,742] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:30:39,756] {logging_mixin.py:104} INFO - [2021-07-08 17:30:39,755] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:30:39,765] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 17:31:10,207] {scheduler_job.py:182} INFO - Started process (PID=3396) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:10,209] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:31:10,209] {logging_mixin.py:104} INFO - [2021-07-08 17:31:10,209] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:10,293] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:10,301] {logging_mixin.py:104} INFO - [2021-07-08 17:31:10,300] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:31:10,311] {logging_mixin.py:104} INFO - [2021-07-08 17:31:10,311] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:31:10,319] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 17:31:40,508] {scheduler_job.py:182} INFO - Started process (PID=3459) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:40,509] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:31:40,510] {logging_mixin.py:104} INFO - [2021-07-08 17:31:40,510] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:40,600] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:31:40,610] {logging_mixin.py:104} INFO - [2021-07-08 17:31:40,610] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:31:40,623] {logging_mixin.py:104} INFO - [2021-07-08 17:31:40,623] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:31:40,632] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 17:32:11,164] {scheduler_job.py:182} INFO - Started process (PID=3525) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:11,165] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:32:11,166] {logging_mixin.py:104} INFO - [2021-07-08 17:32:11,166] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:11,251] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:11,259] {logging_mixin.py:104} INFO - [2021-07-08 17:32:11,259] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:32:11,269] {logging_mixin.py:104} INFO - [2021-07-08 17:32:11,269] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:32:11,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 17:32:41,940] {scheduler_job.py:182} INFO - Started process (PID=3579) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:41,942] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:32:41,943] {logging_mixin.py:104} INFO - [2021-07-08 17:32:41,943] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:42,030] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:32:42,037] {logging_mixin.py:104} INFO - [2021-07-08 17:32:42,037] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:32:42,047] {logging_mixin.py:104} INFO - [2021-07-08 17:32:42,047] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:32:42,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:33:12,802] {scheduler_job.py:182} INFO - Started process (PID=3643) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:12,804] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:33:12,805] {logging_mixin.py:104} INFO - [2021-07-08 17:33:12,805] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:12,898] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:12,907] {logging_mixin.py:104} INFO - [2021-07-08 17:33:12,907] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:33:12,918] {logging_mixin.py:104} INFO - [2021-07-08 17:33:12,918] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:33:12,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 17:33:15,822] {scheduler_job.py:182} INFO - Started process (PID=3644) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:15,823] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:33:15,824] {logging_mixin.py:104} INFO - [2021-07-08 17:33:15,824] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:15,914] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:16,117] {logging_mixin.py:104} INFO - [2021-07-08 17:33:16,117] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:33:16,127] {logging_mixin.py:104} INFO - [2021-07-08 17:33:16,126] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:33:16,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.317 seconds
[2021-07-08 17:33:22,972] {scheduler_job.py:182} INFO - Started process (PID=3655) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:22,973] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:33:22,974] {logging_mixin.py:104} INFO - [2021-07-08 17:33:22,974] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:23,060] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:23,064] {logging_mixin.py:104} INFO - [2021-07-08 17:33:23,064] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:33:23,075] {logging_mixin.py:104} INFO - [2021-07-08 17:33:23,075] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:33:23,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 17:33:33,011] {scheduler_job.py:182} INFO - Started process (PID=3666) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:33,012] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:33:33,012] {logging_mixin.py:104} INFO - [2021-07-08 17:33:33,012] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:33,102] {logging_mixin.py:104} INFO - [2021-07-08 17:33:33,101] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 99, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 134, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 527, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/helpers.py", line 46, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (Check Credentiasl) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2021-07-08 17:33:33,102] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:33,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.098 seconds
[2021-07-08 17:33:35,660] {scheduler_job.py:182} INFO - Started process (PID=3680) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:35,661] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:33:35,662] {logging_mixin.py:104} INFO - [2021-07-08 17:33:35,662] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:35,762] {logging_mixin.py:104} INFO - [2021-07-08 17:33:35,760] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 99, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 134, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 527, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/helpers.py", line 46, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (Check Credentials) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2021-07-08 17:33:35,762] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:33:35,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 17:34:06,507] {scheduler_job.py:182} INFO - Started process (PID=3743) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:06,509] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:34:06,509] {logging_mixin.py:104} INFO - [2021-07-08 17:34:06,509] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:06,650] {logging_mixin.py:104} INFO - [2021-07-08 17:34:06,649] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 99, in <module>
    dag=dag)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/python.py", line 134, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 185, in apply_defaults
    result = func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/baseoperator.py", line 527, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/helpers.py", line 46, in validate_key
    "dots and underscores exclusively".format(k=k)
airflow.exceptions.AirflowException: The key (Check Credentials) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2021-07-08 17:34:06,650] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:06,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 17:34:20,669] {scheduler_job.py:182} INFO - Started process (PID=3773) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:20,670] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:34:20,670] {logging_mixin.py:104} INFO - [2021-07-08 17:34:20,670] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:20,776] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:21,030] {logging_mixin.py:104} INFO - [2021-07-08 17:34:21,030] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:34:21,043] {logging_mixin.py:104} INFO - [2021-07-08 17:34:21,043] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:34:21,057] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.392 seconds
[2021-07-08 17:34:51,806] {scheduler_job.py:182} INFO - Started process (PID=3837) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:51,808] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:34:51,809] {logging_mixin.py:104} INFO - [2021-07-08 17:34:51,809] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:51,893] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:34:51,900] {logging_mixin.py:104} INFO - [2021-07-08 17:34:51,900] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:34:51,910] {logging_mixin.py:104} INFO - [2021-07-08 17:34:51,910] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:34:51,917] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 17:35:22,574] {scheduler_job.py:182} INFO - Started process (PID=3892) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:22,575] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:35:22,575] {logging_mixin.py:104} INFO - [2021-07-08 17:35:22,575] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:22,661] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:22,669] {logging_mixin.py:104} INFO - [2021-07-08 17:35:22,669] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:35:22,680] {logging_mixin.py:104} INFO - [2021-07-08 17:35:22,680] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:35:22,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 17:35:41,377] {scheduler_job.py:182} INFO - Started process (PID=3930) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:41,377] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:35:41,378] {logging_mixin.py:104} INFO - [2021-07-08 17:35:41,378] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:41,473] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:35:41,481] {logging_mixin.py:104} INFO - [2021-07-08 17:35:41,481] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:35:41,493] {logging_mixin.py:104} INFO - [2021-07-08 17:35:41,493] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:35:41,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 17:36:11,979] {scheduler_job.py:182} INFO - Started process (PID=3993) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:11,980] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:36:11,981] {logging_mixin.py:104} INFO - [2021-07-08 17:36:11,981] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:12,150] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:12,162] {logging_mixin.py:104} INFO - [2021-07-08 17:36:12,162] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:36:12,191] {logging_mixin.py:104} INFO - [2021-07-08 17:36:12,190] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:36:12,209] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.234 seconds
[2021-07-08 17:36:42,687] {scheduler_job.py:182} INFO - Started process (PID=4047) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:42,688] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:36:42,689] {logging_mixin.py:104} INFO - [2021-07-08 17:36:42,689] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:42,795] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:36:42,804] {logging_mixin.py:104} INFO - [2021-07-08 17:36:42,804] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:36:42,817] {logging_mixin.py:104} INFO - [2021-07-08 17:36:42,817] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:36:42,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 17:37:13,521] {scheduler_job.py:182} INFO - Started process (PID=4111) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:13,522] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:37:13,524] {logging_mixin.py:104} INFO - [2021-07-08 17:37:13,524] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:13,618] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:13,626] {logging_mixin.py:104} INFO - [2021-07-08 17:37:13,626] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:37:13,637] {logging_mixin.py:104} INFO - [2021-07-08 17:37:13,637] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:37:13,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 17:37:44,142] {scheduler_job.py:182} INFO - Started process (PID=4174) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:44,143] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:37:44,143] {logging_mixin.py:104} INFO - [2021-07-08 17:37:44,143] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:44,239] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:37:44,247] {logging_mixin.py:104} INFO - [2021-07-08 17:37:44,247] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:37:44,258] {logging_mixin.py:104} INFO - [2021-07-08 17:37:44,258] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:37:44,266] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 17:38:14,808] {scheduler_job.py:182} INFO - Started process (PID=4227) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:14,809] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:38:14,810] {logging_mixin.py:104} INFO - [2021-07-08 17:38:14,810] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:14,901] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:14,909] {logging_mixin.py:104} INFO - [2021-07-08 17:38:14,909] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:38:14,921] {logging_mixin.py:104} INFO - [2021-07-08 17:38:14,921] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:38:14,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 17:38:17,641] {scheduler_job.py:182} INFO - Started process (PID=4253) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:17,642] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:38:17,643] {logging_mixin.py:104} INFO - [2021-07-08 17:38:17,643] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:17,741] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:17,751] {logging_mixin.py:104} INFO - [2021-07-08 17:38:17,751] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:38:17,764] {logging_mixin.py:104} INFO - [2021-07-08 17:38:17,764] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:38:17,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 17:38:48,078] {scheduler_job.py:182} INFO - Started process (PID=4305) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:48,079] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:38:48,080] {logging_mixin.py:104} INFO - [2021-07-08 17:38:48,079] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:48,189] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:38:48,197] {logging_mixin.py:104} INFO - [2021-07-08 17:38:48,197] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:38:48,211] {logging_mixin.py:104} INFO - [2021-07-08 17:38:48,211] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:38:48,221] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 17:39:18,331] {scheduler_job.py:182} INFO - Started process (PID=4360) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:18,332] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:39:18,333] {logging_mixin.py:104} INFO - [2021-07-08 17:39:18,333] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:18,443] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:18,452] {logging_mixin.py:104} INFO - [2021-07-08 17:39:18,452] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:39:18,467] {logging_mixin.py:104} INFO - [2021-07-08 17:39:18,467] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:39:18,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-07-08 17:39:49,124] {scheduler_job.py:182} INFO - Started process (PID=4423) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:49,125] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:39:49,126] {logging_mixin.py:104} INFO - [2021-07-08 17:39:49,125] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:49,289] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:39:49,302] {logging_mixin.py:104} INFO - [2021-07-08 17:39:49,302] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:39:49,320] {logging_mixin.py:104} INFO - [2021-07-08 17:39:49,320] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:39:49,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.220 seconds
[2021-07-08 17:40:19,466] {scheduler_job.py:182} INFO - Started process (PID=4479) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:19,467] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:40:19,468] {logging_mixin.py:104} INFO - [2021-07-08 17:40:19,468] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:19,553] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:19,561] {logging_mixin.py:104} INFO - [2021-07-08 17:40:19,561] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:40:19,574] {logging_mixin.py:104} INFO - [2021-07-08 17:40:19,574] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:40:19,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:40:50,358] {scheduler_job.py:182} INFO - Started process (PID=4541) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:50,359] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:40:50,360] {logging_mixin.py:104} INFO - [2021-07-08 17:40:50,360] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:50,451] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:40:50,459] {logging_mixin.py:104} INFO - [2021-07-08 17:40:50,459] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:40:50,473] {logging_mixin.py:104} INFO - [2021-07-08 17:40:50,473] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:40:50,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 17:41:20,957] {scheduler_job.py:182} INFO - Started process (PID=4604) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:20,958] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:41:20,959] {logging_mixin.py:104} INFO - [2021-07-08 17:41:20,958] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:21,061] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:21,072] {logging_mixin.py:104} INFO - [2021-07-08 17:41:21,072] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:41:21,090] {logging_mixin.py:104} INFO - [2021-07-08 17:41:21,090] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:41:21,100] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 17:41:51,441] {scheduler_job.py:182} INFO - Started process (PID=4658) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:51,443] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:41:51,444] {logging_mixin.py:104} INFO - [2021-07-08 17:41:51,444] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:51,527] {logging_mixin.py:104} INFO - [2021-07-08 17:41:51,527] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 11, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:41:51,528] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:51,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 17:41:58,980] {scheduler_job.py:182} INFO - Started process (PID=4680) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:58,981] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:41:58,981] {logging_mixin.py:104} INFO - [2021-07-08 17:41:58,981] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:59,058] {logging_mixin.py:104} INFO - [2021-07-08 17:41:59,058] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 11, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:41:59,059] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:41:59,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.092 seconds
[2021-07-08 17:42:00,005] {scheduler_job.py:182} INFO - Started process (PID=4681) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:00,006] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:42:00,007] {logging_mixin.py:104} INFO - [2021-07-08 17:42:00,007] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:00,093] {logging_mixin.py:104} INFO - [2021-07-08 17:42:00,093] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 11, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:42:00,093] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:00,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.106 seconds
[2021-07-08 17:42:25,727] {scheduler_job.py:182} INFO - Started process (PID=4734) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:25,728] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:42:25,729] {logging_mixin.py:104} INFO - [2021-07-08 17:42:25,729] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:25,819] {logging_mixin.py:104} INFO - [2021-07-08 17:42:25,819] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 11, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:42:25,820] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:25,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 17:42:56,085] {scheduler_job.py:182} INFO - Started process (PID=4798) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:56,087] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:42:56,087] {logging_mixin.py:104} INFO - [2021-07-08 17:42:56,087] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:56,160] {logging_mixin.py:104} INFO - [2021-07-08 17:42:56,159] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 11, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:42:56,160] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:56,171] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.087 seconds
[2021-07-08 17:42:59,138] {scheduler_job.py:182} INFO - Started process (PID=4799) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:59,139] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:42:59,140] {logging_mixin.py:104} INFO - [2021-07-08 17:42:59,140] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:59,223] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:42:59,232] {logging_mixin.py:104} INFO - [2021-07-08 17:42:59,232] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:42:59,243] {logging_mixin.py:104} INFO - [2021-07-08 17:42:59,243] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:42:59,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 17:43:29,822] {scheduler_job.py:182} INFO - Started process (PID=4864) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:43:29,824] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:43:29,825] {logging_mixin.py:104} INFO - [2021-07-08 17:43:29,825] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:43:29,910] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:43:29,918] {logging_mixin.py:104} INFO - [2021-07-08 17:43:29,918] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:43:29,928] {logging_mixin.py:104} INFO - [2021-07-08 17:43:29,928] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:43:29,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 17:44:00,588] {scheduler_job.py:182} INFO - Started process (PID=4926) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:00,589] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:44:00,590] {logging_mixin.py:104} INFO - [2021-07-08 17:44:00,590] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:00,723] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:00,738] {logging_mixin.py:104} INFO - [2021-07-08 17:44:00,737] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:44:00,766] {logging_mixin.py:104} INFO - [2021-07-08 17:44:00,765] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:44:00,781] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 17:44:31,245] {scheduler_job.py:182} INFO - Started process (PID=4981) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:31,250] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:44:31,251] {logging_mixin.py:104} INFO - [2021-07-08 17:44:31,251] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:31,351] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:31,362] {logging_mixin.py:104} INFO - [2021-07-08 17:44:31,362] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:44:31,375] {logging_mixin.py:104} INFO - [2021-07-08 17:44:31,375] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:44:31,383] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-07-08 17:44:37,279] {scheduler_job.py:182} INFO - Started process (PID=4992) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:37,280] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:44:37,281] {logging_mixin.py:104} INFO - [2021-07-08 17:44:37,280] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:37,367] {logging_mixin.py:104} INFO - [2021-07-08 17:44:37,366] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 12, in <module>
    from airflow import AirflowFailException
ImportError: cannot import name 'AirflowFailException'
[2021-07-08 17:44:37,367] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:37,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 17:44:40,291] {scheduler_job.py:182} INFO - Started process (PID=4993) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:40,292] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:44:40,293] {logging_mixin.py:104} INFO - [2021-07-08 17:44:40,293] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:40,412] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:44:40,423] {logging_mixin.py:104} INFO - [2021-07-08 17:44:40,423] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:44:40,439] {logging_mixin.py:104} INFO - [2021-07-08 17:44:40,439] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:44:40,452] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 17:45:08,006] {scheduler_job.py:182} INFO - Started process (PID=5047) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:08,009] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:45:08,010] {logging_mixin.py:104} INFO - [2021-07-08 17:45:08,010] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:08,013] {logging_mixin.py:104} INFO - [2021-07-08 17:45:08,012] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 89
    def task_to_retry():
                       ^
IndentationError: expected an indented block
[2021-07-08 17:45:08,013] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:08,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.026 seconds
[2021-07-08 17:45:11,013] {scheduler_job.py:182} INFO - Started process (PID=5059) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:11,015] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:45:11,015] {logging_mixin.py:104} INFO - [2021-07-08 17:45:11,015] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:11,017] {logging_mixin.py:104} INFO - [2021-07-08 17:45:11,017] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 88
    def task_to_retry():
                       ^
IndentationError: expected an indented block
[2021-07-08 17:45:11,018] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:11,029] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.017 seconds
[2021-07-08 17:45:13,031] {scheduler_job.py:182} INFO - Started process (PID=5060) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:13,033] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:45:13,034] {logging_mixin.py:104} INFO - [2021-07-08 17:45:13,034] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:13,037] {logging_mixin.py:104} INFO - [2021-07-08 17:45:13,036] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 89
    def task_to_retry():
                       ^
IndentationError: expected an indented block
[2021-07-08 17:45:13,037] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:13,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.023 seconds
[2021-07-08 17:45:19,353] {scheduler_job.py:182} INFO - Started process (PID=5069) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:19,355] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:45:19,356] {logging_mixin.py:104} INFO - [2021-07-08 17:45:19,356] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:19,461] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:19,479] {logging_mixin.py:104} INFO - [2021-07-08 17:45:19,479] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:45:19,492] {logging_mixin.py:104} INFO - [2021-07-08 17:45:19,492] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:45:19,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 17:45:50,072] {scheduler_job.py:182} INFO - Started process (PID=5132) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:50,073] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:45:50,074] {logging_mixin.py:104} INFO - [2021-07-08 17:45:50,074] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:50,199] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:45:50,210] {logging_mixin.py:104} INFO - [2021-07-08 17:45:50,210] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:45:50,224] {logging_mixin.py:104} INFO - [2021-07-08 17:45:50,224] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:45:50,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 17:46:20,740] {scheduler_job.py:182} INFO - Started process (PID=5195) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:20,741] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:46:20,742] {logging_mixin.py:104} INFO - [2021-07-08 17:46:20,742] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:20,860] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:20,870] {logging_mixin.py:104} INFO - [2021-07-08 17:46:20,870] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:46:20,883] {logging_mixin.py:104} INFO - [2021-07-08 17:46:20,883] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:46:20,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 17:46:51,030] {scheduler_job.py:182} INFO - Started process (PID=5249) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:51,030] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:46:51,031] {logging_mixin.py:104} INFO - [2021-07-08 17:46:51,031] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:51,131] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:46:51,142] {logging_mixin.py:104} INFO - [2021-07-08 17:46:51,142] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:46:51,158] {logging_mixin.py:104} INFO - [2021-07-08 17:46:51,158] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:46:51,167] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-07-08 17:47:21,743] {scheduler_job.py:182} INFO - Started process (PID=5312) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:21,744] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:47:21,745] {logging_mixin.py:104} INFO - [2021-07-08 17:47:21,745] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:21,845] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:21,855] {logging_mixin.py:104} INFO - [2021-07-08 17:47:21,855] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:47:21,867] {logging_mixin.py:104} INFO - [2021-07-08 17:47:21,867] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:47:21,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 17:47:52,434] {scheduler_job.py:182} INFO - Started process (PID=5376) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:52,435] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:47:52,435] {logging_mixin.py:104} INFO - [2021-07-08 17:47:52,435] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:52,568] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:47:52,583] {logging_mixin.py:104} INFO - [2021-07-08 17:47:52,583] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:47:52,600] {logging_mixin.py:104} INFO - [2021-07-08 17:47:52,600] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:47:52,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.179 seconds
[2021-07-08 17:48:23,089] {scheduler_job.py:182} INFO - Started process (PID=5429) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:23,090] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:48:23,091] {logging_mixin.py:104} INFO - [2021-07-08 17:48:23,091] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:23,206] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:23,215] {logging_mixin.py:104} INFO - [2021-07-08 17:48:23,215] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:48:23,228] {logging_mixin.py:104} INFO - [2021-07-08 17:48:23,228] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:48:23,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 17:48:53,771] {scheduler_job.py:182} INFO - Started process (PID=5492) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:53,772] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:48:53,772] {logging_mixin.py:104} INFO - [2021-07-08 17:48:53,772] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:53,893] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:48:53,904] {logging_mixin.py:104} INFO - [2021-07-08 17:48:53,904] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:48:53,920] {logging_mixin.py:104} INFO - [2021-07-08 17:48:53,920] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:48:53,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 17:49:24,559] {scheduler_job.py:182} INFO - Started process (PID=5556) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:24,560] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:49:24,560] {logging_mixin.py:104} INFO - [2021-07-08 17:49:24,560] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:24,662] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:24,671] {logging_mixin.py:104} INFO - [2021-07-08 17:49:24,671] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:49:24,684] {logging_mixin.py:104} INFO - [2021-07-08 17:49:24,684] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:49:24,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 17:49:55,164] {scheduler_job.py:182} INFO - Started process (PID=5611) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:55,165] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:49:55,166] {logging_mixin.py:104} INFO - [2021-07-08 17:49:55,165] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:55,270] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:49:55,281] {logging_mixin.py:104} INFO - [2021-07-08 17:49:55,281] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:49:55,300] {logging_mixin.py:104} INFO - [2021-07-08 17:49:55,299] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:49:55,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 17:50:24,776] {scheduler_job.py:182} INFO - Started process (PID=5673) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:24,777] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:24,778] {logging_mixin.py:104} INFO - [2021-07-08 17:50:24,778] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:24,875] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:25,092] {logging_mixin.py:104} INFO - [2021-07-08 17:50:25,092] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 17:50:25,102] {logging_mixin.py:104} INFO - [2021-07-08 17:50:25,102] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 17:50:25,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.338 seconds
[2021-07-08 17:50:30,236] {scheduler_job.py:182} INFO - Started process (PID=5691) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:30,237] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:30,238] {logging_mixin.py:104} INFO - [2021-07-08 17:50:30,238] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:30,431] {logging_mixin.py:104} INFO - [2021-07-08 17:50:30,430] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook('myAirflowTest',
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:50:30,432] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:30,438] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.205 seconds
[2021-07-08 17:50:42,214] {scheduler_job.py:182} INFO - Started process (PID=5719) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:42,215] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:42,216] {logging_mixin.py:104} INFO - [2021-07-08 17:50:42,216] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:42,311] {logging_mixin.py:104} INFO - [2021-07-08 17:50:42,310] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:50:42,311] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:42,316] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 17:50:45,671] {scheduler_job.py:182} INFO - Started process (PID=5721) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:45,672] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:45,673] {logging_mixin.py:104} INFO - [2021-07-08 17:50:45,672] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:45,757] {logging_mixin.py:104} INFO - [2021-07-08 17:50:45,757] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:50:45,757] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:45,762] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.093 seconds
[2021-07-08 17:50:52,702] {scheduler_job.py:182} INFO - Started process (PID=5722) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:52,703] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:52,704] {logging_mixin.py:104} INFO - [2021-07-08 17:50:52,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:52,706] {logging_mixin.py:104} INFO - [2021-07-08 17:50:52,706] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 123
    region_name=region_name',
                                    ^
SyntaxError: EOL while scanning string literal
[2021-07-08 17:50:52,707] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:52,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.021 seconds
[2021-07-08 17:50:54,960] {scheduler_job.py:182} INFO - Started process (PID=5738) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:54,961] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:50:54,961] {logging_mixin.py:104} INFO - [2021-07-08 17:50:54,961] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:55,082] {logging_mixin.py:104} INFO - [2021-07-08 17:50:55,081] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:50:55,082] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:50:55,088] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 17:51:16,531] {scheduler_job.py:182} INFO - Started process (PID=5785) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:16,532] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:51:16,532] {logging_mixin.py:104} INFO - [2021-07-08 17:51:16,532] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:16,620] {logging_mixin.py:104} INFO - [2021-07-08 17:51:16,619] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:51:16,620] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:16,625] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.096 seconds
[2021-07-08 17:51:47,113] {scheduler_job.py:182} INFO - Started process (PID=5839) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:47,114] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:51:47,115] {logging_mixin.py:104} INFO - [2021-07-08 17:51:47,115] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:47,215] {logging_mixin.py:104} INFO - [2021-07-08 17:51:47,214] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:51:47,215] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:47,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 17:51:55,148] {scheduler_job.py:182} INFO - Started process (PID=5850) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:55,150] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:51:55,151] {logging_mixin.py:104} INFO - [2021-07-08 17:51:55,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:55,233] {logging_mixin.py:104} INFO - [2021-07-08 17:51:55,233] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:51:55,234] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:51:55,238] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.094 seconds
[2021-07-08 17:52:25,917] {scheduler_job.py:182} INFO - Started process (PID=5914) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:25,918] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:52:25,918] {logging_mixin.py:104} INFO - [2021-07-08 17:52:25,918] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:26,005] {logging_mixin.py:104} INFO - [2021-07-08 17:52:26,005] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:52:26,006] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:26,010] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.095 seconds
[2021-07-08 17:52:56,310] {scheduler_job.py:182} INFO - Started process (PID=5967) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:56,312] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:52:56,313] {logging_mixin.py:104} INFO - [2021-07-08 17:52:56,313] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:56,406] {logging_mixin.py:104} INFO - [2021-07-08 17:52:56,406] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:52:56,407] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:52:56,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 17:53:26,978] {scheduler_job.py:182} INFO - Started process (PID=6030) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:26,980] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:53:26,981] {logging_mixin.py:104} INFO - [2021-07-08 17:53:26,980] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:27,061] {logging_mixin.py:104} INFO - [2021-07-08 17:53:27,061] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:53:27,062] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:27,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.093 seconds
[2021-07-08 17:53:56,797] {scheduler_job.py:182} INFO - Started process (PID=6093) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:56,798] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:53:56,798] {logging_mixin.py:104} INFO - [2021-07-08 17:53:56,798] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:56,886] {logging_mixin.py:104} INFO - [2021-07-08 17:53:56,886] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:53:56,887] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:53:56,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.096 seconds
[2021-07-08 17:54:27,529] {scheduler_job.py:182} INFO - Started process (PID=6146) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:27,530] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:54:27,531] {logging_mixin.py:104} INFO - [2021-07-08 17:54:27,531] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:27,616] {logging_mixin.py:104} INFO - [2021-07-08 17:54:27,615] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:54:27,616] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:27,620] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.095 seconds
[2021-07-08 17:54:58,228] {scheduler_job.py:182} INFO - Started process (PID=6210) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:58,234] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:54:58,235] {logging_mixin.py:104} INFO - [2021-07-08 17:54:58,235] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:58,324] {logging_mixin.py:104} INFO - [2021-07-08 17:54:58,323] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:54:58,324] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:54:58,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 17:55:28,912] {scheduler_job.py:182} INFO - Started process (PID=6273) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:28,913] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:55:28,913] {logging_mixin.py:104} INFO - [2021-07-08 17:55:28,913] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:29,001] {logging_mixin.py:104} INFO - [2021-07-08 17:55:29,000] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:55:29,001] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:29,006] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.096 seconds
[2021-07-08 17:55:59,668] {scheduler_job.py:182} INFO - Started process (PID=6327) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:59,670] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:55:59,671] {logging_mixin.py:104} INFO - [2021-07-08 17:55:59,671] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:59,753] {logging_mixin.py:104} INFO - [2021-07-08 17:55:59,752] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 121, in <module>
    hook = AwsLambdaHook(
NameError: name 'AwsLambdaHook' is not defined
[2021-07-08 17:55:59,753] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:55:59,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.097 seconds
[2021-07-08 17:56:09,786] {scheduler_job.py:182} INFO - Started process (PID=6359) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:09,787] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:56:09,788] {logging_mixin.py:104} INFO - [2021-07-08 17:56:09,788] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:09,878] {logging_mixin.py:104} INFO - [2021-07-08 17:56:09,878] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 130, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:56:09,879] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:09,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.102 seconds
[2021-07-08 17:56:12,464] {scheduler_job.py:182} INFO - Started process (PID=6371) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:12,467] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:56:12,468] {logging_mixin.py:104} INFO - [2021-07-08 17:56:12,467] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:12,577] {logging_mixin.py:104} INFO - [2021-07-08 17:56:12,576] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:56:12,577] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:12,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 17:56:43,170] {scheduler_job.py:182} INFO - Started process (PID=6434) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:43,171] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:56:43,172] {logging_mixin.py:104} INFO - [2021-07-08 17:56:43,172] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:43,277] {logging_mixin.py:104} INFO - [2021-07-08 17:56:43,276] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:56:43,277] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:56:43,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 17:57:13,992] {scheduler_job.py:182} INFO - Started process (PID=6499) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:13,993] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:57:13,994] {logging_mixin.py:104} INFO - [2021-07-08 17:57:13,994] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:14,073] {logging_mixin.py:104} INFO - [2021-07-08 17:57:14,073] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:57:14,074] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:14,078] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.091 seconds
[2021-07-08 17:57:16,893] {scheduler_job.py:182} INFO - Started process (PID=6500) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:16,893] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:57:16,894] {logging_mixin.py:104} INFO - [2021-07-08 17:57:16,894] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:16,973] {logging_mixin.py:104} INFO - [2021-07-08 17:57:16,973] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:57:16,974] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:16,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.087 seconds
[2021-07-08 17:57:47,452] {scheduler_job.py:182} INFO - Started process (PID=6563) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:47,453] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:57:47,454] {logging_mixin.py:104} INFO - [2021-07-08 17:57:47,454] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:47,533] {logging_mixin.py:104} INFO - [2021-07-08 17:57:47,533] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:57:47,534] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:57:47,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.088 seconds
[2021-07-08 17:58:17,951] {scheduler_job.py:182} INFO - Started process (PID=6616) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:17,953] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:58:17,953] {logging_mixin.py:104} INFO - [2021-07-08 17:58:17,953] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:18,037] {logging_mixin.py:104} INFO - [2021-07-08 17:58:18,037] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:58:18,038] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:18,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.093 seconds
[2021-07-08 17:58:48,135] {scheduler_job.py:182} INFO - Started process (PID=6681) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:48,137] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:58:48,138] {logging_mixin.py:104} INFO - [2021-07-08 17:58:48,138] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:48,272] {logging_mixin.py:104} INFO - [2021-07-08 17:58:48,271] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:58:48,272] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:58:48,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-07-08 17:59:19,078] {scheduler_job.py:182} INFO - Started process (PID=6745) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:19,079] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:59:19,079] {logging_mixin.py:104} INFO - [2021-07-08 17:59:19,079] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:19,179] {logging_mixin.py:104} INFO - [2021-07-08 17:59:19,179] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:59:19,180] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:19,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 17:59:28,124] {scheduler_job.py:182} INFO - Started process (PID=6746) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:28,125] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:59:28,126] {logging_mixin.py:104} INFO - [2021-07-08 17:59:28,126] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:28,128] {logging_mixin.py:104} INFO - [2021-07-08 17:59:28,127] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 8
    from airflow.providers.amazon.aws.hooks.lambda import AwsLambdaHook
                                                 ^
SyntaxError: invalid syntax
[2021-07-08 17:59:28,128] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:28,142] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.021 seconds
[2021-07-08 17:59:37,472] {scheduler_job.py:182} INFO - Started process (PID=6765) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:37,473] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 17:59:37,474] {logging_mixin.py:104} INFO - [2021-07-08 17:59:37,474] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:37,575] {logging_mixin.py:104} INFO - [2021-07-08 17:59:37,574] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 17:59:37,576] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 17:59:37,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 18:00:08,429] {scheduler_job.py:182} INFO - Started process (PID=6828) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:08,431] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:00:08,432] {logging_mixin.py:104} INFO - [2021-07-08 18:00:08,432] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:08,551] {logging_mixin.py:104} INFO - [2021-07-08 18:00:08,551] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 18:00:08,552] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:08,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 18:00:39,515] {scheduler_job.py:182} INFO - Started process (PID=6891) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:39,516] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:00:39,516] {logging_mixin.py:104} INFO - [2021-07-08 18:00:39,516] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:39,608] {logging_mixin.py:104} INFO - [2021-07-08 18:00:39,608] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 129, in <module>
    config=None)
TypeError: __init__() missing 1 required positional argument: 'function_name'
[2021-07-08 18:00:39,608] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:39,613] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.100 seconds
[2021-07-08 18:00:43,975] {scheduler_job.py:182} INFO - Started process (PID=6901) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:43,976] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:00:43,976] {logging_mixin.py:104} INFO - [2021-07-08 18:00:43,976] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:44,082] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:44,386] {logging_mixin.py:104} INFO - [2021-07-08 18:00:44,386] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 18:00:44,397] {logging_mixin.py:104} INFO - [2021-07-08 18:00:44,397] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 18:00:44,409] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.437 seconds
[2021-07-08 18:00:48,019] {scheduler_job.py:182} INFO - Started process (PID=6917) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:48,020] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:00:48,021] {logging_mixin.py:104} INFO - [2021-07-08 18:00:48,021] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:48,023] {logging_mixin.py:104} INFO - [2021-07-08 18:00:48,023] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124
    python_callable=lambda,
                          ^
SyntaxError: invalid syntax
[2021-07-08 18:00:48,024] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:48,037] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.020 seconds
[2021-07-08 18:00:52,043] {scheduler_job.py:182} INFO - Started process (PID=6928) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:52,045] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:00:52,046] {logging_mixin.py:104} INFO - [2021-07-08 18:00:52,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:52,146] {logging_mixin.py:104} INFO - [2021-07-08 18:00:52,146] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:00:52,147] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:00:52,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 18:01:22,641] {scheduler_job.py:182} INFO - Started process (PID=6981) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:22,642] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:01:22,643] {logging_mixin.py:104} INFO - [2021-07-08 18:01:22,643] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:22,735] {logging_mixin.py:104} INFO - [2021-07-08 18:01:22,734] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:01:22,735] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:22,739] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.100 seconds
[2021-07-08 18:01:53,243] {scheduler_job.py:182} INFO - Started process (PID=7044) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:53,244] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:01:53,245] {logging_mixin.py:104} INFO - [2021-07-08 18:01:53,244] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:53,329] {logging_mixin.py:104} INFO - [2021-07-08 18:01:53,329] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:01:53,330] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:01:53,334] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.093 seconds
[2021-07-08 18:02:23,891] {scheduler_job.py:182} INFO - Started process (PID=7107) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:23,893] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:02:23,893] {logging_mixin.py:104} INFO - [2021-07-08 18:02:23,893] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:24,020] {logging_mixin.py:104} INFO - [2021-07-08 18:02:24,019] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:02:24,020] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:24,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 18:02:54,392] {scheduler_job.py:182} INFO - Started process (PID=7159) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:54,393] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:02:54,394] {logging_mixin.py:104} INFO - [2021-07-08 18:02:54,394] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:54,539] {logging_mixin.py:104} INFO - [2021-07-08 18:02:54,538] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:02:54,539] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:02:54,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 18:03:25,354] {scheduler_job.py:182} INFO - Started process (PID=7222) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:25,357] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:03:25,358] {logging_mixin.py:104} INFO - [2021-07-08 18:03:25,358] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:25,649] {logging_mixin.py:104} INFO - [2021-07-08 18:03:25,647] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:03:25,650] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:25,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.311 seconds
[2021-07-08 18:03:55,891] {scheduler_job.py:182} INFO - Started process (PID=7274) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:55,894] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:03:55,895] {logging_mixin.py:104} INFO - [2021-07-08 18:03:55,895] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:56,028] {logging_mixin.py:104} INFO - [2021-07-08 18:03:56,027] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:03:56,029] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:03:56,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-07-08 18:04:26,772] {scheduler_job.py:182} INFO - Started process (PID=7337) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:26,773] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:04:26,774] {logging_mixin.py:104} INFO - [2021-07-08 18:04:26,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:26,872] {logging_mixin.py:104} INFO - [2021-07-08 18:04:26,871] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:04:26,872] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:26,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 18:04:57,757] {scheduler_job.py:182} INFO - Started process (PID=7390) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:57,758] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:04:57,758] {logging_mixin.py:104} INFO - [2021-07-08 18:04:57,758] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:57,892] {logging_mixin.py:104} INFO - [2021-07-08 18:04:57,891] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:04:57,892] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:04:57,899] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 18:05:28,076] {scheduler_job.py:182} INFO - Started process (PID=7454) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:28,079] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:05:28,080] {logging_mixin.py:104} INFO - [2021-07-08 18:05:28,080] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:28,385] {logging_mixin.py:104} INFO - [2021-07-08 18:05:28,383] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:05:28,385] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:28,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.325 seconds
[2021-07-08 18:05:58,845] {scheduler_job.py:182} INFO - Started process (PID=7508) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:58,847] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:05:58,847] {logging_mixin.py:104} INFO - [2021-07-08 18:05:58,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:58,951] {logging_mixin.py:104} INFO - [2021-07-08 18:05:58,951] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:05:58,951] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:05:58,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 18:06:04,904] {scheduler_job.py:182} INFO - Started process (PID=7520) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:04,906] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:06:04,907] {logging_mixin.py:104} INFO - [2021-07-08 18:06:04,907] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:05,019] {logging_mixin.py:104} INFO - [2021-07-08 18:06:05,018] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:06:05,020] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:05,027] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 18:06:35,097] {scheduler_job.py:182} INFO - Started process (PID=7573) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:35,099] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:06:35,100] {logging_mixin.py:104} INFO - [2021-07-08 18:06:35,099] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:35,196] {logging_mixin.py:104} INFO - [2021-07-08 18:06:35,195] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:06:35,196] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:06:35,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 18:07:06,047] {scheduler_job.py:182} INFO - Started process (PID=7636) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:06,049] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:07:06,050] {logging_mixin.py:104} INFO - [2021-07-08 18:07:06,049] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:06,146] {logging_mixin.py:104} INFO - [2021-07-08 18:07:06,145] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:07:06,146] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:06,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:07:36,895] {scheduler_job.py:182} INFO - Started process (PID=7699) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:36,897] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:07:36,898] {logging_mixin.py:104} INFO - [2021-07-08 18:07:36,897] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:36,992] {logging_mixin.py:104} INFO - [2021-07-08 18:07:36,992] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:07:36,993] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:07:36,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:08:07,398] {scheduler_job.py:182} INFO - Started process (PID=7752) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:07,399] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:08:07,399] {logging_mixin.py:104} INFO - [2021-07-08 18:08:07,399] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:07,498] {logging_mixin.py:104} INFO - [2021-07-08 18:08:07,497] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:08:07,498] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:07,503] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:08:38,292] {scheduler_job.py:182} INFO - Started process (PID=7817) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:38,293] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:08:38,294] {logging_mixin.py:104} INFO - [2021-07-08 18:08:38,294] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:38,391] {logging_mixin.py:104} INFO - [2021-07-08 18:08:38,390] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:08:38,391] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:08:38,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 18:09:08,438] {scheduler_job.py:182} INFO - Started process (PID=7871) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:08,439] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:09:08,440] {logging_mixin.py:104} INFO - [2021-07-08 18:09:08,440] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:08,532] {logging_mixin.py:104} INFO - [2021-07-08 18:09:08,532] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:09:08,532] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:08,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 18:09:39,117] {scheduler_job.py:182} INFO - Started process (PID=7935) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:39,119] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:09:39,120] {logging_mixin.py:104} INFO - [2021-07-08 18:09:39,119] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:39,220] {logging_mixin.py:104} INFO - [2021-07-08 18:09:39,220] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:09:39,221] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:09:39,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 18:10:10,020] {scheduler_job.py:182} INFO - Started process (PID=7998) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:10,022] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:10:10,023] {logging_mixin.py:104} INFO - [2021-07-08 18:10:10,023] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:10,119] {logging_mixin.py:104} INFO - [2021-07-08 18:10:10,119] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:10:10,120] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:10,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 18:10:40,739] {scheduler_job.py:182} INFO - Started process (PID=8051) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:40,740] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:10:40,740] {logging_mixin.py:104} INFO - [2021-07-08 18:10:40,740] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:40,837] {logging_mixin.py:104} INFO - [2021-07-08 18:10:40,837] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:10:40,838] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:10:40,842] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 18:11:11,813] {scheduler_job.py:182} INFO - Started process (PID=8116) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:11,815] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:11:11,816] {logging_mixin.py:104} INFO - [2021-07-08 18:11:11,815] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:11,925] {logging_mixin.py:104} INFO - [2021-07-08 18:11:11,925] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:11:11,925] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:11,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 18:11:42,278] {scheduler_job.py:182} INFO - Started process (PID=8180) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:42,279] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:11:42,280] {logging_mixin.py:104} INFO - [2021-07-08 18:11:42,279] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:42,374] {logging_mixin.py:104} INFO - [2021-07-08 18:11:42,374] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:11:42,375] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:11:42,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 18:12:13,027] {scheduler_job.py:182} INFO - Started process (PID=8233) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:13,029] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:12:13,030] {logging_mixin.py:104} INFO - [2021-07-08 18:12:13,030] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:13,148] {logging_mixin.py:104} INFO - [2021-07-08 18:12:13,147] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:12:13,148] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:13,153] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 18:12:43,704] {scheduler_job.py:182} INFO - Started process (PID=8299) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:43,705] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:12:43,705] {logging_mixin.py:104} INFO - [2021-07-08 18:12:43,705] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:43,808] {logging_mixin.py:104} INFO - [2021-07-08 18:12:43,808] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:12:43,808] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:12:43,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 18:13:14,608] {scheduler_job.py:182} INFO - Started process (PID=8366) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:14,610] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:13:14,610] {logging_mixin.py:104} INFO - [2021-07-08 18:13:14,610] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:14,701] {logging_mixin.py:104} INFO - [2021-07-08 18:13:14,701] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:13:14,702] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:14,707] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.101 seconds
[2021-07-08 18:13:45,378] {scheduler_job.py:182} INFO - Started process (PID=8420) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:45,380] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:13:45,381] {logging_mixin.py:104} INFO - [2021-07-08 18:13:45,381] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:45,476] {logging_mixin.py:104} INFO - [2021-07-08 18:13:45,475] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:13:45,476] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:13:45,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 18:14:16,062] {scheduler_job.py:182} INFO - Started process (PID=8485) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:16,063] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:14:16,064] {logging_mixin.py:104} INFO - [2021-07-08 18:14:16,064] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:16,157] {logging_mixin.py:104} INFO - [2021-07-08 18:14:16,156] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:14:16,157] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:16,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 18:14:46,758] {scheduler_job.py:182} INFO - Started process (PID=8548) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:46,759] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:14:46,760] {logging_mixin.py:104} INFO - [2021-07-08 18:14:46,759] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:46,858] {logging_mixin.py:104} INFO - [2021-07-08 18:14:46,858] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:14:46,859] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:14:46,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 18:15:17,501] {scheduler_job.py:182} INFO - Started process (PID=8600) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:17,503] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:15:17,503] {logging_mixin.py:104} INFO - [2021-07-08 18:15:17,503] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:17,596] {logging_mixin.py:104} INFO - [2021-07-08 18:15:17,594] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:15:17,596] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:17,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.102 seconds
[2021-07-08 18:15:48,327] {scheduler_job.py:182} INFO - Started process (PID=8663) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:48,329] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:15:48,329] {logging_mixin.py:104} INFO - [2021-07-08 18:15:48,329] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:48,425] {logging_mixin.py:104} INFO - [2021-07-08 18:15:48,424] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:15:48,425] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:15:48,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 18:16:18,994] {scheduler_job.py:182} INFO - Started process (PID=8716) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:18,995] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:16:18,997] {logging_mixin.py:104} INFO - [2021-07-08 18:16:18,996] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:19,105] {logging_mixin.py:104} INFO - [2021-07-08 18:16:19,104] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:16:19,105] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:19,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 18:16:49,409] {scheduler_job.py:182} INFO - Started process (PID=8781) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:49,410] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:16:49,411] {logging_mixin.py:104} INFO - [2021-07-08 18:16:49,411] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:49,511] {logging_mixin.py:104} INFO - [2021-07-08 18:16:49,510] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:16:49,511] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:16:49,516] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 18:17:20,375] {scheduler_job.py:182} INFO - Started process (PID=8845) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:20,376] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:17:20,378] {logging_mixin.py:104} INFO - [2021-07-08 18:17:20,377] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:20,470] {logging_mixin.py:104} INFO - [2021-07-08 18:17:20,469] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:17:20,470] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:20,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:17:50,522] {scheduler_job.py:182} INFO - Started process (PID=8898) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:50,524] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:17:50,525] {logging_mixin.py:104} INFO - [2021-07-08 18:17:50,525] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:50,619] {logging_mixin.py:104} INFO - [2021-07-08 18:17:50,618] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:17:50,619] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:17:50,624] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:18:20,826] {scheduler_job.py:182} INFO - Started process (PID=8961) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:20,828] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:18:20,829] {logging_mixin.py:104} INFO - [2021-07-08 18:18:20,829] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:20,922] {logging_mixin.py:104} INFO - [2021-07-08 18:18:20,922] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:18:20,923] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:20,927] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 18:18:51,647] {scheduler_job.py:182} INFO - Started process (PID=9024) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:51,649] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:18:51,649] {logging_mixin.py:104} INFO - [2021-07-08 18:18:51,649] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:51,752] {logging_mixin.py:104} INFO - [2021-07-08 18:18:51,751] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:18:51,752] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:18:51,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 18:19:22,262] {scheduler_job.py:182} INFO - Started process (PID=9077) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:22,263] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:19:22,264] {logging_mixin.py:104} INFO - [2021-07-08 18:19:22,264] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:22,367] {logging_mixin.py:104} INFO - [2021-07-08 18:19:22,367] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:19:22,368] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:22,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 18:19:53,200] {scheduler_job.py:182} INFO - Started process (PID=9141) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:53,202] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:19:53,203] {logging_mixin.py:104} INFO - [2021-07-08 18:19:53,202] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:53,337] {logging_mixin.py:104} INFO - [2021-07-08 18:19:53,336] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:19:53,337] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:19:53,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 18:20:23,816] {scheduler_job.py:182} INFO - Started process (PID=9203) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:23,818] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:20:23,819] {logging_mixin.py:104} INFO - [2021-07-08 18:20:23,819] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:23,924] {logging_mixin.py:104} INFO - [2021-07-08 18:20:23,923] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:20:23,924] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:23,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 18:20:54,794] {scheduler_job.py:182} INFO - Started process (PID=9257) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:54,796] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:20:54,797] {logging_mixin.py:104} INFO - [2021-07-08 18:20:54,797] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:54,927] {logging_mixin.py:104} INFO - [2021-07-08 18:20:54,926] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:20:54,927] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:20:54,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 18:21:25,774] {scheduler_job.py:182} INFO - Started process (PID=9320) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:25,775] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:21:25,775] {logging_mixin.py:104} INFO - [2021-07-08 18:21:25,775] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:25,870] {logging_mixin.py:104} INFO - [2021-07-08 18:21:25,869] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:21:25,870] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:25,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 18:21:56,374] {scheduler_job.py:182} INFO - Started process (PID=9383) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:56,375] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:21:56,375] {logging_mixin.py:104} INFO - [2021-07-08 18:21:56,375] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:56,468] {logging_mixin.py:104} INFO - [2021-07-08 18:21:56,467] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:21:56,468] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:21:56,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.102 seconds
[2021-07-08 18:22:27,395] {scheduler_job.py:182} INFO - Started process (PID=9438) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:27,396] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:22:27,397] {logging_mixin.py:104} INFO - [2021-07-08 18:22:27,396] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:27,512] {logging_mixin.py:104} INFO - [2021-07-08 18:22:27,511] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:22:27,512] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:27,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 18:22:58,402] {scheduler_job.py:182} INFO - Started process (PID=9502) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:58,405] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:22:58,405] {logging_mixin.py:104} INFO - [2021-07-08 18:22:58,405] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:58,538] {logging_mixin.py:104} INFO - [2021-07-08 18:22:58,538] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:22:58,539] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:22:58,544] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 18:23:29,312] {scheduler_job.py:182} INFO - Started process (PID=9556) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:23:29,314] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:23:29,315] {logging_mixin.py:104} INFO - [2021-07-08 18:23:29,315] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:23:29,417] {logging_mixin.py:104} INFO - [2021-07-08 18:23:29,416] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:23:29,417] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:23:29,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 18:24:00,149] {scheduler_job.py:182} INFO - Started process (PID=9619) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:00,150] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:24:00,151] {logging_mixin.py:104} INFO - [2021-07-08 18:24:00,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:00,258] {logging_mixin.py:104} INFO - [2021-07-08 18:24:00,258] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:24:00,258] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:00,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 18:24:30,811] {scheduler_job.py:182} INFO - Started process (PID=9683) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:30,813] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:24:30,814] {logging_mixin.py:104} INFO - [2021-07-08 18:24:30,813] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:30,913] {logging_mixin.py:104} INFO - [2021-07-08 18:24:30,912] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:24:30,913] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:24:30,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 18:25:01,931] {scheduler_job.py:182} INFO - Started process (PID=9737) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:01,932] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:25:01,933] {logging_mixin.py:104} INFO - [2021-07-08 18:25:01,933] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:02,031] {logging_mixin.py:104} INFO - [2021-07-08 18:25:02,030] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:25:02,031] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:02,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 18:25:32,101] {scheduler_job.py:182} INFO - Started process (PID=9801) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:32,103] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:25:32,104] {logging_mixin.py:104} INFO - [2021-07-08 18:25:32,103] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:32,206] {logging_mixin.py:104} INFO - [2021-07-08 18:25:32,205] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:25:32,206] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:25:32,212] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 18:26:02,948] {scheduler_job.py:182} INFO - Started process (PID=9864) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:02,950] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:26:02,951] {logging_mixin.py:104} INFO - [2021-07-08 18:26:02,950] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:03,055] {logging_mixin.py:104} INFO - [2021-07-08 18:26:03,055] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:26:03,056] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:03,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 18:26:33,706] {scheduler_job.py:182} INFO - Started process (PID=9917) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:33,711] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:26:33,712] {logging_mixin.py:104} INFO - [2021-07-08 18:26:33,712] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:33,814] {logging_mixin.py:104} INFO - [2021-07-08 18:26:33,813] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:26:33,814] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:26:33,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 18:27:04,380] {scheduler_job.py:182} INFO - Started process (PID=9982) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:04,381] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:27:04,382] {logging_mixin.py:104} INFO - [2021-07-08 18:27:04,382] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:04,487] {logging_mixin.py:104} INFO - [2021-07-08 18:27:04,486] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:27:04,487] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:04,493] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 18:27:35,187] {scheduler_job.py:182} INFO - Started process (PID=10048) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:35,189] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:27:35,189] {logging_mixin.py:104} INFO - [2021-07-08 18:27:35,189] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:35,298] {logging_mixin.py:104} INFO - [2021-07-08 18:27:35,297] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:27:35,299] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:27:35,306] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 18:28:05,937] {scheduler_job.py:182} INFO - Started process (PID=10103) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:05,939] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:28:05,940] {logging_mixin.py:104} INFO - [2021-07-08 18:28:05,940] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:06,045] {logging_mixin.py:104} INFO - [2021-07-08 18:28:06,044] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:28:06,045] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:06,052] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 18:28:36,822] {scheduler_job.py:182} INFO - Started process (PID=10167) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:36,824] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:28:36,824] {logging_mixin.py:104} INFO - [2021-07-08 18:28:36,824] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:36,924] {logging_mixin.py:104} INFO - [2021-07-08 18:28:36,924] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:28:36,925] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:28:36,930] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 18:29:07,551] {scheduler_job.py:182} INFO - Started process (PID=10221) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:07,553] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:29:07,554] {logging_mixin.py:104} INFO - [2021-07-08 18:29:07,554] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:07,669] {logging_mixin.py:104} INFO - [2021-07-08 18:29:07,669] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:29:07,669] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:07,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 18:29:38,407] {scheduler_job.py:182} INFO - Started process (PID=10284) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:38,409] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:29:38,410] {logging_mixin.py:104} INFO - [2021-07-08 18:29:38,409] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:38,506] {logging_mixin.py:104} INFO - [2021-07-08 18:29:38,505] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:29:38,506] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:29:38,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 18:30:09,060] {scheduler_job.py:182} INFO - Started process (PID=10347) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:09,062] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:30:09,063] {logging_mixin.py:104} INFO - [2021-07-08 18:30:09,063] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:09,175] {logging_mixin.py:104} INFO - [2021-07-08 18:30:09,174] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:30:09,175] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:09,181] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 18:30:39,955] {scheduler_job.py:182} INFO - Started process (PID=10401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:39,957] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:30:39,958] {logging_mixin.py:104} INFO - [2021-07-08 18:30:39,958] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:40,055] {logging_mixin.py:104} INFO - [2021-07-08 18:30:40,054] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:30:40,055] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:30:40,061] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 18:31:10,768] {scheduler_job.py:182} INFO - Started process (PID=10465) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:10,769] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:31:10,771] {logging_mixin.py:104} INFO - [2021-07-08 18:31:10,770] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:10,869] {logging_mixin.py:104} INFO - [2021-07-08 18:31:10,869] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:31:10,870] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:10,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 18:31:41,511] {scheduler_job.py:182} INFO - Started process (PID=10531) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:41,513] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:31:41,514] {logging_mixin.py:104} INFO - [2021-07-08 18:31:41,514] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:41,614] {logging_mixin.py:104} INFO - [2021-07-08 18:31:41,614] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:31:41,615] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:31:41,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 18:32:12,317] {scheduler_job.py:182} INFO - Started process (PID=10585) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:12,319] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:32:12,320] {logging_mixin.py:104} INFO - [2021-07-08 18:32:12,319] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:12,441] {logging_mixin.py:104} INFO - [2021-07-08 18:32:12,440] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:32:12,441] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:12,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 18:32:43,380] {scheduler_job.py:182} INFO - Started process (PID=10650) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:43,382] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:32:43,383] {logging_mixin.py:104} INFO - [2021-07-08 18:32:43,383] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:43,482] {logging_mixin.py:104} INFO - [2021-07-08 18:32:43,481] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:32:43,482] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:32:43,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 18:33:13,538] {scheduler_job.py:182} INFO - Started process (PID=10713) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:13,539] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:33:13,540] {logging_mixin.py:104} INFO - [2021-07-08 18:33:13,540] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:13,645] {logging_mixin.py:104} INFO - [2021-07-08 18:33:13,645] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:33:13,646] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:13,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 18:33:44,343] {scheduler_job.py:182} INFO - Started process (PID=10766) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:44,345] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:33:44,345] {logging_mixin.py:104} INFO - [2021-07-08 18:33:44,345] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:44,454] {logging_mixin.py:104} INFO - [2021-07-08 18:33:44,454] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:33:44,455] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:33:44,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 18:34:15,136] {scheduler_job.py:182} INFO - Started process (PID=10831) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:15,137] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:34:15,138] {logging_mixin.py:104} INFO - [2021-07-08 18:34:15,138] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:15,261] {logging_mixin.py:104} INFO - [2021-07-08 18:34:15,260] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:34:15,261] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:15,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 18:34:46,038] {scheduler_job.py:182} INFO - Started process (PID=10896) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:46,039] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:34:46,040] {logging_mixin.py:104} INFO - [2021-07-08 18:34:46,039] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:46,171] {logging_mixin.py:104} INFO - [2021-07-08 18:34:46,170] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:34:46,171] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:34:46,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-07-08 18:35:16,884] {scheduler_job.py:182} INFO - Started process (PID=10949) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:16,886] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:35:16,887] {logging_mixin.py:104} INFO - [2021-07-08 18:35:16,886] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:17,003] {logging_mixin.py:104} INFO - [2021-07-08 18:35:17,003] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:35:17,004] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:17,009] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 18:35:47,587] {scheduler_job.py:182} INFO - Started process (PID=11012) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:47,589] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:35:47,589] {logging_mixin.py:104} INFO - [2021-07-08 18:35:47,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:47,683] {logging_mixin.py:104} INFO - [2021-07-08 18:35:47,682] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:35:47,683] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:35:47,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 18:36:18,122] {scheduler_job.py:182} INFO - Started process (PID=11074) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:18,125] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:36:18,126] {logging_mixin.py:104} INFO - [2021-07-08 18:36:18,126] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:18,241] {logging_mixin.py:104} INFO - [2021-07-08 18:36:18,240] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:36:18,241] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:18,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 18:36:48,296] {scheduler_job.py:182} INFO - Started process (PID=11128) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:48,297] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:36:48,298] {logging_mixin.py:104} INFO - [2021-07-08 18:36:48,298] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:48,401] {logging_mixin.py:104} INFO - [2021-07-08 18:36:48,400] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:36:48,402] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:36:48,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 18:37:19,102] {scheduler_job.py:182} INFO - Started process (PID=11190) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:19,103] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:37:19,103] {logging_mixin.py:104} INFO - [2021-07-08 18:37:19,103] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:19,200] {logging_mixin.py:104} INFO - [2021-07-08 18:37:19,199] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:37:19,200] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:19,206] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:37:49,517] {scheduler_job.py:182} INFO - Started process (PID=11244) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:49,519] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:37:49,520] {logging_mixin.py:104} INFO - [2021-07-08 18:37:49,520] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:49,615] {logging_mixin.py:104} INFO - [2021-07-08 18:37:49,614] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:37:49,616] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:37:49,620] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 18:38:20,455] {scheduler_job.py:182} INFO - Started process (PID=11308) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:20,456] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:38:20,457] {logging_mixin.py:104} INFO - [2021-07-08 18:38:20,457] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:20,554] {logging_mixin.py:104} INFO - [2021-07-08 18:38:20,553] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:38:20,554] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:20,559] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.106 seconds
[2021-07-08 18:38:50,970] {scheduler_job.py:182} INFO - Started process (PID=11371) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:50,972] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:38:50,973] {logging_mixin.py:104} INFO - [2021-07-08 18:38:50,973] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:51,070] {logging_mixin.py:104} INFO - [2021-07-08 18:38:51,069] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:38:51,071] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:38:51,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 18:39:21,753] {scheduler_job.py:182} INFO - Started process (PID=11424) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:21,759] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:39:21,760] {logging_mixin.py:104} INFO - [2021-07-08 18:39:21,760] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:21,860] {logging_mixin.py:104} INFO - [2021-07-08 18:39:21,859] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:39:21,860] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:21,865] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 18:39:52,352] {scheduler_job.py:182} INFO - Started process (PID=11487) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:52,353] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:39:52,353] {logging_mixin.py:104} INFO - [2021-07-08 18:39:52,353] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:52,452] {logging_mixin.py:104} INFO - [2021-07-08 18:39:52,452] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:39:52,453] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:39:52,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 18:40:23,181] {scheduler_job.py:182} INFO - Started process (PID=11551) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:23,183] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:40:23,184] {logging_mixin.py:104} INFO - [2021-07-08 18:40:23,184] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:23,292] {logging_mixin.py:104} INFO - [2021-07-08 18:40:23,291] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:40:23,292] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:23,300] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 18:40:54,009] {scheduler_job.py:182} INFO - Started process (PID=11604) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:54,011] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:40:54,012] {logging_mixin.py:104} INFO - [2021-07-08 18:40:54,011] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:54,173] {logging_mixin.py:104} INFO - [2021-07-08 18:40:54,172] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:40:54,174] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:40:54,183] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.179 seconds
[2021-07-08 18:41:25,022] {scheduler_job.py:182} INFO - Started process (PID=11668) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:25,025] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:41:25,026] {logging_mixin.py:104} INFO - [2021-07-08 18:41:25,026] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:25,210] {logging_mixin.py:104} INFO - [2021-07-08 18:41:25,208] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:41:25,211] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:25,222] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.204 seconds
[2021-07-08 18:41:55,395] {scheduler_job.py:182} INFO - Started process (PID=11721) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:55,397] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:41:55,399] {logging_mixin.py:104} INFO - [2021-07-08 18:41:55,399] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:55,582] {logging_mixin.py:104} INFO - [2021-07-08 18:41:55,581] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:41:55,582] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:41:55,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.200 seconds
[2021-07-08 18:42:25,961] {scheduler_job.py:182} INFO - Started process (PID=11774) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:25,964] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:42:25,965] {logging_mixin.py:104} INFO - [2021-07-08 18:42:25,964] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:26,174] {logging_mixin.py:104} INFO - [2021-07-08 18:42:26,172] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:42:26,174] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:26,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-07-08 18:42:56,565] {scheduler_job.py:182} INFO - Started process (PID=11838) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:56,567] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:42:56,568] {logging_mixin.py:104} INFO - [2021-07-08 18:42:56,568] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:56,743] {logging_mixin.py:104} INFO - [2021-07-08 18:42:56,743] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:42:56,744] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:42:56,751] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 18:43:26,911] {scheduler_job.py:182} INFO - Started process (PID=11893) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:26,913] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:43:26,915] {logging_mixin.py:104} INFO - [2021-07-08 18:43:26,914] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:27,094] {logging_mixin.py:104} INFO - [2021-07-08 18:43:27,094] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:43:27,095] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:27,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 18:43:57,536] {scheduler_job.py:182} INFO - Started process (PID=11946) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:57,542] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:43:57,543] {logging_mixin.py:104} INFO - [2021-07-08 18:43:57,543] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:57,745] {logging_mixin.py:104} INFO - [2021-07-08 18:43:57,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:43:57,745] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:43:57,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-07-08 18:44:28,093] {scheduler_job.py:182} INFO - Started process (PID=12008) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:28,099] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:44:28,100] {logging_mixin.py:104} INFO - [2021-07-08 18:44:28,100] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:28,268] {logging_mixin.py:104} INFO - [2021-07-08 18:44:28,268] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:44:28,269] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:28,279] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.189 seconds
[2021-07-08 18:44:58,341] {scheduler_job.py:182} INFO - Started process (PID=12061) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:58,343] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:44:58,344] {logging_mixin.py:104} INFO - [2021-07-08 18:44:58,344] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:58,516] {logging_mixin.py:104} INFO - [2021-07-08 18:44:58,516] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:44:58,517] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:44:58,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.191 seconds
[2021-07-08 18:45:29,069] {scheduler_job.py:182} INFO - Started process (PID=12125) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:45:29,072] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:45:29,073] {logging_mixin.py:104} INFO - [2021-07-08 18:45:29,073] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:45:29,253] {logging_mixin.py:104} INFO - [2021-07-08 18:45:29,251] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:45:29,253] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:45:29,261] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 18:45:59,995] {scheduler_job.py:182} INFO - Started process (PID=12179) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:45:59,997] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:45:59,997] {logging_mixin.py:104} INFO - [2021-07-08 18:45:59,997] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:46:00,162] {logging_mixin.py:104} INFO - [2021-07-08 18:46:00,161] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:46:00,163] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:46:00,171] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.180 seconds
[2021-07-08 18:46:31,035] {scheduler_job.py:182} INFO - Started process (PID=12232) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:46:31,038] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:46:31,039] {logging_mixin.py:104} INFO - [2021-07-08 18:46:31,039] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:46:31,206] {logging_mixin.py:104} INFO - [2021-07-08 18:46:31,205] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:46:31,206] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:46:31,214] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.185 seconds
[2021-07-08 18:47:01,963] {scheduler_job.py:182} INFO - Started process (PID=12297) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:01,965] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:47:01,966] {logging_mixin.py:104} INFO - [2021-07-08 18:47:01,965] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:02,139] {logging_mixin.py:104} INFO - [2021-07-08 18:47:02,138] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:47:02,139] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:02,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-07-08 18:47:32,465] {scheduler_job.py:182} INFO - Started process (PID=12350) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:32,468] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:47:32,469] {logging_mixin.py:104} INFO - [2021-07-08 18:47:32,469] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:32,643] {logging_mixin.py:104} INFO - [2021-07-08 18:47:32,642] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:47:32,644] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:47:32,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 18:48:02,685] {scheduler_job.py:182} INFO - Started process (PID=12404) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:02,691] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:48:02,692] {logging_mixin.py:104} INFO - [2021-07-08 18:48:02,692] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:02,859] {logging_mixin.py:104} INFO - [2021-07-08 18:48:02,858] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:48:02,859] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:02,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.186 seconds
[2021-07-08 18:48:33,163] {scheduler_job.py:182} INFO - Started process (PID=12466) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:33,164] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:48:33,165] {logging_mixin.py:104} INFO - [2021-07-08 18:48:33,165] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:33,344] {logging_mixin.py:104} INFO - [2021-07-08 18:48:33,344] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:48:33,345] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:48:33,354] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.195 seconds
[2021-07-08 18:49:03,892] {scheduler_job.py:182} INFO - Started process (PID=12521) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:03,893] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:49:03,895] {logging_mixin.py:104} INFO - [2021-07-08 18:49:03,894] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:04,074] {logging_mixin.py:104} INFO - [2021-07-08 18:49:04,072] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:49:04,075] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:04,084] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.197 seconds
[2021-07-08 18:49:34,778] {scheduler_job.py:182} INFO - Started process (PID=12584) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:34,780] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:49:34,781] {logging_mixin.py:104} INFO - [2021-07-08 18:49:34,781] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:34,952] {logging_mixin.py:104} INFO - [2021-07-08 18:49:34,952] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:49:34,953] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:49:34,965] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.191 seconds
[2021-07-08 18:50:05,690] {scheduler_job.py:182} INFO - Started process (PID=12639) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:05,692] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:50:05,693] {logging_mixin.py:104} INFO - [2021-07-08 18:50:05,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:05,849] {logging_mixin.py:104} INFO - [2021-07-08 18:50:05,848] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:50:05,850] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:05,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.172 seconds
[2021-07-08 18:50:36,792] {scheduler_job.py:182} INFO - Started process (PID=12693) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:36,793] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:50:36,795] {logging_mixin.py:104} INFO - [2021-07-08 18:50:36,794] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:36,971] {logging_mixin.py:104} INFO - [2021-07-08 18:50:36,970] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:50:36,971] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:50:36,980] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 18:51:07,011] {scheduler_job.py:182} INFO - Started process (PID=12757) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:07,014] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:51:07,015] {logging_mixin.py:104} INFO - [2021-07-08 18:51:07,015] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:07,222] {logging_mixin.py:104} INFO - [2021-07-08 18:51:07,221] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:51:07,223] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:07,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-07-08 18:51:37,727] {scheduler_job.py:182} INFO - Started process (PID=12810) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:37,733] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:51:37,734] {logging_mixin.py:104} INFO - [2021-07-08 18:51:37,733] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:37,908] {logging_mixin.py:104} INFO - [2021-07-08 18:51:37,907] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:51:37,909] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:51:37,919] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 18:52:08,689] {scheduler_job.py:182} INFO - Started process (PID=12873) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:08,692] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:52:08,694] {logging_mixin.py:104} INFO - [2021-07-08 18:52:08,694] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:08,882] {logging_mixin.py:104} INFO - [2021-07-08 18:52:08,881] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:52:08,883] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:08,892] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.207 seconds
[2021-07-08 18:52:39,529] {scheduler_job.py:182} INFO - Started process (PID=12927) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:39,530] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:52:39,532] {logging_mixin.py:104} INFO - [2021-07-08 18:52:39,532] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:39,706] {logging_mixin.py:104} INFO - [2021-07-08 18:52:39,705] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:52:39,707] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:52:39,716] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.191 seconds
[2021-07-08 18:53:10,638] {scheduler_job.py:182} INFO - Started process (PID=12980) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:10,640] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:53:10,641] {logging_mixin.py:104} INFO - [2021-07-08 18:53:10,640] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:10,822] {logging_mixin.py:104} INFO - [2021-07-08 18:53:10,821] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:53:10,823] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:10,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.197 seconds
[2021-07-08 18:53:41,465] {scheduler_job.py:182} INFO - Started process (PID=13044) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:41,467] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:53:41,468] {logging_mixin.py:104} INFO - [2021-07-08 18:53:41,468] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:41,744] {logging_mixin.py:104} INFO - [2021-07-08 18:53:41,741] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:53:41,745] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:53:41,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.295 seconds
[2021-07-08 18:54:12,279] {scheduler_job.py:182} INFO - Started process (PID=13097) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:12,282] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:54:12,284] {logging_mixin.py:104} INFO - [2021-07-08 18:54:12,283] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:12,477] {logging_mixin.py:104} INFO - [2021-07-08 18:54:12,476] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:54:12,478] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:12,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.215 seconds
[2021-07-08 18:54:42,891] {scheduler_job.py:182} INFO - Started process (PID=13161) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:42,898] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:54:42,899] {logging_mixin.py:104} INFO - [2021-07-08 18:54:42,899] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:43,115] {logging_mixin.py:104} INFO - [2021-07-08 18:54:43,114] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:54:43,116] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:54:43,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.240 seconds
[2021-07-08 18:55:13,641] {scheduler_job.py:182} INFO - Started process (PID=13215) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:13,644] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:55:13,645] {logging_mixin.py:104} INFO - [2021-07-08 18:55:13,644] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:13,825] {logging_mixin.py:104} INFO - [2021-07-08 18:55:13,824] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:55:13,826] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:13,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.198 seconds
[2021-07-08 18:55:44,678] {scheduler_job.py:182} INFO - Started process (PID=13268) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:44,684] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:55:44,684] {logging_mixin.py:104} INFO - [2021-07-08 18:55:44,684] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:44,871] {logging_mixin.py:104} INFO - [2021-07-08 18:55:44,869] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:55:44,871] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:55:44,880] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.207 seconds
[2021-07-08 18:56:15,659] {scheduler_job.py:182} INFO - Started process (PID=13333) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:15,661] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:56:15,663] {logging_mixin.py:104} INFO - [2021-07-08 18:56:15,663] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:15,924] {logging_mixin.py:104} INFO - [2021-07-08 18:56:15,923] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:56:15,925] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:15,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.281 seconds
[2021-07-08 18:56:46,650] {scheduler_job.py:182} INFO - Started process (PID=13386) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:46,656] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:56:46,657] {logging_mixin.py:104} INFO - [2021-07-08 18:56:46,657] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:46,856] {logging_mixin.py:104} INFO - [2021-07-08 18:56:46,854] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:56:46,856] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:56:46,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.222 seconds
[2021-07-08 18:57:17,044] {scheduler_job.py:182} INFO - Started process (PID=13449) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:17,047] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:57:17,048] {logging_mixin.py:104} INFO - [2021-07-08 18:57:17,048] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:17,271] {logging_mixin.py:104} INFO - [2021-07-08 18:57:17,269] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:57:17,271] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:17,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.243 seconds
[2021-07-08 18:57:47,382] {scheduler_job.py:182} INFO - Started process (PID=13502) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:47,384] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:57:47,385] {logging_mixin.py:104} INFO - [2021-07-08 18:57:47,385] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:47,595] {logging_mixin.py:104} INFO - [2021-07-08 18:57:47,594] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:57:47,596] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:57:47,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.227 seconds
[2021-07-08 18:58:18,094] {scheduler_job.py:182} INFO - Started process (PID=13555) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:18,099] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:58:18,100] {logging_mixin.py:104} INFO - [2021-07-08 18:58:18,100] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:18,259] {logging_mixin.py:104} INFO - [2021-07-08 18:58:18,258] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:58:18,260] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:18,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.178 seconds
[2021-07-08 18:58:49,027] {scheduler_job.py:182} INFO - Started process (PID=13618) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:49,028] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:58:49,029] {logging_mixin.py:104} INFO - [2021-07-08 18:58:49,029] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:49,222] {logging_mixin.py:104} INFO - [2021-07-08 18:58:49,220] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:58:49,223] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:58:49,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.207 seconds
[2021-07-08 18:59:20,008] {scheduler_job.py:182} INFO - Started process (PID=13673) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:20,010] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:59:20,011] {logging_mixin.py:104} INFO - [2021-07-08 18:59:20,011] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:20,214] {logging_mixin.py:104} INFO - [2021-07-08 18:59:20,213] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:59:20,215] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:20,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.224 seconds
[2021-07-08 18:59:50,826] {scheduler_job.py:182} INFO - Started process (PID=13735) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:50,829] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 18:59:50,830] {logging_mixin.py:104} INFO - [2021-07-08 18:59:50,830] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:51,069] {logging_mixin.py:104} INFO - [2021-07-08 18:59:51,068] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 18:59:51,070] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 18:59:51,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-07-08 19:00:21,693] {scheduler_job.py:182} INFO - Started process (PID=13791) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:21,696] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:00:21,698] {logging_mixin.py:104} INFO - [2021-07-08 19:00:21,697] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:21,879] {logging_mixin.py:104} INFO - [2021-07-08 19:00:21,878] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:00:21,880] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:21,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.199 seconds
[2021-07-08 19:00:52,546] {scheduler_job.py:182} INFO - Started process (PID=13846) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:52,548] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:00:52,549] {logging_mixin.py:104} INFO - [2021-07-08 19:00:52,549] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:52,760] {logging_mixin.py:104} INFO - [2021-07-08 19:00:52,758] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:00:52,760] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:00:52,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-07-08 19:01:23,465] {scheduler_job.py:182} INFO - Started process (PID=13911) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:23,467] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:01:23,469] {logging_mixin.py:104} INFO - [2021-07-08 19:01:23,468] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:23,711] {logging_mixin.py:104} INFO - [2021-07-08 19:01:23,710] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:01:23,712] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:23,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.261 seconds
[2021-07-08 19:01:54,334] {scheduler_job.py:182} INFO - Started process (PID=13965) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:54,335] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:01:54,336] {logging_mixin.py:104} INFO - [2021-07-08 19:01:54,336] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:54,530] {logging_mixin.py:104} INFO - [2021-07-08 19:01:54,529] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:01:54,531] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:01:54,540] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.210 seconds
[2021-07-08 19:02:24,896] {scheduler_job.py:182} INFO - Started process (PID=14023) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:24,899] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:02:24,900] {logging_mixin.py:104} INFO - [2021-07-08 19:02:24,900] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:25,083] {logging_mixin.py:104} INFO - [2021-07-08 19:02:25,081] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:02:25,083] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:25,091] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.200 seconds
[2021-07-08 19:02:55,570] {scheduler_job.py:182} INFO - Started process (PID=14085) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:55,573] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:02:55,574] {logging_mixin.py:104} INFO - [2021-07-08 19:02:55,574] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:55,809] {logging_mixin.py:104} INFO - [2021-07-08 19:02:55,808] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:02:55,810] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:02:55,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.254 seconds
[2021-07-08 19:03:25,931] {scheduler_job.py:182} INFO - Started process (PID=14140) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:25,933] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:03:25,934] {logging_mixin.py:104} INFO - [2021-07-08 19:03:25,934] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:26,244] {logging_mixin.py:104} INFO - [2021-07-08 19:03:26,242] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:03:26,246] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:26,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.330 seconds
[2021-07-08 19:03:56,486] {scheduler_job.py:182} INFO - Started process (PID=14194) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:56,488] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:03:56,489] {logging_mixin.py:104} INFO - [2021-07-08 19:03:56,489] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:56,785] {logging_mixin.py:104} INFO - [2021-07-08 19:03:56,785] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:03:56,786] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:03:56,795] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.314 seconds
[2021-07-08 19:04:26,824] {scheduler_job.py:182} INFO - Started process (PID=14252) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:26,827] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:04:26,828] {logging_mixin.py:104} INFO - [2021-07-08 19:04:26,828] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:26,988] {logging_mixin.py:104} INFO - [2021-07-08 19:04:26,987] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:04:26,988] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:26,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-07-08 19:04:57,200] {scheduler_job.py:182} INFO - Started process (PID=14306) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:57,202] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:04:57,204] {logging_mixin.py:104} INFO - [2021-07-08 19:04:57,203] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:57,457] {logging_mixin.py:104} INFO - [2021-07-08 19:04:57,456] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:04:57,459] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:04:57,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.280 seconds
[2021-07-08 19:05:27,533] {scheduler_job.py:182} INFO - Started process (PID=14371) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:27,537] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:05:27,539] {logging_mixin.py:104} INFO - [2021-07-08 19:05:27,538] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:27,748] {logging_mixin.py:104} INFO - [2021-07-08 19:05:27,747] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:05:27,749] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:27,759] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-07-08 19:05:58,261] {scheduler_job.py:182} INFO - Started process (PID=14427) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:58,263] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:05:58,265] {logging_mixin.py:104} INFO - [2021-07-08 19:05:58,264] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:58,501] {logging_mixin.py:104} INFO - [2021-07-08 19:05:58,500] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:05:58,502] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:05:58,510] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.253 seconds
[2021-07-08 19:06:28,693] {scheduler_job.py:182} INFO - Started process (PID=14482) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:28,695] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:06:28,696] {logging_mixin.py:104} INFO - [2021-07-08 19:06:28,695] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:28,930] {logging_mixin.py:104} INFO - [2021-07-08 19:06:28,929] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:06:28,931] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:28,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.252 seconds
[2021-07-08 19:06:59,354] {scheduler_job.py:182} INFO - Started process (PID=14546) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:59,356] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:06:59,357] {logging_mixin.py:104} INFO - [2021-07-08 19:06:59,357] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:59,536] {logging_mixin.py:104} INFO - [2021-07-08 19:06:59,535] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:06:59,537] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:06:59,545] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.195 seconds
[2021-07-08 19:07:30,009] {scheduler_job.py:182} INFO - Started process (PID=14599) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:07:30,011] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:07:30,013] {logging_mixin.py:104} INFO - [2021-07-08 19:07:30,012] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:07:30,227] {logging_mixin.py:104} INFO - [2021-07-08 19:07:30,226] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:07:30,228] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:07:30,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-07-08 19:08:00,690] {scheduler_job.py:182} INFO - Started process (PID=14661) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:00,692] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:08:00,693] {logging_mixin.py:104} INFO - [2021-07-08 19:08:00,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:00,941] {logging_mixin.py:104} INFO - [2021-07-08 19:08:00,940] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:08:00,942] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:00,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.270 seconds
[2021-07-08 19:08:31,585] {scheduler_job.py:182} INFO - Started process (PID=14715) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:31,587] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:08:31,588] {logging_mixin.py:104} INFO - [2021-07-08 19:08:31,588] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:31,744] {logging_mixin.py:104} INFO - [2021-07-08 19:08:31,744] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:08:31,745] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:08:31,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 19:09:01,817] {scheduler_job.py:182} INFO - Started process (PID=14767) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:01,819] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:09:01,819] {logging_mixin.py:104} INFO - [2021-07-08 19:09:01,819] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:02,008] {logging_mixin.py:104} INFO - [2021-07-08 19:09:02,007] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:09:02,009] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:02,018] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.204 seconds
[2021-07-08 19:09:32,334] {scheduler_job.py:182} INFO - Started process (PID=14832) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:32,336] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:09:32,337] {logging_mixin.py:104} INFO - [2021-07-08 19:09:32,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:32,550] {logging_mixin.py:104} INFO - [2021-07-08 19:09:32,549] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:09:32,551] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:09:32,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-07-08 19:10:02,886] {scheduler_job.py:182} INFO - Started process (PID=14885) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:02,888] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:10:02,889] {logging_mixin.py:104} INFO - [2021-07-08 19:10:02,889] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:03,106] {logging_mixin.py:104} INFO - [2021-07-08 19:10:03,105] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:10:03,107] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:03,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.238 seconds
[2021-07-08 19:10:33,415] {scheduler_job.py:182} INFO - Started process (PID=14948) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:33,418] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:10:33,420] {logging_mixin.py:104} INFO - [2021-07-08 19:10:33,419] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:33,632] {logging_mixin.py:104} INFO - [2021-07-08 19:10:33,631] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:10:33,633] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:10:33,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.233 seconds
[2021-07-08 19:11:03,776] {scheduler_job.py:182} INFO - Started process (PID=15006) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:03,778] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:11:03,780] {logging_mixin.py:104} INFO - [2021-07-08 19:11:03,779] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:04,004] {logging_mixin.py:104} INFO - [2021-07-08 19:11:04,003] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:11:04,004] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:04,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.241 seconds
[2021-07-08 19:11:34,446] {scheduler_job.py:182} INFO - Started process (PID=15059) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:34,447] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:11:34,449] {logging_mixin.py:104} INFO - [2021-07-08 19:11:34,448] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:34,654] {logging_mixin.py:104} INFO - [2021-07-08 19:11:34,653] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:11:34,655] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:11:34,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.221 seconds
[2021-07-08 19:12:05,152] {scheduler_job.py:182} INFO - Started process (PID=15121) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:05,154] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:12:05,155] {logging_mixin.py:104} INFO - [2021-07-08 19:12:05,155] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:05,376] {logging_mixin.py:104} INFO - [2021-07-08 19:12:05,375] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:12:05,377] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:05,387] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.242 seconds
[2021-07-08 19:12:35,435] {scheduler_job.py:182} INFO - Started process (PID=15175) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:35,437] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:12:35,438] {logging_mixin.py:104} INFO - [2021-07-08 19:12:35,438] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:35,657] {logging_mixin.py:104} INFO - [2021-07-08 19:12:35,655] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:12:35,658] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:12:35,667] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.237 seconds
[2021-07-08 19:13:05,806] {scheduler_job.py:182} INFO - Started process (PID=15230) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:05,809] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:13:05,811] {logging_mixin.py:104} INFO - [2021-07-08 19:13:05,810] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:06,032] {logging_mixin.py:104} INFO - [2021-07-08 19:13:06,031] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:13:06,033] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:06,042] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.242 seconds
[2021-07-08 19:13:36,094] {scheduler_job.py:182} INFO - Started process (PID=15290) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:36,096] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:13:36,098] {logging_mixin.py:104} INFO - [2021-07-08 19:13:36,098] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:36,322] {logging_mixin.py:104} INFO - [2021-07-08 19:13:36,320] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:13:36,322] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:13:36,331] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.243 seconds
[2021-07-08 19:14:07,105] {scheduler_job.py:182} INFO - Started process (PID=15343) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:07,106] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:14:07,107] {logging_mixin.py:104} INFO - [2021-07-08 19:14:07,107] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:07,260] {logging_mixin.py:104} INFO - [2021-07-08 19:14:07,259] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:14:07,260] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:07,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.166 seconds
[2021-07-08 19:14:37,446] {scheduler_job.py:182} INFO - Started process (PID=15397) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:37,448] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:14:37,449] {logging_mixin.py:104} INFO - [2021-07-08 19:14:37,448] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:37,621] {logging_mixin.py:104} INFO - [2021-07-08 19:14:37,620] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:14:37,622] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:14:37,630] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.188 seconds
[2021-07-08 19:15:08,090] {scheduler_job.py:182} INFO - Started process (PID=15462) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:08,096] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:15:08,097] {logging_mixin.py:104} INFO - [2021-07-08 19:15:08,097] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:08,265] {logging_mixin.py:104} INFO - [2021-07-08 19:15:08,264] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:15:08,265] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:08,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.189 seconds
[2021-07-08 19:15:38,577] {scheduler_job.py:182} INFO - Started process (PID=15515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:38,585] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:15:38,586] {logging_mixin.py:104} INFO - [2021-07-08 19:15:38,586] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:38,829] {logging_mixin.py:104} INFO - [2021-07-08 19:15:38,827] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:15:38,830] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:15:38,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.269 seconds
[2021-07-08 19:16:08,983] {scheduler_job.py:182} INFO - Started process (PID=15581) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:08,987] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:16:08,989] {logging_mixin.py:104} INFO - [2021-07-08 19:16:08,989] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:09,285] {logging_mixin.py:104} INFO - [2021-07-08 19:16:09,283] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:16:09,286] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:09,295] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.317 seconds
[2021-07-08 19:16:40,189] {scheduler_job.py:182} INFO - Started process (PID=15634) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:40,191] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:16:40,192] {logging_mixin.py:104} INFO - [2021-07-08 19:16:40,192] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:40,407] {logging_mixin.py:104} INFO - [2021-07-08 19:16:40,406] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:16:40,408] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:16:40,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.236 seconds
[2021-07-08 19:17:10,816] {scheduler_job.py:182} INFO - Started process (PID=15687) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:10,817] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:17:10,818] {logging_mixin.py:104} INFO - [2021-07-08 19:17:10,818] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:10,958] {logging_mixin.py:104} INFO - [2021-07-08 19:17:10,957] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:17:10,958] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:10,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 19:17:41,004] {scheduler_job.py:182} INFO - Started process (PID=15753) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:41,006] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:17:41,008] {logging_mixin.py:104} INFO - [2021-07-08 19:17:41,007] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:41,188] {logging_mixin.py:104} INFO - [2021-07-08 19:17:41,187] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:17:41,189] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:17:41,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.199 seconds
[2021-07-08 19:18:11,752] {scheduler_job.py:182} INFO - Started process (PID=15805) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:11,758] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:18:11,758] {logging_mixin.py:104} INFO - [2021-07-08 19:18:11,758] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:11,910] {logging_mixin.py:104} INFO - [2021-07-08 19:18:11,910] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:18:11,911] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:11,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-07-08 19:18:42,272] {scheduler_job.py:182} INFO - Started process (PID=15870) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:42,278] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:18:42,278] {logging_mixin.py:104} INFO - [2021-07-08 19:18:42,278] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:42,415] {logging_mixin.py:104} INFO - [2021-07-08 19:18:42,414] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:18:42,415] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:18:42,421] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 19:19:12,781] {scheduler_job.py:182} INFO - Started process (PID=15923) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:12,783] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:19:12,784] {logging_mixin.py:104} INFO - [2021-07-08 19:19:12,784] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:12,941] {logging_mixin.py:104} INFO - [2021-07-08 19:19:12,940] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:19:12,941] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:12,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 19:19:43,009] {scheduler_job.py:182} INFO - Started process (PID=15987) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:43,010] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:19:43,011] {logging_mixin.py:104} INFO - [2021-07-08 19:19:43,011] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:43,142] {logging_mixin.py:104} INFO - [2021-07-08 19:19:43,141] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:19:43,143] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:19:43,148] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 19:20:13,325] {scheduler_job.py:182} INFO - Started process (PID=16041) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:13,327] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:20:13,328] {logging_mixin.py:104} INFO - [2021-07-08 19:20:13,328] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:13,499] {logging_mixin.py:104} INFO - [2021-07-08 19:20:13,498] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:20:13,500] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:13,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.187 seconds
[2021-07-08 19:20:43,671] {scheduler_job.py:182} INFO - Started process (PID=16104) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:43,673] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:20:43,675] {logging_mixin.py:104} INFO - [2021-07-08 19:20:43,674] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:43,916] {logging_mixin.py:104} INFO - [2021-07-08 19:20:43,915] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:20:43,916] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:20:43,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-07-08 19:21:14,247] {scheduler_job.py:182} INFO - Started process (PID=16165) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:14,248] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:21:14,249] {logging_mixin.py:104} INFO - [2021-07-08 19:21:14,249] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:14,391] {logging_mixin.py:104} INFO - [2021-07-08 19:21:14,390] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:21:14,392] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:14,398] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.155 seconds
[2021-07-08 19:21:44,809] {scheduler_job.py:182} INFO - Started process (PID=16219) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:44,810] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:21:44,811] {logging_mixin.py:104} INFO - [2021-07-08 19:21:44,811] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:44,944] {logging_mixin.py:104} INFO - [2021-07-08 19:21:44,944] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:21:44,945] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:21:44,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 19:22:15,130] {scheduler_job.py:182} INFO - Started process (PID=16282) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:15,132] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:22:15,134] {logging_mixin.py:104} INFO - [2021-07-08 19:22:15,134] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:15,268] {logging_mixin.py:104} INFO - [2021-07-08 19:22:15,267] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:22:15,269] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:15,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-07-08 19:22:45,332] {scheduler_job.py:182} INFO - Started process (PID=16338) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:45,333] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:22:45,334] {logging_mixin.py:104} INFO - [2021-07-08 19:22:45,334] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:45,501] {logging_mixin.py:104} INFO - [2021-07-08 19:22:45,499] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:22:45,502] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:22:45,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.182 seconds
[2021-07-08 19:23:15,934] {scheduler_job.py:182} INFO - Started process (PID=16401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:15,935] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:23:15,936] {logging_mixin.py:104} INFO - [2021-07-08 19:23:15,936] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:16,136] {logging_mixin.py:104} INFO - [2021-07-08 19:23:16,135] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:23:16,137] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:16,143] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.213 seconds
[2021-07-08 19:23:46,655] {scheduler_job.py:182} INFO - Started process (PID=16455) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:46,657] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:23:46,658] {logging_mixin.py:104} INFO - [2021-07-08 19:23:46,658] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:46,817] {logging_mixin.py:104} INFO - [2021-07-08 19:23:46,816] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:23:46,818] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:23:46,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.173 seconds
[2021-07-08 19:24:17,145] {scheduler_job.py:182} INFO - Started process (PID=16518) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:17,151] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:24:17,152] {logging_mixin.py:104} INFO - [2021-07-08 19:24:17,152] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:17,300] {logging_mixin.py:104} INFO - [2021-07-08 19:24:17,299] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:24:17,300] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:17,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-07-08 19:24:47,392] {scheduler_job.py:182} INFO - Started process (PID=16573) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:47,393] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:24:47,394] {logging_mixin.py:104} INFO - [2021-07-08 19:24:47,394] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:47,525] {logging_mixin.py:104} INFO - [2021-07-08 19:24:47,524] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:24:47,526] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:24:47,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 19:25:17,662] {scheduler_job.py:182} INFO - Started process (PID=16635) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:17,664] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:25:17,665] {logging_mixin.py:104} INFO - [2021-07-08 19:25:17,665] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:17,795] {logging_mixin.py:104} INFO - [2021-07-08 19:25:17,794] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:25:17,795] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:17,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 19:25:48,009] {scheduler_job.py:182} INFO - Started process (PID=16698) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:48,010] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:25:48,011] {logging_mixin.py:104} INFO - [2021-07-08 19:25:48,011] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:48,157] {logging_mixin.py:104} INFO - [2021-07-08 19:25:48,156] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:25:48,158] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:25:48,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.159 seconds
[2021-07-08 19:26:18,520] {scheduler_job.py:182} INFO - Started process (PID=16751) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:18,526] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:26:18,528] {logging_mixin.py:104} INFO - [2021-07-08 19:26:18,527] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:18,663] {logging_mixin.py:104} INFO - [2021-07-08 19:26:18,662] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:26:18,663] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:18,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 19:26:48,723] {scheduler_job.py:182} INFO - Started process (PID=16815) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:48,724] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:26:48,725] {logging_mixin.py:104} INFO - [2021-07-08 19:26:48,725] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:48,873] {logging_mixin.py:104} INFO - [2021-07-08 19:26:48,872] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:26:48,874] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:26:48,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-07-08 19:27:18,920] {scheduler_job.py:182} INFO - Started process (PID=16867) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:18,921] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:27:18,922] {logging_mixin.py:104} INFO - [2021-07-08 19:27:18,922] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:19,064] {logging_mixin.py:104} INFO - [2021-07-08 19:27:19,063] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:27:19,064] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:19,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 19:27:49,198] {scheduler_job.py:182} INFO - Started process (PID=16932) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:49,203] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:27:49,204] {logging_mixin.py:104} INFO - [2021-07-08 19:27:49,204] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:49,338] {logging_mixin.py:104} INFO - [2021-07-08 19:27:49,337] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:27:49,338] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:27:49,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 19:28:19,595] {scheduler_job.py:182} INFO - Started process (PID=16986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:19,596] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:28:19,598] {logging_mixin.py:104} INFO - [2021-07-08 19:28:19,597] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:19,740] {logging_mixin.py:104} INFO - [2021-07-08 19:28:19,740] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:28:19,741] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:19,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.155 seconds
[2021-07-08 19:28:50,099] {scheduler_job.py:182} INFO - Started process (PID=17050) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:50,105] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:28:50,105] {logging_mixin.py:104} INFO - [2021-07-08 19:28:50,105] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:50,242] {logging_mixin.py:104} INFO - [2021-07-08 19:28:50,242] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:28:50,243] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:28:50,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 19:29:20,278] {scheduler_job.py:182} INFO - Started process (PID=17113) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:20,284] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:29:20,285] {logging_mixin.py:104} INFO - [2021-07-08 19:29:20,284] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:20,439] {logging_mixin.py:104} INFO - [2021-07-08 19:29:20,438] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:29:20,439] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:20,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.173 seconds
[2021-07-08 19:29:50,725] {scheduler_job.py:182} INFO - Started process (PID=17167) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:50,731] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:29:50,732] {logging_mixin.py:104} INFO - [2021-07-08 19:29:50,732] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:50,869] {logging_mixin.py:104} INFO - [2021-07-08 19:29:50,868] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:29:50,870] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:29:50,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 19:30:21,722] {scheduler_job.py:182} INFO - Started process (PID=17229) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:21,726] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:30:21,727] {logging_mixin.py:104} INFO - [2021-07-08 19:30:21,727] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:21,864] {logging_mixin.py:104} INFO - [2021-07-08 19:30:21,864] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:30:21,865] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:21,871] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-07-08 19:30:52,325] {scheduler_job.py:182} INFO - Started process (PID=17283) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:52,327] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:30:52,328] {logging_mixin.py:104} INFO - [2021-07-08 19:30:52,327] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:52,471] {logging_mixin.py:104} INFO - [2021-07-08 19:30:52,470] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:30:52,472] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:30:52,478] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 19:31:22,869] {scheduler_job.py:182} INFO - Started process (PID=17347) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:22,871] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:31:22,872] {logging_mixin.py:104} INFO - [2021-07-08 19:31:22,872] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:23,003] {logging_mixin.py:104} INFO - [2021-07-08 19:31:23,002] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:31:23,003] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:23,010] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 19:31:53,490] {scheduler_job.py:182} INFO - Started process (PID=17406) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:53,492] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:31:53,493] {logging_mixin.py:104} INFO - [2021-07-08 19:31:53,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:53,636] {logging_mixin.py:104} INFO - [2021-07-08 19:31:53,635] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:31:53,636] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:31:53,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 19:32:23,716] {scheduler_job.py:182} INFO - Started process (PID=17464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:23,717] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:32:23,717] {logging_mixin.py:104} INFO - [2021-07-08 19:32:23,717] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:23,850] {logging_mixin.py:104} INFO - [2021-07-08 19:32:23,849] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:32:23,850] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:23,856] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 19:32:53,952] {scheduler_job.py:182} INFO - Started process (PID=17528) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:53,953] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:32:53,954] {logging_mixin.py:104} INFO - [2021-07-08 19:32:53,954] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:54,104] {logging_mixin.py:104} INFO - [2021-07-08 19:32:54,104] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:32:54,105] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:32:54,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 19:33:24,247] {scheduler_job.py:182} INFO - Started process (PID=17582) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:24,248] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:33:24,249] {logging_mixin.py:104} INFO - [2021-07-08 19:33:24,249] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:24,379] {logging_mixin.py:104} INFO - [2021-07-08 19:33:24,378] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:33:24,380] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:24,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 19:33:54,748] {scheduler_job.py:182} INFO - Started process (PID=17644) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:54,749] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:33:54,750] {logging_mixin.py:104} INFO - [2021-07-08 19:33:54,750] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:54,881] {logging_mixin.py:104} INFO - [2021-07-08 19:33:54,880] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:33:54,881] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:33:54,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 19:34:25,241] {scheduler_job.py:182} INFO - Started process (PID=17698) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:25,242] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:34:25,243] {logging_mixin.py:104} INFO - [2021-07-08 19:34:25,243] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:25,377] {logging_mixin.py:104} INFO - [2021-07-08 19:34:25,376] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:34:25,377] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:25,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 19:34:55,675] {scheduler_job.py:182} INFO - Started process (PID=17762) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:55,676] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:34:55,677] {logging_mixin.py:104} INFO - [2021-07-08 19:34:55,677] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:55,811] {logging_mixin.py:104} INFO - [2021-07-08 19:34:55,810] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:34:55,811] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:34:55,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 19:35:26,101] {scheduler_job.py:182} INFO - Started process (PID=17815) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:26,103] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:35:26,104] {logging_mixin.py:104} INFO - [2021-07-08 19:35:26,104] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:26,239] {logging_mixin.py:104} INFO - [2021-07-08 19:35:26,238] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:35:26,239] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:26,245] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-07-08 19:35:56,272] {scheduler_job.py:182} INFO - Started process (PID=17882) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:56,273] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:35:56,274] {logging_mixin.py:104} INFO - [2021-07-08 19:35:56,274] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:56,404] {logging_mixin.py:104} INFO - [2021-07-08 19:35:56,403] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:35:56,404] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:35:56,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 19:36:26,469] {scheduler_job.py:182} INFO - Started process (PID=17934) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:26,474] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:36:26,476] {logging_mixin.py:104} INFO - [2021-07-08 19:36:26,475] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:26,672] {logging_mixin.py:104} INFO - [2021-07-08 19:36:26,671] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:36:26,673] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:26,681] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.216 seconds
[2021-07-08 19:36:56,765] {scheduler_job.py:182} INFO - Started process (PID=17999) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:56,766] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:36:56,767] {logging_mixin.py:104} INFO - [2021-07-08 19:36:56,767] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:56,914] {logging_mixin.py:104} INFO - [2021-07-08 19:36:56,913] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 124, in <module>
    python_callable=lambda_function,
NameError: name 'lambda_function' is not defined
[2021-07-08 19:36:56,915] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:36:56,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-07-08 19:37:17,180] {scheduler_job.py:182} INFO - Started process (PID=18048) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:17,181] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:37:17,183] {logging_mixin.py:104} INFO - [2021-07-08 19:37:17,182] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:17,330] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:17,344] {logging_mixin.py:104} INFO - [2021-07-08 19:37:17,344] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:37:17,367] {logging_mixin.py:104} INFO - [2021-07-08 19:37:17,367] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:37:17,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.212 seconds
[2021-07-08 19:37:30,071] {scheduler_job.py:182} INFO - Started process (PID=18075) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:30,073] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:37:30,074] {logging_mixin.py:104} INFO - [2021-07-08 19:37:30,074] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:30,252] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:37:30,268] {logging_mixin.py:104} INFO - [2021-07-08 19:37:30,268] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:37:30,288] {logging_mixin.py:104} INFO - [2021-07-08 19:37:30,288] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:37:30,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.237 seconds
[2021-07-08 19:38:00,410] {scheduler_job.py:182} INFO - Started process (PID=18128) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:00,411] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:38:00,412] {logging_mixin.py:104} INFO - [2021-07-08 19:38:00,412] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:00,553] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:00,565] {logging_mixin.py:104} INFO - [2021-07-08 19:38:00,565] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:38:00,584] {logging_mixin.py:104} INFO - [2021-07-08 19:38:00,584] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:38:00,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.193 seconds
[2021-07-08 19:38:03,911] {scheduler_job.py:182} INFO - Started process (PID=18136) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:03,913] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:38:03,914] {logging_mixin.py:104} INFO - [2021-07-08 19:38:03,914] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:04,051] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:04,063] {logging_mixin.py:104} INFO - [2021-07-08 19:38:04,063] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:38:04,082] {logging_mixin.py:104} INFO - [2021-07-08 19:38:04,082] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:38:04,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.189 seconds
[2021-07-08 19:38:18,427] {scheduler_job.py:182} INFO - Started process (PID=18170) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:18,428] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:38:18,429] {logging_mixin.py:104} INFO - [2021-07-08 19:38:18,429] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:18,582] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:18,596] {logging_mixin.py:104} INFO - [2021-07-08 19:38:18,596] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:38:18,615] {logging_mixin.py:104} INFO - [2021-07-08 19:38:18,615] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:38:18,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.207 seconds
[2021-07-08 19:38:29,394] {scheduler_job.py:182} INFO - Started process (PID=18197) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:29,395] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:38:29,396] {logging_mixin.py:104} INFO - [2021-07-08 19:38:29,395] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:29,521] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:29,533] {logging_mixin.py:104} INFO - [2021-07-08 19:38:29,533] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:38:29,553] {logging_mixin.py:104} INFO - [2021-07-08 19:38:29,553] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:38:29,564] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-07-08 19:38:59,043] {scheduler_job.py:182} INFO - Started process (PID=18240) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:59,045] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:38:59,046] {logging_mixin.py:104} INFO - [2021-07-08 19:38:59,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:59,191] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:38:59,204] {logging_mixin.py:104} INFO - [2021-07-08 19:38:59,204] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:38:59,224] {logging_mixin.py:104} INFO - [2021-07-08 19:38:59,224] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:38:59,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 19:39:05,364] {scheduler_job.py:182} INFO - Started process (PID=18273) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:05,366] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:39:05,367] {logging_mixin.py:104} INFO - [2021-07-08 19:39:05,367] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:05,575] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:05,593] {logging_mixin.py:104} INFO - [2021-07-08 19:39:05,593] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:39:05,619] {logging_mixin.py:104} INFO - [2021-07-08 19:39:05,618] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:39:05,636] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.276 seconds
[2021-07-08 19:39:10,055] {scheduler_job.py:182} INFO - Started process (PID=18277) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:10,057] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:39:10,058] {logging_mixin.py:104} INFO - [2021-07-08 19:39:10,058] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:10,176] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:10,187] {logging_mixin.py:104} INFO - [2021-07-08 19:39:10,187] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:39:10,204] {logging_mixin.py:104} INFO - [2021-07-08 19:39:10,204] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:39:10,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-07-08 19:39:13,247] {scheduler_job.py:182} INFO - Started process (PID=18279) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:13,249] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:39:13,250] {logging_mixin.py:104} INFO - [2021-07-08 19:39:13,249] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:13,371] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:13,383] {logging_mixin.py:104} INFO - [2021-07-08 19:39:13,383] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:39:13,403] {logging_mixin.py:104} INFO - [2021-07-08 19:39:13,403] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:39:13,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 19:39:43,599] {scheduler_job.py:182} INFO - Started process (PID=18344) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:43,601] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:39:43,602] {logging_mixin.py:104} INFO - [2021-07-08 19:39:43,601] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:43,757] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:39:43,773] {logging_mixin.py:104} INFO - [2021-07-08 19:39:43,773] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:39:43,792] {logging_mixin.py:104} INFO - [2021-07-08 19:39:43,792] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:39:43,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.208 seconds
[2021-07-08 19:40:14,058] {scheduler_job.py:182} INFO - Started process (PID=18399) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:14,061] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:40:14,061] {logging_mixin.py:104} INFO - [2021-07-08 19:40:14,061] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:14,202] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:14,216] {logging_mixin.py:104} INFO - [2021-07-08 19:40:14,215] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:40:14,236] {logging_mixin.py:104} INFO - [2021-07-08 19:40:14,236] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:40:14,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 19:40:44,608] {scheduler_job.py:182} INFO - Started process (PID=18464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:44,610] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:40:44,611] {logging_mixin.py:104} INFO - [2021-07-08 19:40:44,611] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:44,765] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:40:44,780] {logging_mixin.py:104} INFO - [2021-07-08 19:40:44,780] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:40:44,804] {logging_mixin.py:104} INFO - [2021-07-08 19:40:44,804] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:40:44,819] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.214 seconds
[2021-07-08 19:41:15,024] {scheduler_job.py:182} INFO - Started process (PID=18517) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:15,026] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:41:15,027] {logging_mixin.py:104} INFO - [2021-07-08 19:41:15,027] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:15,249] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:15,263] {logging_mixin.py:104} INFO - [2021-07-08 19:41:15,262] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:41:15,286] {logging_mixin.py:104} INFO - [2021-07-08 19:41:15,286] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:41:15,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.281 seconds
[2021-07-08 19:41:46,226] {scheduler_job.py:182} INFO - Started process (PID=18580) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:46,229] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:41:46,231] {logging_mixin.py:104} INFO - [2021-07-08 19:41:46,231] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:46,412] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:41:46,426] {logging_mixin.py:104} INFO - [2021-07-08 19:41:46,426] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:41:46,445] {logging_mixin.py:104} INFO - [2021-07-08 19:41:46,445] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:41:46,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.237 seconds
[2021-07-08 19:42:16,910] {scheduler_job.py:182} INFO - Started process (PID=18636) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:16,912] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:42:16,913] {logging_mixin.py:104} INFO - [2021-07-08 19:42:16,913] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:17,043] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:17,055] {logging_mixin.py:104} INFO - [2021-07-08 19:42:17,055] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:42:17,071] {logging_mixin.py:104} INFO - [2021-07-08 19:42:17,070] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:42:17,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-07-08 19:42:47,204] {scheduler_job.py:182} INFO - Started process (PID=18702) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:47,205] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:42:47,206] {logging_mixin.py:104} INFO - [2021-07-08 19:42:47,206] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:47,316] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:42:47,327] {logging_mixin.py:104} INFO - [2021-07-08 19:42:47,327] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:42:47,341] {logging_mixin.py:104} INFO - [2021-07-08 19:42:47,341] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:42:47,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 19:43:17,373] {scheduler_job.py:182} INFO - Started process (PID=18754) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:17,374] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:43:17,375] {logging_mixin.py:104} INFO - [2021-07-08 19:43:17,375] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:17,512] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:17,523] {logging_mixin.py:104} INFO - [2021-07-08 19:43:17,523] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:43:17,540] {logging_mixin.py:104} INFO - [2021-07-08 19:43:17,540] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:43:17,552] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.182 seconds
[2021-07-08 19:43:48,280] {scheduler_job.py:182} INFO - Started process (PID=18817) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:48,285] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:43:48,290] {logging_mixin.py:104} INFO - [2021-07-08 19:43:48,289] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:49,109] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:43:49,153] {logging_mixin.py:104} INFO - [2021-07-08 19:43:49,153] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:43:49,201] {logging_mixin.py:104} INFO - [2021-07-08 19:43:49,200] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:43:49,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.964 seconds
[2021-07-08 19:44:19,517] {scheduler_job.py:182} INFO - Started process (PID=18872) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:19,520] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:44:19,521] {logging_mixin.py:104} INFO - [2021-07-08 19:44:19,521] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:19,701] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:19,712] {logging_mixin.py:104} INFO - [2021-07-08 19:44:19,712] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:44:19,727] {logging_mixin.py:104} INFO - [2021-07-08 19:44:19,727] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:44:19,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.225 seconds
[2021-07-08 19:44:49,844] {scheduler_job.py:182} INFO - Started process (PID=18925) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:49,846] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:44:49,847] {logging_mixin.py:104} INFO - [2021-07-08 19:44:49,846] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:49,980] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:44:49,994] {logging_mixin.py:104} INFO - [2021-07-08 19:44:49,994] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:44:50,015] {logging_mixin.py:104} INFO - [2021-07-08 19:44:50,014] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:44:50,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.187 seconds
[2021-07-08 19:45:20,194] {scheduler_job.py:182} INFO - Started process (PID=18988) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:20,198] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:45:20,198] {logging_mixin.py:104} INFO - [2021-07-08 19:45:20,198] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:20,349] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:20,360] {logging_mixin.py:104} INFO - [2021-07-08 19:45:20,360] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:45:20,375] {logging_mixin.py:104} INFO - [2021-07-08 19:45:20,375] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:45:20,385] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.193 seconds
[2021-07-08 19:45:50,419] {scheduler_job.py:182} INFO - Started process (PID=19042) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:50,421] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:45:50,423] {logging_mixin.py:104} INFO - [2021-07-08 19:45:50,422] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:50,543] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:45:50,560] {logging_mixin.py:104} INFO - [2021-07-08 19:45:50,560] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:45:50,577] {logging_mixin.py:104} INFO - [2021-07-08 19:45:50,577] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:45:50,587] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.173 seconds
[2021-07-08 19:46:21,462] {scheduler_job.py:182} INFO - Started process (PID=19109) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:21,464] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:46:21,465] {logging_mixin.py:104} INFO - [2021-07-08 19:46:21,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:21,587] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:21,599] {logging_mixin.py:104} INFO - [2021-07-08 19:46:21,599] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:46:21,617] {logging_mixin.py:104} INFO - [2021-07-08 19:46:21,617] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:46:21,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 19:46:52,463] {scheduler_job.py:182} INFO - Started process (PID=19164) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:52,464] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:46:52,465] {logging_mixin.py:104} INFO - [2021-07-08 19:46:52,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:52,663] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:46:52,681] {logging_mixin.py:104} INFO - [2021-07-08 19:46:52,681] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:46:52,708] {logging_mixin.py:104} INFO - [2021-07-08 19:46:52,707] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:46:52,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.264 seconds
[2021-07-08 19:47:23,197] {scheduler_job.py:182} INFO - Started process (PID=19227) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:23,200] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:47:23,201] {logging_mixin.py:104} INFO - [2021-07-08 19:47:23,201] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:23,330] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:23,342] {logging_mixin.py:104} INFO - [2021-07-08 19:47:23,342] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:47:23,359] {logging_mixin.py:104} INFO - [2021-07-08 19:47:23,359] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:47:23,368] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.173 seconds
[2021-07-08 19:47:54,163] {scheduler_job.py:182} INFO - Started process (PID=19281) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:54,165] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:47:54,165] {logging_mixin.py:104} INFO - [2021-07-08 19:47:54,165] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:54,273] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:47:54,286] {logging_mixin.py:104} INFO - [2021-07-08 19:47:54,286] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:47:54,302] {logging_mixin.py:104} INFO - [2021-07-08 19:47:54,302] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:47:54,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 19:48:24,427] {scheduler_job.py:182} INFO - Started process (PID=19346) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:24,428] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:48:24,429] {logging_mixin.py:104} INFO - [2021-07-08 19:48:24,429] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:24,604] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:24,624] {logging_mixin.py:104} INFO - [2021-07-08 19:48:24,624] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:48:24,653] {logging_mixin.py:104} INFO - [2021-07-08 19:48:24,653] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:48:24,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.247 seconds
[2021-07-08 19:48:54,716] {scheduler_job.py:182} INFO - Started process (PID=19399) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:54,719] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:48:54,720] {logging_mixin.py:104} INFO - [2021-07-08 19:48:54,720] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:54,925] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:48:54,940] {logging_mixin.py:104} INFO - [2021-07-08 19:48:54,939] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:48:54,959] {logging_mixin.py:104} INFO - [2021-07-08 19:48:54,958] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:48:54,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.257 seconds
[2021-07-08 19:49:25,105] {scheduler_job.py:182} INFO - Started process (PID=19452) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:25,108] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:49:25,109] {logging_mixin.py:104} INFO - [2021-07-08 19:49:25,109] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:25,290] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:25,309] {logging_mixin.py:104} INFO - [2021-07-08 19:49:25,309] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:49:25,333] {logging_mixin.py:104} INFO - [2021-07-08 19:49:25,332] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:49:25,347] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.247 seconds
[2021-07-08 19:49:55,744] {scheduler_job.py:182} INFO - Started process (PID=19515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:55,747] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:49:55,748] {logging_mixin.py:104} INFO - [2021-07-08 19:49:55,748] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:55,963] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:49:55,985] {logging_mixin.py:104} INFO - [2021-07-08 19:49:55,985] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:49:56,011] {logging_mixin.py:104} INFO - [2021-07-08 19:49:56,011] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:49:56,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.286 seconds
[2021-07-08 19:50:26,389] {scheduler_job.py:182} INFO - Started process (PID=19568) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:26,397] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:50:26,399] {logging_mixin.py:104} INFO - [2021-07-08 19:50:26,399] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:26,566] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:26,580] {logging_mixin.py:104} INFO - [2021-07-08 19:50:26,580] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:50:26,600] {logging_mixin.py:104} INFO - [2021-07-08 19:50:26,599] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:50:26,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-07-08 19:50:56,992] {scheduler_job.py:182} INFO - Started process (PID=19634) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:56,995] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:50:56,996] {logging_mixin.py:104} INFO - [2021-07-08 19:50:56,996] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:57,216] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:50:57,233] {logging_mixin.py:104} INFO - [2021-07-08 19:50:57,233] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:50:57,255] {logging_mixin.py:104} INFO - [2021-07-08 19:50:57,255] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:50:57,266] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.277 seconds
[2021-07-08 19:51:27,641] {scheduler_job.py:182} INFO - Started process (PID=19688) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:27,644] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:51:27,645] {logging_mixin.py:104} INFO - [2021-07-08 19:51:27,645] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:27,773] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:27,789] {logging_mixin.py:104} INFO - [2021-07-08 19:51:27,788] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:51:27,814] {logging_mixin.py:104} INFO - [2021-07-08 19:51:27,814] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:51:27,829] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.193 seconds
[2021-07-08 19:51:58,482] {scheduler_job.py:182} INFO - Started process (PID=19751) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:58,487] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:51:58,488] {logging_mixin.py:104} INFO - [2021-07-08 19:51:58,488] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:58,620] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:51:58,639] {logging_mixin.py:104} INFO - [2021-07-08 19:51:58,638] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:51:58,663] {logging_mixin.py:104} INFO - [2021-07-08 19:51:58,663] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:51:58,676] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.197 seconds
[2021-07-08 19:52:29,297] {scheduler_job.py:182} INFO - Started process (PID=19806) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:52:29,300] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:52:29,301] {logging_mixin.py:104} INFO - [2021-07-08 19:52:29,301] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:52:29,422] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:52:29,435] {logging_mixin.py:104} INFO - [2021-07-08 19:52:29,435] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:52:29,453] {logging_mixin.py:104} INFO - [2021-07-08 19:52:29,453] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:52:29,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-07-08 19:53:00,033] {scheduler_job.py:182} INFO - Started process (PID=19869) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:00,035] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:53:00,036] {logging_mixin.py:104} INFO - [2021-07-08 19:53:00,035] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:00,157] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:00,172] {logging_mixin.py:104} INFO - [2021-07-08 19:53:00,172] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:53:00,193] {logging_mixin.py:104} INFO - [2021-07-08 19:53:00,193] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:53:00,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-07-08 19:53:30,591] {scheduler_job.py:182} INFO - Started process (PID=19922) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:30,593] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:53:30,594] {logging_mixin.py:104} INFO - [2021-07-08 19:53:30,594] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:30,712] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:53:30,725] {logging_mixin.py:104} INFO - [2021-07-08 19:53:30,725] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:53:30,744] {logging_mixin.py:104} INFO - [2021-07-08 19:53:30,744] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:53:30,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.170 seconds
[2021-07-08 19:54:01,341] {scheduler_job.py:182} INFO - Started process (PID=19986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:01,342] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:54:01,343] {logging_mixin.py:104} INFO - [2021-07-08 19:54:01,343] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:01,506] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:01,518] {logging_mixin.py:104} INFO - [2021-07-08 19:54:01,518] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:54:01,535] {logging_mixin.py:104} INFO - [2021-07-08 19:54:01,535] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:54:01,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.210 seconds
[2021-07-08 19:54:31,781] {scheduler_job.py:182} INFO - Started process (PID=20039) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:31,783] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:54:31,785] {logging_mixin.py:104} INFO - [2021-07-08 19:54:31,784] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:31,995] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:54:32,010] {logging_mixin.py:104} INFO - [2021-07-08 19:54:32,009] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:54:32,028] {logging_mixin.py:104} INFO - [2021-07-08 19:54:32,027] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:54:32,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.262 seconds
[2021-07-08 19:55:02,336] {scheduler_job.py:182} INFO - Started process (PID=20095) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:02,339] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:55:02,340] {logging_mixin.py:104} INFO - [2021-07-08 19:55:02,340] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:02,508] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:02,520] {logging_mixin.py:104} INFO - [2021-07-08 19:55:02,520] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:55:02,539] {logging_mixin.py:104} INFO - [2021-07-08 19:55:02,539] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:55:02,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.217 seconds
[2021-07-08 19:55:33,025] {scheduler_job.py:182} INFO - Started process (PID=20159) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:33,028] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:55:33,029] {logging_mixin.py:104} INFO - [2021-07-08 19:55:33,029] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:33,187] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:55:33,200] {logging_mixin.py:104} INFO - [2021-07-08 19:55:33,200] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:55:33,216] {logging_mixin.py:104} INFO - [2021-07-08 19:55:33,216] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:55:33,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.205 seconds
[2021-07-08 19:56:03,312] {scheduler_job.py:182} INFO - Started process (PID=20216) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:03,314] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:56:03,315] {logging_mixin.py:104} INFO - [2021-07-08 19:56:03,315] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:03,557] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:03,572] {logging_mixin.py:104} INFO - [2021-07-08 19:56:03,572] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:56:03,594] {logging_mixin.py:104} INFO - [2021-07-08 19:56:03,594] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:56:03,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.296 seconds
[2021-07-08 19:56:34,432] {scheduler_job.py:182} INFO - Started process (PID=20278) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:34,434] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:56:34,435] {logging_mixin.py:104} INFO - [2021-07-08 19:56:34,434] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:34,644] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:56:34,659] {logging_mixin.py:104} INFO - [2021-07-08 19:56:34,658] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:56:34,683] {logging_mixin.py:104} INFO - [2021-07-08 19:56:34,683] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:56:34,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.269 seconds
[2021-07-08 19:57:05,631] {scheduler_job.py:182} INFO - Started process (PID=20334) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:05,633] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:57:05,634] {logging_mixin.py:104} INFO - [2021-07-08 19:57:05,634] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:05,846] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:05,862] {logging_mixin.py:104} INFO - [2021-07-08 19:57:05,862] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:57:05,882] {logging_mixin.py:104} INFO - [2021-07-08 19:57:05,882] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:57:05,893] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.267 seconds
[2021-07-08 19:57:36,522] {scheduler_job.py:182} INFO - Started process (PID=20388) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:36,523] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:57:36,524] {logging_mixin.py:104} INFO - [2021-07-08 19:57:36,524] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:36,775] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:57:36,787] {logging_mixin.py:104} INFO - [2021-07-08 19:57:36,787] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:57:36,803] {logging_mixin.py:104} INFO - [2021-07-08 19:57:36,803] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:57:36,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.295 seconds
[2021-07-08 19:58:07,685] {scheduler_job.py:182} INFO - Started process (PID=20452) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:07,690] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:58:07,691] {logging_mixin.py:104} INFO - [2021-07-08 19:58:07,691] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:07,947] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:07,960] {logging_mixin.py:104} INFO - [2021-07-08 19:58:07,960] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:58:07,983] {logging_mixin.py:104} INFO - [2021-07-08 19:58:07,982] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:58:07,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.318 seconds
[2021-07-08 19:58:38,186] {scheduler_job.py:182} INFO - Started process (PID=20509) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:38,188] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:58:38,189] {logging_mixin.py:104} INFO - [2021-07-08 19:58:38,189] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:38,407] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:58:38,420] {logging_mixin.py:104} INFO - [2021-07-08 19:58:38,420] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:58:38,439] {logging_mixin.py:104} INFO - [2021-07-08 19:58:38,439] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:58:38,450] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.267 seconds
[2021-07-08 19:59:08,702] {scheduler_job.py:182} INFO - Started process (PID=20562) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:08,704] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:59:08,704] {logging_mixin.py:104} INFO - [2021-07-08 19:59:08,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:08,853] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:08,865] {logging_mixin.py:104} INFO - [2021-07-08 19:59:08,865] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:59:08,880] {logging_mixin.py:104} INFO - [2021-07-08 19:59:08,880] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:59:08,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 19:59:39,073] {scheduler_job.py:182} INFO - Started process (PID=20626) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:39,075] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 19:59:39,076] {logging_mixin.py:104} INFO - [2021-07-08 19:59:39,076] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:39,331] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 19:59:39,347] {logging_mixin.py:104} INFO - [2021-07-08 19:59:39,346] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 19:59:39,367] {logging_mixin.py:104} INFO - [2021-07-08 19:59:39,367] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 19:59:39,378] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.309 seconds
[2021-07-08 20:00:09,645] {scheduler_job.py:182} INFO - Started process (PID=20679) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:09,646] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:00:09,647] {logging_mixin.py:104} INFO - [2021-07-08 20:00:09,647] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:09,824] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:09,835] {logging_mixin.py:104} INFO - [2021-07-08 20:00:09,835] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:00:09,851] {logging_mixin.py:104} INFO - [2021-07-08 20:00:09,851] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:00:09,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.219 seconds
[2021-07-08 20:00:39,965] {scheduler_job.py:182} INFO - Started process (PID=20743) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:39,969] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:00:39,970] {logging_mixin.py:104} INFO - [2021-07-08 20:00:39,970] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:40,255] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:00:40,277] {logging_mixin.py:104} INFO - [2021-07-08 20:00:40,277] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:00:40,309] {logging_mixin.py:104} INFO - [2021-07-08 20:00:40,308] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:00:40,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.365 seconds
[2021-07-08 20:01:10,360] {scheduler_job.py:182} INFO - Started process (PID=20796) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:10,362] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:01:10,363] {logging_mixin.py:104} INFO - [2021-07-08 20:01:10,362] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:10,552] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:10,568] {logging_mixin.py:104} INFO - [2021-07-08 20:01:10,568] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:01:10,591] {logging_mixin.py:104} INFO - [2021-07-08 20:01:10,591] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:01:10,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.248 seconds
[2021-07-08 20:01:40,635] {scheduler_job.py:182} INFO - Started process (PID=20859) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:40,636] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:01:40,638] {logging_mixin.py:104} INFO - [2021-07-08 20:01:40,637] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:40,911] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:01:40,927] {logging_mixin.py:104} INFO - [2021-07-08 20:01:40,927] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:01:40,957] {logging_mixin.py:104} INFO - [2021-07-08 20:01:40,957] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:01:40,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.345 seconds
[2021-07-08 20:02:11,856] {scheduler_job.py:182} INFO - Started process (PID=20912) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:11,857] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:02:11,858] {logging_mixin.py:104} INFO - [2021-07-08 20:02:11,858] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:12,015] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:12,027] {logging_mixin.py:104} INFO - [2021-07-08 20:02:12,027] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:02:12,044] {logging_mixin.py:104} INFO - [2021-07-08 20:02:12,044] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:02:12,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.201 seconds
[2021-07-08 20:02:42,115] {scheduler_job.py:182} INFO - Started process (PID=20965) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:42,116] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:02:42,117] {logging_mixin.py:104} INFO - [2021-07-08 20:02:42,117] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:42,268] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:02:42,279] {logging_mixin.py:104} INFO - [2021-07-08 20:02:42,279] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:02:42,294] {logging_mixin.py:104} INFO - [2021-07-08 20:02:42,294] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:02:42,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.192 seconds
[2021-07-08 20:03:12,522] {scheduler_job.py:182} INFO - Started process (PID=21028) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:12,524] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:03:12,525] {logging_mixin.py:104} INFO - [2021-07-08 20:03:12,525] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:12,697] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:12,709] {logging_mixin.py:104} INFO - [2021-07-08 20:03:12,709] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:03:12,726] {logging_mixin.py:104} INFO - [2021-07-08 20:03:12,726] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:03:12,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.218 seconds
[2021-07-08 20:03:43,296] {scheduler_job.py:182} INFO - Started process (PID=21082) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:43,297] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:03:43,298] {logging_mixin.py:104} INFO - [2021-07-08 20:03:43,298] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:43,477] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:03:43,489] {logging_mixin.py:104} INFO - [2021-07-08 20:03:43,489] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:03:43,505] {logging_mixin.py:104} INFO - [2021-07-08 20:03:43,505] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:03:43,516] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-07-08 20:04:13,607] {scheduler_job.py:182} INFO - Started process (PID=21147) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:13,610] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:04:13,611] {logging_mixin.py:104} INFO - [2021-07-08 20:04:13,611] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:13,752] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:13,764] {logging_mixin.py:104} INFO - [2021-07-08 20:04:13,764] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:04:13,781] {logging_mixin.py:104} INFO - [2021-07-08 20:04:13,780] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:04:13,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.189 seconds
[2021-07-08 20:04:44,094] {scheduler_job.py:182} INFO - Started process (PID=21200) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:44,096] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:04:44,096] {logging_mixin.py:104} INFO - [2021-07-08 20:04:44,096] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:44,319] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:04:44,335] {logging_mixin.py:104} INFO - [2021-07-08 20:04:44,335] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:04:44,358] {logging_mixin.py:104} INFO - [2021-07-08 20:04:44,358] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:04:44,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.283 seconds
[2021-07-08 20:05:14,763] {scheduler_job.py:182} INFO - Started process (PID=21254) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:14,765] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:05:14,766] {logging_mixin.py:104} INFO - [2021-07-08 20:05:14,766] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:14,905] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:14,920] {logging_mixin.py:104} INFO - [2021-07-08 20:05:14,920] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:05:14,943] {logging_mixin.py:104} INFO - [2021-07-08 20:05:14,943] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:05:14,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.193 seconds
[2021-07-08 20:05:45,016] {scheduler_job.py:182} INFO - Started process (PID=21319) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:45,018] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:05:45,019] {logging_mixin.py:104} INFO - [2021-07-08 20:05:45,019] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:45,174] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:05:45,187] {logging_mixin.py:104} INFO - [2021-07-08 20:05:45,186] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:05:45,206] {logging_mixin.py:104} INFO - [2021-07-08 20:05:45,206] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:05:45,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.205 seconds
[2021-07-08 20:06:15,349] {scheduler_job.py:182} INFO - Started process (PID=21372) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:15,350] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:06:15,351] {logging_mixin.py:104} INFO - [2021-07-08 20:06:15,351] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:15,488] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:15,503] {logging_mixin.py:104} INFO - [2021-07-08 20:06:15,503] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:06:15,519] {logging_mixin.py:104} INFO - [2021-07-08 20:06:15,519] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:06:15,529] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.183 seconds
[2021-07-08 20:06:45,832] {scheduler_job.py:182} INFO - Started process (PID=21435) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:45,834] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:06:45,834] {logging_mixin.py:104} INFO - [2021-07-08 20:06:45,834] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:45,960] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:06:45,970] {logging_mixin.py:104} INFO - [2021-07-08 20:06:45,970] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:06:45,984] {logging_mixin.py:104} INFO - [2021-07-08 20:06:45,984] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:06:45,994] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.165 seconds
[2021-07-08 20:07:16,076] {scheduler_job.py:182} INFO - Started process (PID=21488) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:16,077] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:07:16,078] {logging_mixin.py:104} INFO - [2021-07-08 20:07:16,078] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:16,217] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:16,230] {logging_mixin.py:104} INFO - [2021-07-08 20:07:16,230] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:07:16,249] {logging_mixin.py:104} INFO - [2021-07-08 20:07:16,248] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:07:16,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.188 seconds
[2021-07-08 20:07:46,371] {scheduler_job.py:182} INFO - Started process (PID=21550) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:46,373] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:07:46,374] {logging_mixin.py:104} INFO - [2021-07-08 20:07:46,374] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:46,518] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:07:46,529] {logging_mixin.py:104} INFO - [2021-07-08 20:07:46,529] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:07:46,544] {logging_mixin.py:104} INFO - [2021-07-08 20:07:46,544] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:07:46,556] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.187 seconds
[2021-07-08 20:08:16,830] {scheduler_job.py:182} INFO - Started process (PID=21604) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:16,832] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:08:16,833] {logging_mixin.py:104} INFO - [2021-07-08 20:08:16,833] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:16,968] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:16,980] {logging_mixin.py:104} INFO - [2021-07-08 20:08:16,980] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:08:17,000] {logging_mixin.py:104} INFO - [2021-07-08 20:08:17,000] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:08:17,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.184 seconds
[2021-07-08 20:08:47,135] {scheduler_job.py:182} INFO - Started process (PID=21667) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:47,137] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:08:47,138] {logging_mixin.py:104} INFO - [2021-07-08 20:08:47,138] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:47,274] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:08:47,285] {logging_mixin.py:104} INFO - [2021-07-08 20:08:47,284] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:08:47,300] {logging_mixin.py:104} INFO - [2021-07-08 20:08:47,300] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:08:47,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.177 seconds
[2021-07-08 20:09:17,420] {scheduler_job.py:182} INFO - Started process (PID=21718) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:17,422] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:09:17,423] {logging_mixin.py:104} INFO - [2021-07-08 20:09:17,423] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:17,595] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:17,612] {logging_mixin.py:104} INFO - [2021-07-08 20:09:17,612] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:09:17,640] {logging_mixin.py:104} INFO - [2021-07-08 20:09:17,639] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:09:17,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.238 seconds
[2021-07-08 20:09:48,042] {scheduler_job.py:182} INFO - Started process (PID=21783) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:48,044] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:09:48,046] {logging_mixin.py:104} INFO - [2021-07-08 20:09:48,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:48,353] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:09:48,370] {logging_mixin.py:104} INFO - [2021-07-08 20:09:48,370] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:09:48,390] {logging_mixin.py:104} INFO - [2021-07-08 20:09:48,390] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:09:48,403] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.365 seconds
[2021-07-08 20:10:19,040] {scheduler_job.py:182} INFO - Started process (PID=21838) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:19,044] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:10:19,045] {logging_mixin.py:104} INFO - [2021-07-08 20:10:19,044] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:19,525] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:19,557] {logging_mixin.py:104} INFO - [2021-07-08 20:10:19,557] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:10:19,622] {logging_mixin.py:104} INFO - [2021-07-08 20:10:19,616] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:10:19,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.615 seconds
[2021-07-08 20:10:49,957] {scheduler_job.py:182} INFO - Started process (PID=21893) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:49,961] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:10:49,964] {logging_mixin.py:104} INFO - [2021-07-08 20:10:49,964] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:50,315] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:10:50,357] {logging_mixin.py:104} INFO - [2021-07-08 20:10:50,357] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:10:50,403] {logging_mixin.py:104} INFO - [2021-07-08 20:10:50,402] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:10:50,423] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.486 seconds
[2021-07-08 20:11:20,491] {scheduler_job.py:182} INFO - Started process (PID=21948) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:20,492] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:11:20,493] {logging_mixin.py:104} INFO - [2021-07-08 20:11:20,493] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:20,758] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:20,777] {logging_mixin.py:104} INFO - [2021-07-08 20:11:20,777] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:11:20,805] {logging_mixin.py:104} INFO - [2021-07-08 20:11:20,805] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:11:20,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.333 seconds
[2021-07-08 20:11:51,023] {scheduler_job.py:182} INFO - Started process (PID=22000) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:51,025] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:11:51,026] {logging_mixin.py:104} INFO - [2021-07-08 20:11:51,026] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:51,300] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:11:51,329] {logging_mixin.py:104} INFO - [2021-07-08 20:11:51,329] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:11:51,350] {logging_mixin.py:104} INFO - [2021-07-08 20:11:51,350] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:11:51,362] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.342 seconds
[2021-07-08 20:13:16,301] {scheduler_job.py:182} INFO - Started process (PID=22054) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:16,308] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:13:16,309] {logging_mixin.py:104} INFO - [2021-07-08 20:13:16,309] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:17,184] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:17,237] {logging_mixin.py:104} INFO - [2021-07-08 20:13:17,237] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:13:17,274] {logging_mixin.py:104} INFO - [2021-07-08 20:13:17,273] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:13:17,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 1.017 seconds
[2021-07-08 20:13:48,335] {scheduler_job.py:182} INFO - Started process (PID=22108) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:48,336] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:13:48,337] {logging_mixin.py:104} INFO - [2021-07-08 20:13:48,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:48,655] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:13:48,672] {logging_mixin.py:104} INFO - [2021-07-08 20:13:48,672] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:13:48,715] {logging_mixin.py:104} INFO - [2021-07-08 20:13:48,714] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:13:48,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.400 seconds
[2021-07-08 20:14:19,691] {scheduler_job.py:182} INFO - Started process (PID=22167) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:19,694] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:14:19,694] {logging_mixin.py:104} INFO - [2021-07-08 20:14:19,694] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:19,949] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:19,961] {logging_mixin.py:104} INFO - [2021-07-08 20:14:19,961] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:14:19,978] {logging_mixin.py:104} INFO - [2021-07-08 20:14:19,978] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:14:19,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.303 seconds
[2021-07-08 20:14:50,118] {scheduler_job.py:182} INFO - Started process (PID=22231) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:50,250] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:14:50,251] {logging_mixin.py:104} INFO - [2021-07-08 20:14:50,251] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:50,482] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:14:50,497] {logging_mixin.py:104} INFO - [2021-07-08 20:14:50,497] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:14:50,517] {logging_mixin.py:104} INFO - [2021-07-08 20:14:50,517] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:14:50,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.421 seconds
[2021-07-08 20:15:21,167] {scheduler_job.py:182} INFO - Started process (PID=22284) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:21,169] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:15:21,170] {logging_mixin.py:104} INFO - [2021-07-08 20:15:21,170] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:21,327] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:21,342] {logging_mixin.py:104} INFO - [2021-07-08 20:15:21,342] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:15:21,358] {logging_mixin.py:104} INFO - [2021-07-08 20:15:21,358] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:15:21,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.205 seconds
[2021-07-08 20:15:51,793] {scheduler_job.py:182} INFO - Started process (PID=22349) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:51,798] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:15:51,802] {logging_mixin.py:104} INFO - [2021-07-08 20:15:51,802] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:52,073] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:15:52,090] {logging_mixin.py:104} INFO - [2021-07-08 20:15:52,090] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:15:52,110] {logging_mixin.py:104} INFO - [2021-07-08 20:15:52,109] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:15:52,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.336 seconds
[2021-07-08 20:16:22,238] {scheduler_job.py:182} INFO - Started process (PID=22403) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:22,240] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:16:22,241] {logging_mixin.py:104} INFO - [2021-07-08 20:16:22,241] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:22,425] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:22,440] {logging_mixin.py:104} INFO - [2021-07-08 20:16:22,440] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:16:22,453] {logging_mixin.py:104} INFO - [2021-07-08 20:16:22,453] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:16:22,464] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-07-08 20:16:52,780] {scheduler_job.py:182} INFO - Started process (PID=22467) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:52,782] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:16:52,783] {logging_mixin.py:104} INFO - [2021-07-08 20:16:52,783] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:52,920] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:16:52,938] {logging_mixin.py:104} INFO - [2021-07-08 20:16:52,938] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:16:52,952] {logging_mixin.py:104} INFO - [2021-07-08 20:16:52,952] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:16:52,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.187 seconds
[2021-07-08 20:17:23,771] {scheduler_job.py:182} INFO - Started process (PID=22520) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:23,777] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:17:23,778] {logging_mixin.py:104} INFO - [2021-07-08 20:17:23,777] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:23,913] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:23,925] {logging_mixin.py:104} INFO - [2021-07-08 20:17:23,925] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:17:23,939] {logging_mixin.py:104} INFO - [2021-07-08 20:17:23,939] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:17:23,950] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.182 seconds
[2021-07-08 20:17:54,293] {scheduler_job.py:182} INFO - Started process (PID=22585) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:54,295] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:17:54,296] {logging_mixin.py:104} INFO - [2021-07-08 20:17:54,295] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:54,467] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:17:54,482] {logging_mixin.py:104} INFO - [2021-07-08 20:17:54,482] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:17:54,498] {logging_mixin.py:104} INFO - [2021-07-08 20:17:54,498] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:17:54,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-07-08 20:18:24,667] {scheduler_job.py:182} INFO - Started process (PID=22639) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:24,670] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:18:24,671] {logging_mixin.py:104} INFO - [2021-07-08 20:18:24,671] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:24,820] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:24,834] {logging_mixin.py:104} INFO - [2021-07-08 20:18:24,834] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:18:24,850] {logging_mixin.py:104} INFO - [2021-07-08 20:18:24,850] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:18:24,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.198 seconds
[2021-07-08 20:18:55,691] {scheduler_job.py:182} INFO - Started process (PID=22702) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:55,692] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:18:55,693] {logging_mixin.py:104} INFO - [2021-07-08 20:18:55,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:55,914] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:18:55,933] {logging_mixin.py:104} INFO - [2021-07-08 20:18:55,932] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:18:55,951] {logging_mixin.py:104} INFO - [2021-07-08 20:18:55,951] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:18:55,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.277 seconds
[2021-07-08 20:19:26,080] {scheduler_job.py:182} INFO - Started process (PID=22757) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:26,082] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:19:26,083] {logging_mixin.py:104} INFO - [2021-07-08 20:19:26,083] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:26,229] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:26,244] {logging_mixin.py:104} INFO - [2021-07-08 20:19:26,243] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:19:26,261] {logging_mixin.py:104} INFO - [2021-07-08 20:19:26,261] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:19:26,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.197 seconds
[2021-07-08 20:19:56,454] {scheduler_job.py:182} INFO - Started process (PID=22821) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:56,457] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:19:56,458] {logging_mixin.py:104} INFO - [2021-07-08 20:19:56,458] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:56,638] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:19:56,656] {logging_mixin.py:104} INFO - [2021-07-08 20:19:56,655] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:19:56,680] {logging_mixin.py:104} INFO - [2021-07-08 20:19:56,680] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:19:56,697] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.246 seconds
[2021-07-08 20:20:27,595] {scheduler_job.py:182} INFO - Started process (PID=22874) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:27,597] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:20:27,598] {logging_mixin.py:104} INFO - [2021-07-08 20:20:27,598] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:27,846] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:27,873] {logging_mixin.py:104} INFO - [2021-07-08 20:20:27,873] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:20:27,890] {logging_mixin.py:104} INFO - [2021-07-08 20:20:27,890] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:20:27,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.313 seconds
[2021-07-08 20:20:58,053] {scheduler_job.py:182} INFO - Started process (PID=22932) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:58,054] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:20:58,055] {logging_mixin.py:104} INFO - [2021-07-08 20:20:58,055] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:58,254] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:20:58,267] {logging_mixin.py:104} INFO - [2021-07-08 20:20:58,267] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:20:58,283] {logging_mixin.py:104} INFO - [2021-07-08 20:20:58,283] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:20:58,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.247 seconds
[2021-07-08 20:21:28,517] {scheduler_job.py:182} INFO - Started process (PID=22986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:28,519] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:21:28,520] {logging_mixin.py:104} INFO - [2021-07-08 20:21:28,520] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:28,696] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:28,710] {logging_mixin.py:104} INFO - [2021-07-08 20:21:28,710] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:21:28,724] {logging_mixin.py:104} INFO - [2021-07-08 20:21:28,724] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:21:28,736] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-07-08 20:21:59,104] {scheduler_job.py:182} INFO - Started process (PID=23049) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:59,106] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:21:59,108] {logging_mixin.py:104} INFO - [2021-07-08 20:21:59,108] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:59,282] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:21:59,298] {logging_mixin.py:104} INFO - [2021-07-08 20:21:59,298] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:21:59,314] {logging_mixin.py:104} INFO - [2021-07-08 20:21:59,314] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:21:59,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-07-08 20:22:29,582] {scheduler_job.py:182} INFO - Started process (PID=23103) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:22:29,588] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:22:29,590] {logging_mixin.py:104} INFO - [2021-07-08 20:22:29,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:22:29,781] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:22:29,802] {logging_mixin.py:104} INFO - [2021-07-08 20:22:29,802] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:22:29,820] {logging_mixin.py:104} INFO - [2021-07-08 20:22:29,820] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:22:29,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-07-08 20:23:00,717] {scheduler_job.py:182} INFO - Started process (PID=23166) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:00,720] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:23:00,721] {logging_mixin.py:104} INFO - [2021-07-08 20:23:00,721] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:00,906] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:00,924] {logging_mixin.py:104} INFO - [2021-07-08 20:23:00,924] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:23:00,943] {logging_mixin.py:104} INFO - [2021-07-08 20:23:00,943] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:23:00,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.244 seconds
[2021-07-08 20:23:31,064] {scheduler_job.py:182} INFO - Started process (PID=23219) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:31,067] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:23:31,068] {logging_mixin.py:104} INFO - [2021-07-08 20:23:31,068] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:31,220] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:31,233] {logging_mixin.py:104} INFO - [2021-07-08 20:23:31,232] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:23:31,246] {logging_mixin.py:104} INFO - [2021-07-08 20:23:31,246] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:23:31,256] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 20:23:38,733] {scheduler_job.py:182} INFO - Started process (PID=23254) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:38,734] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:23:38,735] {logging_mixin.py:104} INFO - [2021-07-08 20:23:38,735] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:38,890] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:23:38,903] {logging_mixin.py:104} INFO - [2021-07-08 20:23:38,903] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:23:38,917] {logging_mixin.py:104} INFO - [2021-07-08 20:23:38,917] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:23:38,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.204 seconds
[2021-07-08 20:24:09,850] {scheduler_job.py:182} INFO - Started process (PID=23308) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:09,851] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:09,852] {logging_mixin.py:104} INFO - [2021-07-08 20:24:09,852] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:10,002] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:10,016] {logging_mixin.py:104} INFO - [2021-07-08 20:24:10,016] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:24:10,034] {logging_mixin.py:104} INFO - [2021-07-08 20:24:10,034] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:24:10,048] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.203 seconds
[2021-07-08 20:24:11,162] {scheduler_job.py:182} INFO - Started process (PID=23322) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:11,164] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:11,165] {logging_mixin.py:104} INFO - [2021-07-08 20:24:11,164] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:11,168] {logging_mixin.py:104} INFO - [2021-07-08 20:24:11,166] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:24:11,168] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:11,192] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.033 seconds
[2021-07-08 20:24:22,441] {scheduler_job.py:182} INFO - Started process (PID=23329) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:22,443] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:22,444] {logging_mixin.py:104} INFO - [2021-07-08 20:24:22,444] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:22,447] {logging_mixin.py:104} INFO - [2021-07-08 20:24:22,446] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:24:22,448] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:22,468] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.032 seconds
[2021-07-08 20:24:23,447] {scheduler_job.py:182} INFO - Started process (PID=23339) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:23,449] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:23,450] {logging_mixin.py:104} INFO - [2021-07-08 20:24:23,450] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:23,453] {logging_mixin.py:104} INFO - [2021-07-08 20:24:23,452] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:24:23,454] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:23,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.030 seconds
[2021-07-08 20:24:24,492] {scheduler_job.py:182} INFO - Started process (PID=23341) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:24,493] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:24,494] {logging_mixin.py:104} INFO - [2021-07-08 20:24:24,494] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:24,498] {logging_mixin.py:104} INFO - [2021-07-08 20:24:24,497] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:24:24,498] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:24,519] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.030 seconds
[2021-07-08 20:24:54,920] {scheduler_job.py:182} INFO - Started process (PID=23394) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:54,921] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:24:54,922] {logging_mixin.py:104} INFO - [2021-07-08 20:24:54,922] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:54,925] {logging_mixin.py:104} INFO - [2021-07-08 20:24:54,924] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:24:54,925] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:24:54,943] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.026 seconds
[2021-07-08 20:25:01,958] {scheduler_job.py:182} INFO - Started process (PID=23405) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:01,959] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:01,960] {logging_mixin.py:104} INFO - [2021-07-08 20:25:01,960] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:01,965] {logging_mixin.py:104} INFO - [2021-07-08 20:25:01,963] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:01,965] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:01,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.029 seconds
[2021-07-08 20:25:08,821] {scheduler_job.py:182} INFO - Started process (PID=23426) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:08,824] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:08,825] {logging_mixin.py:104} INFO - [2021-07-08 20:25:08,825] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:08,830] {logging_mixin.py:104} INFO - [2021-07-08 20:25:08,828] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:08,830] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:08,844] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.026 seconds
[2021-07-08 20:25:19,216] {scheduler_job.py:182} INFO - Started process (PID=23449) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:19,218] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:19,219] {logging_mixin.py:104} INFO - [2021-07-08 20:25:19,219] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:19,222] {logging_mixin.py:104} INFO - [2021-07-08 20:25:19,221] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 126
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:19,223] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:19,237] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.023 seconds
[2021-07-08 20:25:30,257] {scheduler_job.py:182} INFO - Started process (PID=23461) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:30,259] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:30,259] {logging_mixin.py:104} INFO - [2021-07-08 20:25:30,259] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:30,261] {logging_mixin.py:104} INFO - [2021-07-08 20:25:30,260] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 117
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:30,261] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:30,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.021 seconds
[2021-07-08 20:25:37,050] {scheduler_job.py:182} INFO - Started process (PID=23493) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:37,054] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:37,055] {logging_mixin.py:104} INFO - [2021-07-08 20:25:37,055] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:37,058] {logging_mixin.py:104} INFO - [2021-07-08 20:25:37,058] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 117
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:37,059] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:37,073] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.028 seconds
[2021-07-08 20:25:43,469] {scheduler_job.py:182} INFO - Started process (PID=23501) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:43,470] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:25:43,471] {logging_mixin.py:104} INFO - [2021-07-08 20:25:43,471] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:43,472] {logging_mixin.py:104} INFO - [2021-07-08 20:25:43,472] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 117
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:25:43,473] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:25:43,487] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.021 seconds
[2021-07-08 20:26:13,982] {scheduler_job.py:182} INFO - Started process (PID=23565) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:13,984] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:26:13,985] {logging_mixin.py:104} INFO - [2021-07-08 20:26:13,984] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:13,987] {logging_mixin.py:104} INFO - [2021-07-08 20:26:13,987] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 117
    region_name=region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:26:13,988] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:14,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.023 seconds
[2021-07-08 20:26:31,207] {scheduler_job.py:182} INFO - Started process (PID=23591) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:31,208] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:26:31,209] {logging_mixin.py:104} INFO - [2021-07-08 20:26:31,209] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:31,211] {logging_mixin.py:104} INFO - [2021-07-08 20:26:31,210] {dagbag.py:329} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 326, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 117
    region_name = region_name,
              ^
SyntaxError: invalid syntax
[2021-07-08 20:26:31,211] {scheduler_job.py:645} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:31,227] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.024 seconds
[2021-07-08 20:26:44,647] {scheduler_job.py:182} INFO - Started process (PID=23630) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:44,648] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:26:44,649] {logging_mixin.py:104} INFO - [2021-07-08 20:26:44,649] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:44,744] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:26:44,901] {logging_mixin.py:104} INFO - [2021-07-08 20:26:44,901] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:26:44,909] {logging_mixin.py:104} INFO - [2021-07-08 20:26:44,909] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:26:44,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.276 seconds
[2021-07-08 20:27:15,153] {scheduler_job.py:182} INFO - Started process (PID=23684) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:15,156] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:27:15,156] {logging_mixin.py:104} INFO - [2021-07-08 20:27:15,156] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:15,251] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:15,258] {logging_mixin.py:104} INFO - [2021-07-08 20:27:15,258] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:27:15,267] {logging_mixin.py:104} INFO - [2021-07-08 20:27:15,267] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:27:15,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 20:27:45,632] {scheduler_job.py:182} INFO - Started process (PID=23747) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:45,634] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:27:45,635] {logging_mixin.py:104} INFO - [2021-07-08 20:27:45,634] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:45,731] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:27:45,739] {logging_mixin.py:104} INFO - [2021-07-08 20:27:45,739] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:27:45,749] {logging_mixin.py:104} INFO - [2021-07-08 20:27:45,749] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:27:45,756] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 20:28:16,031] {scheduler_job.py:182} INFO - Started process (PID=23811) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:16,032] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:28:16,032] {logging_mixin.py:104} INFO - [2021-07-08 20:28:16,032] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:16,148] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:16,156] {logging_mixin.py:104} INFO - [2021-07-08 20:28:16,156] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:28:16,166] {logging_mixin.py:104} INFO - [2021-07-08 20:28:16,166] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:28:16,173] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 20:28:46,739] {scheduler_job.py:182} INFO - Started process (PID=23865) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:46,740] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:28:46,740] {logging_mixin.py:104} INFO - [2021-07-08 20:28:46,740] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:46,838] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:28:46,847] {logging_mixin.py:104} INFO - [2021-07-08 20:28:46,847] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:28:46,857] {logging_mixin.py:104} INFO - [2021-07-08 20:28:46,857] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:28:46,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 20:29:17,306] {scheduler_job.py:182} INFO - Started process (PID=23928) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:17,307] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:29:17,309] {logging_mixin.py:104} INFO - [2021-07-08 20:29:17,308] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:17,437] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:17,448] {logging_mixin.py:104} INFO - [2021-07-08 20:29:17,448] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:29:17,465] {logging_mixin.py:104} INFO - [2021-07-08 20:29:17,464] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:29:17,477] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-07-08 20:29:47,860] {scheduler_job.py:182} INFO - Started process (PID=23991) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:47,863] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:29:47,864] {logging_mixin.py:104} INFO - [2021-07-08 20:29:47,864] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:48,083] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:29:48,097] {logging_mixin.py:104} INFO - [2021-07-08 20:29:48,097] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:29:48,114] {logging_mixin.py:104} INFO - [2021-07-08 20:29:48,114] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:29:48,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.269 seconds
[2021-07-08 20:30:18,215] {scheduler_job.py:182} INFO - Started process (PID=24046) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:18,217] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:30:18,217] {logging_mixin.py:104} INFO - [2021-07-08 20:30:18,217] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:18,307] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:18,314] {logging_mixin.py:104} INFO - [2021-07-08 20:30:18,314] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:30:18,323] {logging_mixin.py:104} INFO - [2021-07-08 20:30:18,323] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:30:18,331] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 20:30:49,274] {scheduler_job.py:182} INFO - Started process (PID=24109) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:49,275] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:30:49,276] {logging_mixin.py:104} INFO - [2021-07-08 20:30:49,276] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:49,394] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:30:49,404] {logging_mixin.py:104} INFO - [2021-07-08 20:30:49,403] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:30:49,414] {logging_mixin.py:104} INFO - [2021-07-08 20:30:49,414] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:30:49,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 20:31:20,087] {scheduler_job.py:182} INFO - Started process (PID=24163) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:20,090] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:31:20,091] {logging_mixin.py:104} INFO - [2021-07-08 20:31:20,091] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:20,242] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:20,253] {logging_mixin.py:104} INFO - [2021-07-08 20:31:20,253] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:31:20,266] {logging_mixin.py:104} INFO - [2021-07-08 20:31:20,266] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:31:20,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.196 seconds
[2021-07-08 20:31:51,267] {scheduler_job.py:182} INFO - Started process (PID=24227) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:51,269] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:31:51,269] {logging_mixin.py:104} INFO - [2021-07-08 20:31:51,269] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:51,361] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:31:51,369] {logging_mixin.py:104} INFO - [2021-07-08 20:31:51,369] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:31:51,382] {logging_mixin.py:104} INFO - [2021-07-08 20:31:51,382] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:31:51,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 20:32:21,928] {scheduler_job.py:182} INFO - Started process (PID=24292) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:21,930] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:32:21,930] {logging_mixin.py:104} INFO - [2021-07-08 20:32:21,930] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:22,066] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:22,076] {logging_mixin.py:104} INFO - [2021-07-08 20:32:22,076] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:32:22,087] {logging_mixin.py:104} INFO - [2021-07-08 20:32:22,087] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:32:22,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-07-08 20:32:52,586] {scheduler_job.py:182} INFO - Started process (PID=24345) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:52,588] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:32:52,589] {logging_mixin.py:104} INFO - [2021-07-08 20:32:52,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:52,706] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:32:52,716] {logging_mixin.py:104} INFO - [2021-07-08 20:32:52,716] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:32:52,726] {logging_mixin.py:104} INFO - [2021-07-08 20:32:52,726] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:32:52,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 20:33:23,042] {scheduler_job.py:182} INFO - Started process (PID=24410) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:23,044] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:33:23,045] {logging_mixin.py:104} INFO - [2021-07-08 20:33:23,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:23,151] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:23,163] {logging_mixin.py:104} INFO - [2021-07-08 20:33:23,163] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:33:23,176] {logging_mixin.py:104} INFO - [2021-07-08 20:33:23,176] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:33:23,185] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 20:33:53,689] {scheduler_job.py:182} INFO - Started process (PID=24473) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:53,691] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:33:53,692] {logging_mixin.py:104} INFO - [2021-07-08 20:33:53,691] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:53,783] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:33:53,790] {logging_mixin.py:104} INFO - [2021-07-08 20:33:53,790] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:33:53,801] {logging_mixin.py:104} INFO - [2021-07-08 20:33:53,801] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:33:53,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 20:34:24,212] {scheduler_job.py:182} INFO - Started process (PID=24526) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:24,214] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:34:24,214] {logging_mixin.py:104} INFO - [2021-07-08 20:34:24,214] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:24,315] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:24,323] {logging_mixin.py:104} INFO - [2021-07-08 20:34:24,323] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:34:24,334] {logging_mixin.py:104} INFO - [2021-07-08 20:34:24,334] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:34:24,345] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 20:34:54,690] {scheduler_job.py:182} INFO - Started process (PID=24589) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:54,695] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:34:54,696] {logging_mixin.py:104} INFO - [2021-07-08 20:34:54,696] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:54,794] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:34:54,802] {logging_mixin.py:104} INFO - [2021-07-08 20:34:54,802] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:34:54,811] {logging_mixin.py:104} INFO - [2021-07-08 20:34:54,811] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:34:54,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 20:35:25,006] {scheduler_job.py:182} INFO - Started process (PID=24654) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:25,008] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:35:25,009] {logging_mixin.py:104} INFO - [2021-07-08 20:35:25,009] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:25,110] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:25,121] {logging_mixin.py:104} INFO - [2021-07-08 20:35:25,121] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:35:25,131] {logging_mixin.py:104} INFO - [2021-07-08 20:35:25,131] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:35:25,139] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 20:35:55,771] {scheduler_job.py:182} INFO - Started process (PID=24707) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:55,773] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:35:55,774] {logging_mixin.py:104} INFO - [2021-07-08 20:35:55,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:55,874] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:35:55,885] {logging_mixin.py:104} INFO - [2021-07-08 20:35:55,885] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:35:55,895] {logging_mixin.py:104} INFO - [2021-07-08 20:35:55,895] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:35:55,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 20:36:26,373] {scheduler_job.py:182} INFO - Started process (PID=24770) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:26,375] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:36:26,376] {logging_mixin.py:104} INFO - [2021-07-08 20:36:26,376] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:26,540] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:26,567] {logging_mixin.py:104} INFO - [2021-07-08 20:36:26,567] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:36:26,595] {logging_mixin.py:104} INFO - [2021-07-08 20:36:26,595] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:36:26,611] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.242 seconds
[2021-07-08 20:36:57,405] {scheduler_job.py:182} INFO - Started process (PID=24834) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:57,407] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:36:57,407] {logging_mixin.py:104} INFO - [2021-07-08 20:36:57,407] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:57,500] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:36:57,508] {logging_mixin.py:104} INFO - [2021-07-08 20:36:57,508] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:36:57,519] {logging_mixin.py:104} INFO - [2021-07-08 20:36:57,519] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:36:57,527] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 20:37:18,014] {scheduler_job.py:182} INFO - Started process (PID=24872) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:18,015] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:37:18,016] {logging_mixin.py:104} INFO - [2021-07-08 20:37:18,016] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:18,121] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:18,135] {logging_mixin.py:104} INFO - [2021-07-08 20:37:18,135] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:37:18,149] {logging_mixin.py:104} INFO - [2021-07-08 20:37:18,149] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:37:18,163] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 20:37:48,459] {scheduler_job.py:182} INFO - Started process (PID=24926) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:48,465] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:37:48,466] {logging_mixin.py:104} INFO - [2021-07-08 20:37:48,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:48,559] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:48,567] {logging_mixin.py:104} INFO - [2021-07-08 20:37:48,567] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:37:48,577] {logging_mixin.py:104} INFO - [2021-07-08 20:37:48,577] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:37:48,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 20:37:51,801] {scheduler_job.py:182} INFO - Started process (PID=24935) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:51,802] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:37:51,802] {logging_mixin.py:104} INFO - [2021-07-08 20:37:51,802] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:51,915] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:51,925] {logging_mixin.py:104} INFO - [2021-07-08 20:37:51,925] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:37:51,935] {logging_mixin.py:104} INFO - [2021-07-08 20:37:51,935] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:37:51,944] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 20:37:57,232] {scheduler_job.py:182} INFO - Started process (PID=24955) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:57,234] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:37:57,235] {logging_mixin.py:104} INFO - [2021-07-08 20:37:57,235] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:57,322] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:37:57,330] {logging_mixin.py:104} INFO - [2021-07-08 20:37:57,330] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:37:57,338] {logging_mixin.py:104} INFO - [2021-07-08 20:37:57,338] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:37:57,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 20:38:02,639] {scheduler_job.py:182} INFO - Started process (PID=24961) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:02,640] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:38:02,641] {logging_mixin.py:104} INFO - [2021-07-08 20:38:02,641] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:02,725] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:02,732] {logging_mixin.py:104} INFO - [2021-07-08 20:38:02,731] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:38:02,741] {logging_mixin.py:104} INFO - [2021-07-08 20:38:02,741] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:38:02,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 20:38:13,706] {scheduler_job.py:182} INFO - Started process (PID=24972) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:13,707] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:38:13,708] {logging_mixin.py:104} INFO - [2021-07-08 20:38:13,708] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:13,810] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:13,819] {logging_mixin.py:104} INFO - [2021-07-08 20:38:13,819] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:38:13,828] {logging_mixin.py:104} INFO - [2021-07-08 20:38:13,828] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:38:13,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 20:38:44,461] {scheduler_job.py:182} INFO - Started process (PID=25036) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:44,464] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:38:44,464] {logging_mixin.py:104} INFO - [2021-07-08 20:38:44,464] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:44,576] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:38:44,583] {logging_mixin.py:104} INFO - [2021-07-08 20:38:44,583] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:38:44,590] {logging_mixin.py:104} INFO - [2021-07-08 20:38:44,590] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:38:44,597] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 20:39:14,918] {scheduler_job.py:182} INFO - Started process (PID=25101) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:14,922] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:39:14,923] {logging_mixin.py:104} INFO - [2021-07-08 20:39:14,923] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:15,012] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:15,019] {logging_mixin.py:104} INFO - [2021-07-08 20:39:15,019] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:39:15,027] {logging_mixin.py:104} INFO - [2021-07-08 20:39:15,027] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:39:15,034] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 20:39:45,283] {scheduler_job.py:182} INFO - Started process (PID=25154) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:45,284] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:39:45,285] {logging_mixin.py:104} INFO - [2021-07-08 20:39:45,285] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:45,365] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:39:45,372] {logging_mixin.py:104} INFO - [2021-07-08 20:39:45,372] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:39:45,379] {logging_mixin.py:104} INFO - [2021-07-08 20:39:45,379] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:39:45,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 20:40:15,615] {scheduler_job.py:182} INFO - Started process (PID=25217) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:15,618] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:40:15,619] {logging_mixin.py:104} INFO - [2021-07-08 20:40:15,619] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:15,744] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:15,751] {logging_mixin.py:104} INFO - [2021-07-08 20:40:15,751] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:40:15,759] {logging_mixin.py:104} INFO - [2021-07-08 20:40:15,759] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:40:15,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 20:40:46,426] {scheduler_job.py:182} INFO - Started process (PID=25280) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:46,430] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:40:46,431] {logging_mixin.py:104} INFO - [2021-07-08 20:40:46,431] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:46,515] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:40:46,522] {logging_mixin.py:104} INFO - [2021-07-08 20:40:46,522] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:40:46,530] {logging_mixin.py:104} INFO - [2021-07-08 20:40:46,530] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:40:46,537] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 20:41:16,921] {scheduler_job.py:182} INFO - Started process (PID=25335) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:16,927] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:41:16,928] {logging_mixin.py:104} INFO - [2021-07-08 20:41:16,928] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:17,025] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:17,031] {logging_mixin.py:104} INFO - [2021-07-08 20:41:17,031] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:41:17,039] {logging_mixin.py:104} INFO - [2021-07-08 20:41:17,039] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:41:17,047] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 20:41:47,488] {scheduler_job.py:182} INFO - Started process (PID=25401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:47,490] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:41:47,491] {logging_mixin.py:104} INFO - [2021-07-08 20:41:47,491] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:47,576] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:41:47,583] {logging_mixin.py:104} INFO - [2021-07-08 20:41:47,583] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:41:47,594] {logging_mixin.py:104} INFO - [2021-07-08 20:41:47,594] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:41:47,600] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 20:42:17,995] {scheduler_job.py:182} INFO - Started process (PID=25464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:17,997] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:42:17,997] {logging_mixin.py:104} INFO - [2021-07-08 20:42:17,997] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:18,077] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:18,084] {logging_mixin.py:104} INFO - [2021-07-08 20:42:18,084] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:42:18,092] {logging_mixin.py:104} INFO - [2021-07-08 20:42:18,091] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:42:18,098] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.104 seconds
[2021-07-08 20:42:48,519] {scheduler_job.py:182} INFO - Started process (PID=25517) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:48,522] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:42:48,523] {logging_mixin.py:104} INFO - [2021-07-08 20:42:48,523] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:48,644] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:42:48,652] {logging_mixin.py:104} INFO - [2021-07-08 20:42:48,652] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:42:48,659] {logging_mixin.py:104} INFO - [2021-07-08 20:42:48,659] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:42:48,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 20:43:19,081] {scheduler_job.py:182} INFO - Started process (PID=25580) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:19,083] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:43:19,084] {logging_mixin.py:104} INFO - [2021-07-08 20:43:19,084] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:19,172] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:19,179] {logging_mixin.py:104} INFO - [2021-07-08 20:43:19,179] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:43:19,186] {logging_mixin.py:104} INFO - [2021-07-08 20:43:19,186] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:43:19,193] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 20:43:49,702] {scheduler_job.py:182} INFO - Started process (PID=25644) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:49,703] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:43:49,704] {logging_mixin.py:104} INFO - [2021-07-08 20:43:49,704] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:49,799] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:43:49,806] {logging_mixin.py:104} INFO - [2021-07-08 20:43:49,806] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:43:49,814] {logging_mixin.py:104} INFO - [2021-07-08 20:43:49,814] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:43:49,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 20:44:20,025] {scheduler_job.py:182} INFO - Started process (PID=25697) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:20,026] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:44:20,027] {logging_mixin.py:104} INFO - [2021-07-08 20:44:20,027] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:20,111] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:20,118] {logging_mixin.py:104} INFO - [2021-07-08 20:44:20,118] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:44:20,129] {logging_mixin.py:104} INFO - [2021-07-08 20:44:20,129] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:44:20,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 20:44:50,452] {scheduler_job.py:182} INFO - Started process (PID=25760) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:50,455] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:44:50,456] {logging_mixin.py:104} INFO - [2021-07-08 20:44:50,456] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:50,544] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:44:50,551] {logging_mixin.py:104} INFO - [2021-07-08 20:44:50,551] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:44:50,559] {logging_mixin.py:104} INFO - [2021-07-08 20:44:50,559] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:44:50,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 20:45:20,756] {scheduler_job.py:182} INFO - Started process (PID=25825) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:20,758] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:45:20,758] {logging_mixin.py:104} INFO - [2021-07-08 20:45:20,758] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:20,878] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:20,890] {logging_mixin.py:104} INFO - [2021-07-08 20:45:20,890] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:45:20,906] {logging_mixin.py:104} INFO - [2021-07-08 20:45:20,906] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:45:20,925] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 20:45:51,094] {scheduler_job.py:182} INFO - Started process (PID=25878) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:51,101] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:45:51,102] {logging_mixin.py:104} INFO - [2021-07-08 20:45:51,102] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:51,188] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:45:51,196] {logging_mixin.py:104} INFO - [2021-07-08 20:45:51,196] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:45:51,208] {logging_mixin.py:104} INFO - [2021-07-08 20:45:51,208] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:45:51,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 20:46:21,627] {scheduler_job.py:182} INFO - Started process (PID=25941) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:21,630] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:46:21,631] {logging_mixin.py:104} INFO - [2021-07-08 20:46:21,631] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:21,724] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:21,732] {logging_mixin.py:104} INFO - [2021-07-08 20:46:21,732] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:46:21,741] {logging_mixin.py:104} INFO - [2021-07-08 20:46:21,740] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:46:21,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 20:46:51,911] {scheduler_job.py:182} INFO - Started process (PID=25994) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:51,913] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:46:51,914] {logging_mixin.py:104} INFO - [2021-07-08 20:46:51,914] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:52,001] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:46:52,008] {logging_mixin.py:104} INFO - [2021-07-08 20:46:52,008] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:46:52,017] {logging_mixin.py:104} INFO - [2021-07-08 20:46:52,017] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:46:52,024] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 20:47:22,278] {scheduler_job.py:182} INFO - Started process (PID=26059) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:22,280] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:47:22,281] {logging_mixin.py:104} INFO - [2021-07-08 20:47:22,281] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:22,382] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:22,390] {logging_mixin.py:104} INFO - [2021-07-08 20:47:22,390] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:47:22,400] {logging_mixin.py:104} INFO - [2021-07-08 20:47:22,400] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:47:22,408] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 20:47:52,879] {scheduler_job.py:182} INFO - Started process (PID=26123) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:52,882] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:47:52,883] {logging_mixin.py:104} INFO - [2021-07-08 20:47:52,883] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:53,013] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:47:53,021] {logging_mixin.py:104} INFO - [2021-07-08 20:47:53,021] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:47:53,029] {logging_mixin.py:104} INFO - [2021-07-08 20:47:53,029] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:47:53,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-07-08 20:48:23,629] {scheduler_job.py:182} INFO - Started process (PID=26177) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:23,631] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:48:23,632] {logging_mixin.py:104} INFO - [2021-07-08 20:48:23,632] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:23,725] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:23,732] {logging_mixin.py:104} INFO - [2021-07-08 20:48:23,732] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:48:23,742] {logging_mixin.py:104} INFO - [2021-07-08 20:48:23,742] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:48:23,751] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 20:48:54,418] {scheduler_job.py:182} INFO - Started process (PID=26241) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:54,420] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:48:54,421] {logging_mixin.py:104} INFO - [2021-07-08 20:48:54,421] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:54,547] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:48:54,555] {logging_mixin.py:104} INFO - [2021-07-08 20:48:54,555] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:48:54,564] {logging_mixin.py:104} INFO - [2021-07-08 20:48:54,564] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:48:54,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.158 seconds
[2021-07-08 20:49:24,917] {scheduler_job.py:182} INFO - Started process (PID=26304) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:24,919] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:49:24,920] {logging_mixin.py:104} INFO - [2021-07-08 20:49:24,920] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:25,067] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:25,075] {logging_mixin.py:104} INFO - [2021-07-08 20:49:25,075] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:49:25,085] {logging_mixin.py:104} INFO - [2021-07-08 20:49:25,085] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:49:25,092] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.177 seconds
[2021-07-08 20:49:55,578] {scheduler_job.py:182} INFO - Started process (PID=26357) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:55,581] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:49:55,582] {logging_mixin.py:104} INFO - [2021-07-08 20:49:55,582] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:55,711] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:49:55,718] {logging_mixin.py:104} INFO - [2021-07-08 20:49:55,718] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:49:55,727] {logging_mixin.py:104} INFO - [2021-07-08 20:49:55,727] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:49:55,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-07-08 20:50:25,844] {scheduler_job.py:182} INFO - Started process (PID=26421) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:25,849] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:50:25,850] {logging_mixin.py:104} INFO - [2021-07-08 20:50:25,850] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:25,968] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:25,974] {logging_mixin.py:104} INFO - [2021-07-08 20:50:25,974] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:50:25,983] {logging_mixin.py:104} INFO - [2021-07-08 20:50:25,983] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:50:25,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 20:50:56,414] {scheduler_job.py:182} INFO - Started process (PID=26474) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:56,415] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:50:56,416] {logging_mixin.py:104} INFO - [2021-07-08 20:50:56,416] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:56,575] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:50:56,585] {logging_mixin.py:104} INFO - [2021-07-08 20:50:56,585] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:50:56,603] {logging_mixin.py:104} INFO - [2021-07-08 20:50:56,603] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:50:56,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.205 seconds
[2021-07-08 20:51:27,335] {scheduler_job.py:182} INFO - Started process (PID=26539) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:27,336] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:51:27,337] {logging_mixin.py:104} INFO - [2021-07-08 20:51:27,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:27,479] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:27,490] {logging_mixin.py:104} INFO - [2021-07-08 20:51:27,490] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:51:27,500] {logging_mixin.py:104} INFO - [2021-07-08 20:51:27,500] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:51:27,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.177 seconds
[2021-07-08 20:51:58,067] {scheduler_job.py:182} INFO - Started process (PID=26602) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:58,068] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:51:58,069] {logging_mixin.py:104} INFO - [2021-07-08 20:51:58,069] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:58,204] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:51:58,214] {logging_mixin.py:104} INFO - [2021-07-08 20:51:58,214] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:51:58,226] {logging_mixin.py:104} INFO - [2021-07-08 20:51:58,226] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:51:58,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.170 seconds
[2021-07-08 20:52:28,704] {scheduler_job.py:182} INFO - Started process (PID=26658) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:28,707] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:52:28,708] {logging_mixin.py:104} INFO - [2021-07-08 20:52:28,708] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:28,821] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:28,830] {logging_mixin.py:104} INFO - [2021-07-08 20:52:28,830] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:52:28,838] {logging_mixin.py:104} INFO - [2021-07-08 20:52:28,838] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:52:28,845] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 20:52:59,143] {scheduler_job.py:182} INFO - Started process (PID=26722) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:59,144] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:52:59,146] {logging_mixin.py:104} INFO - [2021-07-08 20:52:59,145] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:59,261] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:52:59,268] {logging_mixin.py:104} INFO - [2021-07-08 20:52:59,268] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:52:59,276] {logging_mixin.py:104} INFO - [2021-07-08 20:52:59,276] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:52:59,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 20:53:29,386] {scheduler_job.py:182} INFO - Started process (PID=26776) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:29,388] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:53:29,390] {logging_mixin.py:104} INFO - [2021-07-08 20:53:29,389] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:29,505] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:29,512] {logging_mixin.py:104} INFO - [2021-07-08 20:53:29,512] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:53:29,520] {logging_mixin.py:104} INFO - [2021-07-08 20:53:29,520] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:53:29,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-07-08 20:53:59,763] {scheduler_job.py:182} INFO - Started process (PID=26839) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:59,764] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:53:59,765] {logging_mixin.py:104} INFO - [2021-07-08 20:53:59,765] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:59,890] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:53:59,898] {logging_mixin.py:104} INFO - [2021-07-08 20:53:59,898] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:53:59,906] {logging_mixin.py:104} INFO - [2021-07-08 20:53:59,906] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:53:59,912] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 20:54:29,962] {scheduler_job.py:182} INFO - Started process (PID=26902) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:54:29,964] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:54:29,965] {logging_mixin.py:104} INFO - [2021-07-08 20:54:29,965] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:54:30,069] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:54:30,076] {logging_mixin.py:104} INFO - [2021-07-08 20:54:30,076] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:54:30,084] {logging_mixin.py:104} INFO - [2021-07-08 20:54:30,084] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:54:30,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 20:55:00,313] {scheduler_job.py:182} INFO - Started process (PID=26955) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:00,315] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:55:00,316] {logging_mixin.py:104} INFO - [2021-07-08 20:55:00,316] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:00,402] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:00,409] {logging_mixin.py:104} INFO - [2021-07-08 20:55:00,409] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:55:00,417] {logging_mixin.py:104} INFO - [2021-07-08 20:55:00,417] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:55:00,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 20:55:30,697] {scheduler_job.py:182} INFO - Started process (PID=27017) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:30,701] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:55:30,702] {logging_mixin.py:104} INFO - [2021-07-08 20:55:30,702] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:30,835] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:55:30,843] {logging_mixin.py:104} INFO - [2021-07-08 20:55:30,843] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:55:30,851] {logging_mixin.py:104} INFO - [2021-07-08 20:55:30,851] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:55:30,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.166 seconds
[2021-07-08 20:56:01,115] {scheduler_job.py:182} INFO - Started process (PID=27082) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:01,116] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:56:01,117] {logging_mixin.py:104} INFO - [2021-07-08 20:56:01,117] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:01,204] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:01,212] {logging_mixin.py:104} INFO - [2021-07-08 20:56:01,212] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:56:01,221] {logging_mixin.py:104} INFO - [2021-07-08 20:56:01,221] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:56:01,229] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 20:56:31,601] {scheduler_job.py:182} INFO - Started process (PID=27135) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:31,604] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:56:31,606] {logging_mixin.py:104} INFO - [2021-07-08 20:56:31,605] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:31,709] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:56:31,716] {logging_mixin.py:104} INFO - [2021-07-08 20:56:31,716] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:56:31,724] {logging_mixin.py:104} INFO - [2021-07-08 20:56:31,724] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:56:31,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 20:57:01,911] {scheduler_job.py:182} INFO - Started process (PID=27200) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:01,915] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:57:01,916] {logging_mixin.py:104} INFO - [2021-07-08 20:57:01,916] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:01,998] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:02,005] {logging_mixin.py:104} INFO - [2021-07-08 20:57:02,005] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:57:02,012] {logging_mixin.py:104} INFO - [2021-07-08 20:57:02,012] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:57:02,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 20:57:32,618] {scheduler_job.py:182} INFO - Started process (PID=27264) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:32,619] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:57:32,620] {logging_mixin.py:104} INFO - [2021-07-08 20:57:32,620] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:32,700] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:57:32,707] {logging_mixin.py:104} INFO - [2021-07-08 20:57:32,707] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:57:32,715] {logging_mixin.py:104} INFO - [2021-07-08 20:57:32,715] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:57:32,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 20:58:02,950] {scheduler_job.py:182} INFO - Started process (PID=27319) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:02,953] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:58:02,954] {logging_mixin.py:104} INFO - [2021-07-08 20:58:02,954] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:03,068] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:03,075] {logging_mixin.py:104} INFO - [2021-07-08 20:58:03,075] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:58:03,083] {logging_mixin.py:104} INFO - [2021-07-08 20:58:03,083] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:58:03,089] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 20:58:33,221] {scheduler_job.py:182} INFO - Started process (PID=27383) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:33,225] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:58:33,227] {logging_mixin.py:104} INFO - [2021-07-08 20:58:33,226] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:33,319] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:58:33,326] {logging_mixin.py:104} INFO - [2021-07-08 20:58:33,326] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:58:33,334] {logging_mixin.py:104} INFO - [2021-07-08 20:58:33,334] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:58:33,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 20:59:03,574] {scheduler_job.py:182} INFO - Started process (PID=27447) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:03,576] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:59:03,576] {logging_mixin.py:104} INFO - [2021-07-08 20:59:03,576] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:03,670] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:03,677] {logging_mixin.py:104} INFO - [2021-07-08 20:59:03,677] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:59:03,685] {logging_mixin.py:104} INFO - [2021-07-08 20:59:03,685] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:59:03,692] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 20:59:33,864] {scheduler_job.py:182} INFO - Started process (PID=27502) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:33,865] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 20:59:33,865] {logging_mixin.py:104} INFO - [2021-07-08 20:59:33,865] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:33,948] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 20:59:33,955] {logging_mixin.py:104} INFO - [2021-07-08 20:59:33,955] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 20:59:33,963] {logging_mixin.py:104} INFO - [2021-07-08 20:59:33,963] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 20:59:33,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:00:04,210] {scheduler_job.py:182} INFO - Started process (PID=27565) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:04,212] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:00:04,213] {logging_mixin.py:104} INFO - [2021-07-08 21:00:04,213] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:04,290] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:04,298] {logging_mixin.py:104} INFO - [2021-07-08 21:00:04,298] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:00:04,308] {logging_mixin.py:104} INFO - [2021-07-08 21:00:04,308] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:00:04,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:00:34,440] {scheduler_job.py:182} INFO - Started process (PID=27631) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:34,442] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:00:34,444] {logging_mixin.py:104} INFO - [2021-07-08 21:00:34,443] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:34,525] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:00:34,532] {logging_mixin.py:104} INFO - [2021-07-08 21:00:34,532] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:00:34,541] {logging_mixin.py:104} INFO - [2021-07-08 21:00:34,541] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:00:34,547] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:01:04,864] {scheduler_job.py:182} INFO - Started process (PID=27684) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:04,866] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:01:04,867] {logging_mixin.py:104} INFO - [2021-07-08 21:01:04,866] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:04,947] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:04,954] {logging_mixin.py:104} INFO - [2021-07-08 21:01:04,954] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:01:04,962] {logging_mixin.py:104} INFO - [2021-07-08 21:01:04,962] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:01:04,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 21:01:35,354] {scheduler_job.py:182} INFO - Started process (PID=27747) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:35,356] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:01:35,356] {logging_mixin.py:104} INFO - [2021-07-08 21:01:35,356] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:35,439] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:01:35,446] {logging_mixin.py:104} INFO - [2021-07-08 21:01:35,446] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:01:35,454] {logging_mixin.py:104} INFO - [2021-07-08 21:01:35,454] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:01:35,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:02:05,858] {scheduler_job.py:182} INFO - Started process (PID=27810) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:05,860] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:02:05,860] {logging_mixin.py:104} INFO - [2021-07-08 21:02:05,860] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:05,944] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:05,952] {logging_mixin.py:104} INFO - [2021-07-08 21:02:05,951] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:02:05,960] {logging_mixin.py:104} INFO - [2021-07-08 21:02:05,960] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:02:05,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:02:36,144] {scheduler_job.py:182} INFO - Started process (PID=27863) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:36,147] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:02:36,148] {logging_mixin.py:104} INFO - [2021-07-08 21:02:36,148] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:36,228] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:02:36,235] {logging_mixin.py:104} INFO - [2021-07-08 21:02:36,235] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:02:36,242] {logging_mixin.py:104} INFO - [2021-07-08 21:02:36,242] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:02:36,249] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:03:06,530] {scheduler_job.py:182} INFO - Started process (PID=27925) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:06,532] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:03:06,534] {logging_mixin.py:104} INFO - [2021-07-08 21:03:06,533] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:06,615] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:06,622] {logging_mixin.py:104} INFO - [2021-07-08 21:03:06,622] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:03:06,630] {logging_mixin.py:104} INFO - [2021-07-08 21:03:06,630] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:03:06,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 21:03:36,861] {scheduler_job.py:182} INFO - Started process (PID=27989) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:36,864] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:03:36,865] {logging_mixin.py:104} INFO - [2021-07-08 21:03:36,865] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:36,946] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:03:36,953] {logging_mixin.py:104} INFO - [2021-07-08 21:03:36,953] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:03:36,961] {logging_mixin.py:104} INFO - [2021-07-08 21:03:36,961] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:03:36,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 21:04:07,272] {scheduler_job.py:182} INFO - Started process (PID=28042) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:07,273] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:04:07,274] {logging_mixin.py:104} INFO - [2021-07-08 21:04:07,274] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:07,363] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:07,370] {logging_mixin.py:104} INFO - [2021-07-08 21:04:07,370] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:04:07,378] {logging_mixin.py:104} INFO - [2021-07-08 21:04:07,378] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:04:07,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 21:04:37,416] {scheduler_job.py:182} INFO - Started process (PID=28106) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:37,417] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:04:37,418] {logging_mixin.py:104} INFO - [2021-07-08 21:04:37,418] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:37,504] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:04:37,511] {logging_mixin.py:104} INFO - [2021-07-08 21:04:37,511] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:04:37,519] {logging_mixin.py:104} INFO - [2021-07-08 21:04:37,519] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:04:37,526] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:05:07,887] {scheduler_job.py:182} INFO - Started process (PID=28173) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:07,889] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:05:07,890] {logging_mixin.py:104} INFO - [2021-07-08 21:05:07,890] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:08,001] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:08,008] {logging_mixin.py:104} INFO - [2021-07-08 21:05:08,007] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:05:08,015] {logging_mixin.py:104} INFO - [2021-07-08 21:05:08,015] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:05:08,022] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.138 seconds
[2021-07-08 21:05:38,084] {scheduler_job.py:182} INFO - Started process (PID=28226) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:38,086] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:05:38,087] {logging_mixin.py:104} INFO - [2021-07-08 21:05:38,086] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:38,171] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:05:38,179] {logging_mixin.py:104} INFO - [2021-07-08 21:05:38,178] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:05:38,186] {logging_mixin.py:104} INFO - [2021-07-08 21:05:38,186] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:05:38,193] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:06:08,455] {scheduler_job.py:182} INFO - Started process (PID=28289) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:08,457] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:06:08,458] {logging_mixin.py:104} INFO - [2021-07-08 21:06:08,458] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:08,545] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:08,551] {logging_mixin.py:104} INFO - [2021-07-08 21:06:08,551] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:06:08,560] {logging_mixin.py:104} INFO - [2021-07-08 21:06:08,559] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:06:08,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 21:06:38,823] {scheduler_job.py:182} INFO - Started process (PID=28352) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:38,824] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:06:38,824] {logging_mixin.py:104} INFO - [2021-07-08 21:06:38,824] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:38,906] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:06:38,913] {logging_mixin.py:104} INFO - [2021-07-08 21:06:38,913] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:06:38,921] {logging_mixin.py:104} INFO - [2021-07-08 21:06:38,921] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:06:38,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:07:09,260] {scheduler_job.py:182} INFO - Started process (PID=28406) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:09,261] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:07:09,262] {logging_mixin.py:104} INFO - [2021-07-08 21:07:09,262] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:09,354] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:09,361] {logging_mixin.py:104} INFO - [2021-07-08 21:07:09,361] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:07:09,369] {logging_mixin.py:104} INFO - [2021-07-08 21:07:09,369] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:07:09,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 21:07:39,535] {scheduler_job.py:182} INFO - Started process (PID=28469) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:39,536] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:07:39,537] {logging_mixin.py:104} INFO - [2021-07-08 21:07:39,537] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:39,619] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:07:39,627] {logging_mixin.py:104} INFO - [2021-07-08 21:07:39,627] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:07:39,636] {logging_mixin.py:104} INFO - [2021-07-08 21:07:39,636] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:07:39,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:08:09,914] {scheduler_job.py:182} INFO - Started process (PID=28532) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:09,916] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:08:09,916] {logging_mixin.py:104} INFO - [2021-07-08 21:08:09,916] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:10,024] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:10,031] {logging_mixin.py:104} INFO - [2021-07-08 21:08:10,031] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:08:10,039] {logging_mixin.py:104} INFO - [2021-07-08 21:08:10,039] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:08:10,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 21:08:40,385] {scheduler_job.py:182} INFO - Started process (PID=28585) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:40,386] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:08:40,387] {logging_mixin.py:104} INFO - [2021-07-08 21:08:40,387] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:40,469] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:08:40,476] {logging_mixin.py:104} INFO - [2021-07-08 21:08:40,476] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:08:40,485] {logging_mixin.py:104} INFO - [2021-07-08 21:08:40,485] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:08:40,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 21:09:10,847] {scheduler_job.py:182} INFO - Started process (PID=28648) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:10,851] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:09:10,852] {logging_mixin.py:104} INFO - [2021-07-08 21:09:10,852] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:10,957] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:10,964] {logging_mixin.py:104} INFO - [2021-07-08 21:09:10,964] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:09:10,971] {logging_mixin.py:104} INFO - [2021-07-08 21:09:10,971] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:09:10,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 21:09:41,220] {scheduler_job.py:182} INFO - Started process (PID=28712) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:41,221] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:09:41,221] {logging_mixin.py:104} INFO - [2021-07-08 21:09:41,221] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:41,307] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:09:41,314] {logging_mixin.py:104} INFO - [2021-07-08 21:09:41,314] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:09:41,323] {logging_mixin.py:104} INFO - [2021-07-08 21:09:41,323] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:09:41,331] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:10:11,755] {scheduler_job.py:182} INFO - Started process (PID=28765) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:11,757] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:10:11,757] {logging_mixin.py:104} INFO - [2021-07-08 21:10:11,757] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:11,869] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:11,876] {logging_mixin.py:104} INFO - [2021-07-08 21:10:11,876] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:10:11,884] {logging_mixin.py:104} INFO - [2021-07-08 21:10:11,884] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:10:11,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.138 seconds
[2021-07-08 21:10:42,366] {scheduler_job.py:182} INFO - Started process (PID=28828) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:42,368] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:10:42,369] {logging_mixin.py:104} INFO - [2021-07-08 21:10:42,369] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:42,449] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:10:42,456] {logging_mixin.py:104} INFO - [2021-07-08 21:10:42,455] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:10:42,464] {logging_mixin.py:104} INFO - [2021-07-08 21:10:42,464] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:10:42,471] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-07-08 21:11:12,702] {scheduler_job.py:182} INFO - Started process (PID=28890) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:12,704] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:11:12,705] {logging_mixin.py:104} INFO - [2021-07-08 21:11:12,705] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:12,819] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:12,826] {logging_mixin.py:104} INFO - [2021-07-08 21:11:12,826] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:11:12,835] {logging_mixin.py:104} INFO - [2021-07-08 21:11:12,835] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:11:12,842] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 21:11:43,259] {scheduler_job.py:182} INFO - Started process (PID=28945) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:43,260] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:11:43,261] {logging_mixin.py:104} INFO - [2021-07-08 21:11:43,261] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:43,370] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:11:43,378] {logging_mixin.py:104} INFO - [2021-07-08 21:11:43,378] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:11:43,388] {logging_mixin.py:104} INFO - [2021-07-08 21:11:43,388] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:11:43,396] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 21:12:13,776] {scheduler_job.py:182} INFO - Started process (PID=29008) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:13,779] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:12:13,780] {logging_mixin.py:104} INFO - [2021-07-08 21:12:13,780] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:13,862] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:13,869] {logging_mixin.py:104} INFO - [2021-07-08 21:12:13,869] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:12:13,877] {logging_mixin.py:104} INFO - [2021-07-08 21:12:13,876] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:12:13,883] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:12:44,185] {scheduler_job.py:182} INFO - Started process (PID=29071) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:44,188] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:12:44,190] {logging_mixin.py:104} INFO - [2021-07-08 21:12:44,189] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:44,294] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:12:44,301] {logging_mixin.py:104} INFO - [2021-07-08 21:12:44,301] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:12:44,309] {logging_mixin.py:104} INFO - [2021-07-08 21:12:44,309] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:12:44,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 21:13:14,714] {scheduler_job.py:182} INFO - Started process (PID=29134) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:14,715] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:13:14,716] {logging_mixin.py:104} INFO - [2021-07-08 21:13:14,716] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:14,823] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:14,830] {logging_mixin.py:104} INFO - [2021-07-08 21:13:14,830] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:13:14,838] {logging_mixin.py:104} INFO - [2021-07-08 21:13:14,838] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:13:14,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 21:13:45,306] {scheduler_job.py:182} INFO - Started process (PID=29188) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:45,310] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:13:45,311] {logging_mixin.py:104} INFO - [2021-07-08 21:13:45,311] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:45,429] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:13:45,437] {logging_mixin.py:104} INFO - [2021-07-08 21:13:45,437] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:13:45,445] {logging_mixin.py:104} INFO - [2021-07-08 21:13:45,445] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:13:45,451] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 21:14:15,720] {scheduler_job.py:182} INFO - Started process (PID=29252) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:15,722] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:14:15,722] {logging_mixin.py:104} INFO - [2021-07-08 21:14:15,722] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:15,804] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:15,811] {logging_mixin.py:104} INFO - [2021-07-08 21:14:15,811] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:14:15,819] {logging_mixin.py:104} INFO - [2021-07-08 21:14:15,819] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:14:15,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:14:46,095] {scheduler_job.py:182} INFO - Started process (PID=29315) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:46,097] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:14:46,098] {logging_mixin.py:104} INFO - [2021-07-08 21:14:46,098] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:46,219] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:14:46,227] {logging_mixin.py:104} INFO - [2021-07-08 21:14:46,226] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:14:46,236] {logging_mixin.py:104} INFO - [2021-07-08 21:14:46,236] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:14:46,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 21:15:16,551] {scheduler_job.py:182} INFO - Started process (PID=29368) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:16,552] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:15:16,553] {logging_mixin.py:104} INFO - [2021-07-08 21:15:16,552] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:16,637] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:16,646] {logging_mixin.py:104} INFO - [2021-07-08 21:15:16,646] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:15:16,656] {logging_mixin.py:104} INFO - [2021-07-08 21:15:16,656] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:15:16,665] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 21:15:46,919] {scheduler_job.py:182} INFO - Started process (PID=29431) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:46,920] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:15:46,921] {logging_mixin.py:104} INFO - [2021-07-08 21:15:46,921] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:47,000] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:15:47,007] {logging_mixin.py:104} INFO - [2021-07-08 21:15:47,007] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:15:47,015] {logging_mixin.py:104} INFO - [2021-07-08 21:15:47,015] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:15:47,022] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 21:16:17,350] {scheduler_job.py:182} INFO - Started process (PID=29495) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:17,352] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:16:17,352] {logging_mixin.py:104} INFO - [2021-07-08 21:16:17,352] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:17,471] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:17,483] {logging_mixin.py:104} INFO - [2021-07-08 21:16:17,482] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:16:17,493] {logging_mixin.py:104} INFO - [2021-07-08 21:16:17,493] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:16:17,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 21:16:47,830] {scheduler_job.py:182} INFO - Started process (PID=29549) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:47,832] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:16:47,834] {logging_mixin.py:104} INFO - [2021-07-08 21:16:47,833] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:47,914] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:16:47,921] {logging_mixin.py:104} INFO - [2021-07-08 21:16:47,921] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:16:47,929] {logging_mixin.py:104} INFO - [2021-07-08 21:16:47,929] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:16:47,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 21:17:18,282] {scheduler_job.py:182} INFO - Started process (PID=29613) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:18,288] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:17:18,289] {logging_mixin.py:104} INFO - [2021-07-08 21:17:18,289] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:18,373] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:18,379] {logging_mixin.py:104} INFO - [2021-07-08 21:17:18,379] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:17:18,387] {logging_mixin.py:104} INFO - [2021-07-08 21:17:18,387] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:17:18,394] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 21:17:48,554] {scheduler_job.py:182} INFO - Started process (PID=29677) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:48,555] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:17:48,556] {logging_mixin.py:104} INFO - [2021-07-08 21:17:48,556] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:48,637] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:17:48,644] {logging_mixin.py:104} INFO - [2021-07-08 21:17:48,644] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:17:48,652] {logging_mixin.py:104} INFO - [2021-07-08 21:17:48,652] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:17:48,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.108 seconds
[2021-07-08 21:18:18,865] {scheduler_job.py:182} INFO - Started process (PID=29730) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:18,866] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:18:18,867] {logging_mixin.py:104} INFO - [2021-07-08 21:18:18,867] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:18,945] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:18,952] {logging_mixin.py:104} INFO - [2021-07-08 21:18:18,952] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:18:18,960] {logging_mixin.py:104} INFO - [2021-07-08 21:18:18,960] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:18:18,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.106 seconds
[2021-07-08 21:18:49,219] {scheduler_job.py:182} INFO - Started process (PID=29794) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:49,220] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:18:49,221] {logging_mixin.py:104} INFO - [2021-07-08 21:18:49,221] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:49,302] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:18:49,308] {logging_mixin.py:104} INFO - [2021-07-08 21:18:49,308] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:18:49,316] {logging_mixin.py:104} INFO - [2021-07-08 21:18:49,316] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:18:49,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 21:19:19,392] {scheduler_job.py:182} INFO - Started process (PID=29859) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:19,393] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:19:19,394] {logging_mixin.py:104} INFO - [2021-07-08 21:19:19,394] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:19,471] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:19,478] {logging_mixin.py:104} INFO - [2021-07-08 21:19:19,478] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:19:19,486] {logging_mixin.py:104} INFO - [2021-07-08 21:19:19,486] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:19:19,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.102 seconds
[2021-07-08 21:19:49,619] {scheduler_job.py:182} INFO - Started process (PID=29913) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:49,620] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:19:49,620] {logging_mixin.py:104} INFO - [2021-07-08 21:19:49,620] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:49,703] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:19:49,711] {logging_mixin.py:104} INFO - [2021-07-08 21:19:49,710] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:19:49,719] {logging_mixin.py:104} INFO - [2021-07-08 21:19:49,719] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:19:49,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 21:20:20,000] {scheduler_job.py:182} INFO - Started process (PID=29976) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:20,001] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:20:20,002] {logging_mixin.py:104} INFO - [2021-07-08 21:20:20,001] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:20,081] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:20,088] {logging_mixin.py:104} INFO - [2021-07-08 21:20:20,088] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:20:20,097] {logging_mixin.py:104} INFO - [2021-07-08 21:20:20,097] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:20:20,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.106 seconds
[2021-07-08 21:20:50,166] {scheduler_job.py:182} INFO - Started process (PID=30039) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:50,168] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:20:50,169] {logging_mixin.py:104} INFO - [2021-07-08 21:20:50,169] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:50,245] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:20:50,252] {logging_mixin.py:104} INFO - [2021-07-08 21:20:50,252] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:20:50,261] {logging_mixin.py:104} INFO - [2021-07-08 21:20:50,261] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:20:50,267] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.103 seconds
[2021-07-08 21:21:20,614] {scheduler_job.py:182} INFO - Started process (PID=30093) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:20,617] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:21:20,618] {logging_mixin.py:104} INFO - [2021-07-08 21:21:20,618] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:20,699] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:20,707] {logging_mixin.py:104} INFO - [2021-07-08 21:21:20,707] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:21:20,715] {logging_mixin.py:104} INFO - [2021-07-08 21:21:20,715] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:21:20,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:21:50,968] {scheduler_job.py:182} INFO - Started process (PID=30156) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:50,969] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:21:50,969] {logging_mixin.py:104} INFO - [2021-07-08 21:21:50,969] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:51,051] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:21:51,059] {logging_mixin.py:104} INFO - [2021-07-08 21:21:51,059] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:21:51,068] {logging_mixin.py:104} INFO - [2021-07-08 21:21:51,068] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:21:51,076] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:22:21,542] {scheduler_job.py:182} INFO - Started process (PID=30220) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:21,544] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:22:21,545] {logging_mixin.py:104} INFO - [2021-07-08 21:22:21,545] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:21,652] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:21,660] {logging_mixin.py:104} INFO - [2021-07-08 21:22:21,660] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:22:21,667] {logging_mixin.py:104} INFO - [2021-07-08 21:22:21,667] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:22:21,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 21:22:51,833] {scheduler_job.py:182} INFO - Started process (PID=30274) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:51,834] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:22:51,835] {logging_mixin.py:104} INFO - [2021-07-08 21:22:51,835] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:51,924] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:22:51,933] {logging_mixin.py:104} INFO - [2021-07-08 21:22:51,933] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:22:51,943] {logging_mixin.py:104} INFO - [2021-07-08 21:22:51,943] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:22:51,951] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 21:23:22,143] {scheduler_job.py:182} INFO - Started process (PID=30338) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:22,144] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:23:22,146] {logging_mixin.py:104} INFO - [2021-07-08 21:23:22,146] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:22,228] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:22,235] {logging_mixin.py:104} INFO - [2021-07-08 21:23:22,235] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:23:22,243] {logging_mixin.py:104} INFO - [2021-07-08 21:23:22,243] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:23:22,250] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 21:23:52,509] {scheduler_job.py:182} INFO - Started process (PID=30403) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:52,512] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:23:52,513] {logging_mixin.py:104} INFO - [2021-07-08 21:23:52,513] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:52,596] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:23:52,602] {logging_mixin.py:104} INFO - [2021-07-08 21:23:52,602] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:23:52,610] {logging_mixin.py:104} INFO - [2021-07-08 21:23:52,610] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:23:52,617] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:24:22,880] {scheduler_job.py:182} INFO - Started process (PID=30456) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:22,882] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:24:22,883] {logging_mixin.py:104} INFO - [2021-07-08 21:24:22,883] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:22,965] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:22,972] {logging_mixin.py:104} INFO - [2021-07-08 21:24:22,972] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:24:22,980] {logging_mixin.py:104} INFO - [2021-07-08 21:24:22,980] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:24:22,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:24:53,241] {scheduler_job.py:182} INFO - Started process (PID=30522) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:53,242] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:24:53,242] {logging_mixin.py:104} INFO - [2021-07-08 21:24:53,242] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:53,326] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:24:53,333] {logging_mixin.py:104} INFO - [2021-07-08 21:24:53,333] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:24:53,341] {logging_mixin.py:104} INFO - [2021-07-08 21:24:53,341] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:24:53,348] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 21:25:23,470] {scheduler_job.py:182} INFO - Started process (PID=30585) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:23,472] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:25:23,472] {logging_mixin.py:104} INFO - [2021-07-08 21:25:23,472] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:23,549] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:23,556] {logging_mixin.py:104} INFO - [2021-07-08 21:25:23,556] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:25:23,564] {logging_mixin.py:104} INFO - [2021-07-08 21:25:23,564] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:25:23,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.102 seconds
[2021-07-08 21:25:53,852] {scheduler_job.py:182} INFO - Started process (PID=30638) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:53,855] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:25:53,856] {logging_mixin.py:104} INFO - [2021-07-08 21:25:53,856] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:53,937] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:25:53,945] {logging_mixin.py:104} INFO - [2021-07-08 21:25:53,945] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:25:53,953] {logging_mixin.py:104} INFO - [2021-07-08 21:25:53,953] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:25:53,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:26:24,291] {scheduler_job.py:182} INFO - Started process (PID=30702) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:24,292] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:26:24,293] {logging_mixin.py:104} INFO - [2021-07-08 21:26:24,293] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:24,393] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:24,401] {logging_mixin.py:104} INFO - [2021-07-08 21:26:24,401] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:26:24,409] {logging_mixin.py:104} INFO - [2021-07-08 21:26:24,409] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:26:24,416] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 21:26:54,708] {scheduler_job.py:182} INFO - Started process (PID=30766) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:54,709] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:26:54,710] {logging_mixin.py:104} INFO - [2021-07-08 21:26:54,709] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:54,790] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:26:54,797] {logging_mixin.py:104} INFO - [2021-07-08 21:26:54,797] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:26:54,804] {logging_mixin.py:104} INFO - [2021-07-08 21:26:54,804] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:26:54,811] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.106 seconds
[2021-07-08 21:27:24,977] {scheduler_job.py:182} INFO - Started process (PID=30819) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:24,978] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:27:24,979] {logging_mixin.py:104} INFO - [2021-07-08 21:27:24,979] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:25,062] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:25,069] {logging_mixin.py:104} INFO - [2021-07-08 21:27:25,069] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:27:25,077] {logging_mixin.py:104} INFO - [2021-07-08 21:27:25,077] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:27:25,085] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:27:55,343] {scheduler_job.py:182} INFO - Started process (PID=30884) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:55,345] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:27:55,345] {logging_mixin.py:104} INFO - [2021-07-08 21:27:55,345] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:55,459] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:27:55,466] {logging_mixin.py:104} INFO - [2021-07-08 21:27:55,466] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:27:55,474] {logging_mixin.py:104} INFO - [2021-07-08 21:27:55,474] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:27:55,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-07-08 21:28:25,538] {scheduler_job.py:182} INFO - Started process (PID=30948) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:25,539] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:28:25,540] {logging_mixin.py:104} INFO - [2021-07-08 21:28:25,540] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:25,628] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:25,637] {logging_mixin.py:104} INFO - [2021-07-08 21:28:25,637] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:28:25,646] {logging_mixin.py:104} INFO - [2021-07-08 21:28:25,646] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:28:25,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 21:28:55,955] {scheduler_job.py:182} INFO - Started process (PID=31001) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:55,956] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:28:55,956] {logging_mixin.py:104} INFO - [2021-07-08 21:28:55,956] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:56,039] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:28:56,046] {logging_mixin.py:104} INFO - [2021-07-08 21:28:56,046] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:28:56,054] {logging_mixin.py:104} INFO - [2021-07-08 21:28:56,053] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:28:56,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:29:26,358] {scheduler_job.py:182} INFO - Started process (PID=31064) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:26,360] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:29:26,361] {logging_mixin.py:104} INFO - [2021-07-08 21:29:26,361] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:26,443] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:26,450] {logging_mixin.py:104} INFO - [2021-07-08 21:29:26,450] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:29:26,458] {logging_mixin.py:104} INFO - [2021-07-08 21:29:26,458] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:29:26,465] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 21:29:56,558] {scheduler_job.py:182} INFO - Started process (PID=31128) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:56,559] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:29:56,560] {logging_mixin.py:104} INFO - [2021-07-08 21:29:56,560] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:56,639] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:29:56,646] {logging_mixin.py:104} INFO - [2021-07-08 21:29:56,646] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:29:56,654] {logging_mixin.py:104} INFO - [2021-07-08 21:29:56,654] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:29:56,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.105 seconds
[2021-07-08 21:30:27,529] {scheduler_job.py:182} INFO - Started process (PID=31181) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:27,531] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:30:27,532] {logging_mixin.py:104} INFO - [2021-07-08 21:30:27,532] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:27,628] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:27,636] {logging_mixin.py:104} INFO - [2021-07-08 21:30:27,636] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:30:27,645] {logging_mixin.py:104} INFO - [2021-07-08 21:30:27,645] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:30:27,652] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 21:30:57,879] {scheduler_job.py:182} INFO - Started process (PID=31246) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:57,881] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:30:57,881] {logging_mixin.py:104} INFO - [2021-07-08 21:30:57,881] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:57,978] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:30:57,987] {logging_mixin.py:104} INFO - [2021-07-08 21:30:57,987] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:30:57,998] {logging_mixin.py:104} INFO - [2021-07-08 21:30:57,998] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:30:58,007] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 21:31:28,351] {scheduler_job.py:182} INFO - Started process (PID=31310) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:28,352] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:31:28,353] {logging_mixin.py:104} INFO - [2021-07-08 21:31:28,352] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:28,437] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:28,444] {logging_mixin.py:104} INFO - [2021-07-08 21:31:28,444] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:31:28,453] {logging_mixin.py:104} INFO - [2021-07-08 21:31:28,453] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:31:28,461] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:31:58,794] {scheduler_job.py:182} INFO - Started process (PID=31373) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:58,797] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:31:58,797] {logging_mixin.py:104} INFO - [2021-07-08 21:31:58,797] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:58,893] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:31:58,904] {logging_mixin.py:104} INFO - [2021-07-08 21:31:58,904] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:31:58,914] {logging_mixin.py:104} INFO - [2021-07-08 21:31:58,914] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:31:58,922] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 21:32:29,149] {scheduler_job.py:182} INFO - Started process (PID=31427) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:29,150] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:32:29,151] {logging_mixin.py:104} INFO - [2021-07-08 21:32:29,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:29,238] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:29,248] {logging_mixin.py:104} INFO - [2021-07-08 21:32:29,247] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:32:29,259] {logging_mixin.py:104} INFO - [2021-07-08 21:32:29,258] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:32:29,267] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 21:32:59,498] {scheduler_job.py:182} INFO - Started process (PID=31490) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:59,499] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:32:59,500] {logging_mixin.py:104} INFO - [2021-07-08 21:32:59,500] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:59,634] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:32:59,645] {logging_mixin.py:104} INFO - [2021-07-08 21:32:59,645] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:32:59,656] {logging_mixin.py:104} INFO - [2021-07-08 21:32:59,656] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:32:59,663] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-07-08 21:33:29,828] {scheduler_job.py:182} INFO - Started process (PID=31555) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:33:29,829] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:33:29,830] {logging_mixin.py:104} INFO - [2021-07-08 21:33:29,830] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:33:29,917] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:33:29,925] {logging_mixin.py:104} INFO - [2021-07-08 21:33:29,925] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:33:29,935] {logging_mixin.py:104} INFO - [2021-07-08 21:33:29,935] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:33:29,942] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 21:34:00,335] {scheduler_job.py:182} INFO - Started process (PID=31608) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:00,336] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:34:00,337] {logging_mixin.py:104} INFO - [2021-07-08 21:34:00,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:00,423] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:00,431] {logging_mixin.py:104} INFO - [2021-07-08 21:34:00,431] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:34:00,440] {logging_mixin.py:104} INFO - [2021-07-08 21:34:00,440] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:34:00,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 21:34:30,613] {scheduler_job.py:182} INFO - Started process (PID=31671) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:30,614] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:34:30,615] {logging_mixin.py:104} INFO - [2021-07-08 21:34:30,615] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:30,700] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:34:30,708] {logging_mixin.py:104} INFO - [2021-07-08 21:34:30,708] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:34:30,717] {logging_mixin.py:104} INFO - [2021-07-08 21:34:30,717] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:34:30,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 21:35:01,126] {scheduler_job.py:182} INFO - Started process (PID=31735) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:01,127] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:35:01,128] {logging_mixin.py:104} INFO - [2021-07-08 21:35:01,128] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:01,236] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:01,244] {logging_mixin.py:104} INFO - [2021-07-08 21:35:01,244] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:35:01,252] {logging_mixin.py:104} INFO - [2021-07-08 21:35:01,252] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:35:01,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 21:35:32,212] {scheduler_job.py:182} INFO - Started process (PID=31789) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:32,214] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:35:32,215] {logging_mixin.py:104} INFO - [2021-07-08 21:35:32,215] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:32,298] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:35:32,306] {logging_mixin.py:104} INFO - [2021-07-08 21:35:32,306] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:35:32,315] {logging_mixin.py:104} INFO - [2021-07-08 21:35:32,314] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:35:32,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:36:02,537] {scheduler_job.py:182} INFO - Started process (PID=31854) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:02,538] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:36:02,538] {logging_mixin.py:104} INFO - [2021-07-08 21:36:02,538] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:02,655] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:02,663] {logging_mixin.py:104} INFO - [2021-07-08 21:36:02,663] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:36:02,671] {logging_mixin.py:104} INFO - [2021-07-08 21:36:02,671] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:36:02,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 21:36:32,994] {scheduler_job.py:182} INFO - Started process (PID=31917) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:32,995] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:36:32,995] {logging_mixin.py:104} INFO - [2021-07-08 21:36:32,995] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:33,084] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:36:33,092] {logging_mixin.py:104} INFO - [2021-07-08 21:36:33,091] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:36:33,101] {logging_mixin.py:104} INFO - [2021-07-08 21:36:33,101] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:36:33,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 21:37:03,552] {scheduler_job.py:182} INFO - Started process (PID=31971) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:03,554] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:37:03,555] {logging_mixin.py:104} INFO - [2021-07-08 21:37:03,554] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:03,644] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:03,652] {logging_mixin.py:104} INFO - [2021-07-08 21:37:03,652] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:37:03,664] {logging_mixin.py:104} INFO - [2021-07-08 21:37:03,664] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:37:03,672] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 21:37:33,864] {scheduler_job.py:182} INFO - Started process (PID=32035) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:33,865] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:37:33,866] {logging_mixin.py:104} INFO - [2021-07-08 21:37:33,866] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:33,956] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:37:33,966] {logging_mixin.py:104} INFO - [2021-07-08 21:37:33,966] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:37:33,979] {logging_mixin.py:104} INFO - [2021-07-08 21:37:33,978] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:37:33,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 21:38:04,359] {scheduler_job.py:182} INFO - Started process (PID=32098) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:04,360] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:38:04,361] {logging_mixin.py:104} INFO - [2021-07-08 21:38:04,361] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:04,446] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:04,453] {logging_mixin.py:104} INFO - [2021-07-08 21:38:04,453] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:38:04,462] {logging_mixin.py:104} INFO - [2021-07-08 21:38:04,462] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:38:04,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:38:34,576] {scheduler_job.py:182} INFO - Started process (PID=32152) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:34,577] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:38:34,578] {logging_mixin.py:104} INFO - [2021-07-08 21:38:34,578] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:34,664] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:38:34,671] {logging_mixin.py:104} INFO - [2021-07-08 21:38:34,671] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:38:34,680] {logging_mixin.py:104} INFO - [2021-07-08 21:38:34,680] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:38:34,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 21:39:05,081] {scheduler_job.py:182} INFO - Started process (PID=32216) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:05,083] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:39:05,084] {logging_mixin.py:104} INFO - [2021-07-08 21:39:05,084] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:05,170] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:05,178] {logging_mixin.py:104} INFO - [2021-07-08 21:39:05,178] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:39:05,187] {logging_mixin.py:104} INFO - [2021-07-08 21:39:05,187] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:39:05,194] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 21:39:35,384] {scheduler_job.py:182} INFO - Started process (PID=32279) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:35,386] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:39:35,387] {logging_mixin.py:104} INFO - [2021-07-08 21:39:35,387] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:35,476] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:39:35,484] {logging_mixin.py:104} INFO - [2021-07-08 21:39:35,483] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:39:35,492] {logging_mixin.py:104} INFO - [2021-07-08 21:39:35,492] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:39:35,500] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 21:40:05,784] {scheduler_job.py:182} INFO - Started process (PID=32332) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:05,786] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:40:05,786] {logging_mixin.py:104} INFO - [2021-07-08 21:40:05,786] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:05,870] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:05,878] {logging_mixin.py:104} INFO - [2021-07-08 21:40:05,878] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:40:05,886] {logging_mixin.py:104} INFO - [2021-07-08 21:40:05,886] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:40:05,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:40:36,217] {scheduler_job.py:182} INFO - Started process (PID=32396) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:36,219] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:40:36,220] {logging_mixin.py:104} INFO - [2021-07-08 21:40:36,220] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:36,305] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:40:36,312] {logging_mixin.py:104} INFO - [2021-07-08 21:40:36,312] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:40:36,322] {logging_mixin.py:104} INFO - [2021-07-08 21:40:36,321] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:40:36,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 21:41:06,591] {scheduler_job.py:182} INFO - Started process (PID=32460) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:06,592] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:41:06,593] {logging_mixin.py:104} INFO - [2021-07-08 21:41:06,593] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:06,681] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:06,691] {logging_mixin.py:104} INFO - [2021-07-08 21:41:06,691] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:41:06,702] {logging_mixin.py:104} INFO - [2021-07-08 21:41:06,702] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:41:06,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 21:41:37,180] {scheduler_job.py:182} INFO - Started process (PID=32515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:37,182] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:41:37,183] {logging_mixin.py:104} INFO - [2021-07-08 21:41:37,183] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:37,299] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:41:37,307] {logging_mixin.py:104} INFO - [2021-07-08 21:41:37,307] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:41:37,316] {logging_mixin.py:104} INFO - [2021-07-08 21:41:37,316] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:41:37,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-07-08 21:42:07,745] {scheduler_job.py:182} INFO - Started process (PID=32576) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:07,746] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:42:07,747] {logging_mixin.py:104} INFO - [2021-07-08 21:42:07,747] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:07,835] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:07,844] {logging_mixin.py:104} INFO - [2021-07-08 21:42:07,844] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:42:07,853] {logging_mixin.py:104} INFO - [2021-07-08 21:42:07,853] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:42:07,861] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 21:42:38,181] {scheduler_job.py:182} INFO - Started process (PID=32640) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:38,187] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:42:38,188] {logging_mixin.py:104} INFO - [2021-07-08 21:42:38,187] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:38,270] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:42:38,278] {logging_mixin.py:104} INFO - [2021-07-08 21:42:38,278] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:42:38,286] {logging_mixin.py:104} INFO - [2021-07-08 21:42:38,286] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:42:38,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 21:43:08,587] {scheduler_job.py:182} INFO - Started process (PID=32705) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:08,588] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:43:08,588] {logging_mixin.py:104} INFO - [2021-07-08 21:43:08,588] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:08,677] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:08,685] {logging_mixin.py:104} INFO - [2021-07-08 21:43:08,685] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:43:08,695] {logging_mixin.py:104} INFO - [2021-07-08 21:43:08,695] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:43:08,703] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 21:43:39,271] {scheduler_job.py:182} INFO - Started process (PID=32758) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:39,273] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:43:39,274] {logging_mixin.py:104} INFO - [2021-07-08 21:43:39,274] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:39,384] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:43:39,393] {logging_mixin.py:104} INFO - [2021-07-08 21:43:39,393] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:43:39,404] {logging_mixin.py:104} INFO - [2021-07-08 21:43:39,403] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:43:39,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 21:44:09,838] {scheduler_job.py:182} INFO - Started process (PID=32822) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:09,839] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:44:09,840] {logging_mixin.py:104} INFO - [2021-07-08 21:44:09,840] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:09,925] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:09,933] {logging_mixin.py:104} INFO - [2021-07-08 21:44:09,933] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:44:09,942] {logging_mixin.py:104} INFO - [2021-07-08 21:44:09,942] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:44:09,949] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:44:40,104] {scheduler_job.py:182} INFO - Started process (PID=32886) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:40,105] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:44:40,106] {logging_mixin.py:104} INFO - [2021-07-08 21:44:40,106] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:40,194] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:44:40,202] {logging_mixin.py:104} INFO - [2021-07-08 21:44:40,202] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:44:40,212] {logging_mixin.py:104} INFO - [2021-07-08 21:44:40,212] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:44:40,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 21:45:10,678] {scheduler_job.py:182} INFO - Started process (PID=32939) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:10,680] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:45:10,681] {logging_mixin.py:104} INFO - [2021-07-08 21:45:10,681] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:10,775] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:10,782] {logging_mixin.py:104} INFO - [2021-07-08 21:45:10,782] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:45:10,791] {logging_mixin.py:104} INFO - [2021-07-08 21:45:10,791] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:45:10,797] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 21:45:40,841] {scheduler_job.py:182} INFO - Started process (PID=33004) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:40,844] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:45:40,844] {logging_mixin.py:104} INFO - [2021-07-08 21:45:40,844] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:40,932] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:45:40,940] {logging_mixin.py:104} INFO - [2021-07-08 21:45:40,940] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:45:40,949] {logging_mixin.py:104} INFO - [2021-07-08 21:45:40,949] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:45:40,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 21:46:11,335] {scheduler_job.py:182} INFO - Started process (PID=33067) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:11,336] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:46:11,337] {logging_mixin.py:104} INFO - [2021-07-08 21:46:11,337] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:11,425] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:11,432] {logging_mixin.py:104} INFO - [2021-07-08 21:46:11,432] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:46:11,442] {logging_mixin.py:104} INFO - [2021-07-08 21:46:11,441] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:46:11,449] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 21:46:41,713] {scheduler_job.py:182} INFO - Started process (PID=33120) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:41,714] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:46:41,715] {logging_mixin.py:104} INFO - [2021-07-08 21:46:41,715] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:41,816] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:46:41,825] {logging_mixin.py:104} INFO - [2021-07-08 21:46:41,825] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:46:41,837] {logging_mixin.py:104} INFO - [2021-07-08 21:46:41,837] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:46:41,847] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 21:47:12,247] {scheduler_job.py:182} INFO - Started process (PID=33183) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:12,253] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:47:12,254] {logging_mixin.py:104} INFO - [2021-07-08 21:47:12,254] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:12,359] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:12,366] {logging_mixin.py:104} INFO - [2021-07-08 21:47:12,366] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:47:12,374] {logging_mixin.py:104} INFO - [2021-07-08 21:47:12,374] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:47:12,382] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 21:47:42,587] {scheduler_job.py:182} INFO - Started process (PID=33247) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:42,588] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:47:42,589] {logging_mixin.py:104} INFO - [2021-07-08 21:47:42,589] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:42,681] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:47:42,692] {logging_mixin.py:104} INFO - [2021-07-08 21:47:42,692] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:47:42,703] {logging_mixin.py:104} INFO - [2021-07-08 21:47:42,703] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:47:42,713] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 21:48:13,135] {scheduler_job.py:182} INFO - Started process (PID=33300) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:13,137] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:48:13,137] {logging_mixin.py:104} INFO - [2021-07-08 21:48:13,137] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:13,224] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:13,234] {logging_mixin.py:104} INFO - [2021-07-08 21:48:13,234] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:48:13,247] {logging_mixin.py:104} INFO - [2021-07-08 21:48:13,247] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:48:13,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 21:48:43,670] {scheduler_job.py:182} INFO - Started process (PID=33364) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:43,672] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:48:43,673] {logging_mixin.py:104} INFO - [2021-07-08 21:48:43,673] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:43,792] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:48:43,800] {logging_mixin.py:104} INFO - [2021-07-08 21:48:43,800] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:48:43,809] {logging_mixin.py:104} INFO - [2021-07-08 21:48:43,809] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:48:43,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 21:49:14,328] {scheduler_job.py:182} INFO - Started process (PID=33428) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:14,330] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:49:14,331] {logging_mixin.py:104} INFO - [2021-07-08 21:49:14,331] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:14,455] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:14,463] {logging_mixin.py:104} INFO - [2021-07-08 21:49:14,463] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:49:14,474] {logging_mixin.py:104} INFO - [2021-07-08 21:49:14,474] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:49:14,482] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 21:49:44,919] {scheduler_job.py:182} INFO - Started process (PID=33481) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:44,920] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:49:44,921] {logging_mixin.py:104} INFO - [2021-07-08 21:49:44,920] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:45,054] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:49:45,063] {logging_mixin.py:104} INFO - [2021-07-08 21:49:45,063] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:49:45,076] {logging_mixin.py:104} INFO - [2021-07-08 21:49:45,075] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:49:45,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-07-08 21:50:15,644] {scheduler_job.py:182} INFO - Started process (PID=33550) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:15,646] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:50:15,646] {logging_mixin.py:104} INFO - [2021-07-08 21:50:15,646] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:15,763] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:15,770] {logging_mixin.py:104} INFO - [2021-07-08 21:50:15,770] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:50:15,780] {logging_mixin.py:104} INFO - [2021-07-08 21:50:15,780] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:50:15,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 21:50:45,979] {scheduler_job.py:182} INFO - Started process (PID=33613) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:45,981] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:50:45,982] {logging_mixin.py:104} INFO - [2021-07-08 21:50:45,982] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:46,124] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:50:46,135] {logging_mixin.py:104} INFO - [2021-07-08 21:50:46,135] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:50:46,149] {logging_mixin.py:104} INFO - [2021-07-08 21:50:46,149] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:50:46,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.182 seconds
[2021-07-08 21:51:16,586] {scheduler_job.py:182} INFO - Started process (PID=33667) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:16,588] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:51:16,589] {logging_mixin.py:104} INFO - [2021-07-08 21:51:16,588] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:16,709] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:16,716] {logging_mixin.py:104} INFO - [2021-07-08 21:51:16,716] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:51:16,726] {logging_mixin.py:104} INFO - [2021-07-08 21:51:16,726] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:51:16,733] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 21:51:47,181] {scheduler_job.py:182} INFO - Started process (PID=33731) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:47,184] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:51:47,184] {logging_mixin.py:104} INFO - [2021-07-08 21:51:47,184] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:47,310] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:51:47,319] {logging_mixin.py:104} INFO - [2021-07-08 21:51:47,319] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:51:47,328] {logging_mixin.py:104} INFO - [2021-07-08 21:51:47,328] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:51:47,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.157 seconds
[2021-07-08 21:52:17,590] {scheduler_job.py:182} INFO - Started process (PID=33793) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:17,592] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:52:17,592] {logging_mixin.py:104} INFO - [2021-07-08 21:52:17,592] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:17,690] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:17,701] {logging_mixin.py:104} INFO - [2021-07-08 21:52:17,701] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:52:17,712] {logging_mixin.py:104} INFO - [2021-07-08 21:52:17,712] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:52:17,721] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 21:52:47,958] {scheduler_job.py:182} INFO - Started process (PID=33847) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:47,959] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:52:47,960] {logging_mixin.py:104} INFO - [2021-07-08 21:52:47,960] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:48,053] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:52:48,064] {logging_mixin.py:104} INFO - [2021-07-08 21:52:48,063] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:52:48,073] {logging_mixin.py:104} INFO - [2021-07-08 21:52:48,073] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:52:48,081] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 21:53:18,560] {scheduler_job.py:182} INFO - Started process (PID=33911) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:18,562] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:53:18,563] {logging_mixin.py:104} INFO - [2021-07-08 21:53:18,563] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:18,646] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:18,654] {logging_mixin.py:104} INFO - [2021-07-08 21:53:18,654] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:53:18,663] {logging_mixin.py:104} INFO - [2021-07-08 21:53:18,663] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:53:18,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:53:48,926] {scheduler_job.py:182} INFO - Started process (PID=33976) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:48,928] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:53:48,929] {logging_mixin.py:104} INFO - [2021-07-08 21:53:48,928] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:49,038] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:53:49,048] {logging_mixin.py:104} INFO - [2021-07-08 21:53:49,048] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:53:49,059] {logging_mixin.py:104} INFO - [2021-07-08 21:53:49,059] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:53:49,068] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 21:54:19,365] {scheduler_job.py:182} INFO - Started process (PID=34030) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:19,368] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:54:19,369] {logging_mixin.py:104} INFO - [2021-07-08 21:54:19,368] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:19,467] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:19,475] {logging_mixin.py:104} INFO - [2021-07-08 21:54:19,475] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:54:19,483] {logging_mixin.py:104} INFO - [2021-07-08 21:54:19,483] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:54:19,491] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 21:54:49,880] {scheduler_job.py:182} INFO - Started process (PID=34093) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:49,881] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:54:49,882] {logging_mixin.py:104} INFO - [2021-07-08 21:54:49,882] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:49,967] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:54:49,975] {logging_mixin.py:104} INFO - [2021-07-08 21:54:49,975] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:54:49,983] {logging_mixin.py:104} INFO - [2021-07-08 21:54:49,983] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:54:49,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 21:55:20,160] {scheduler_job.py:182} INFO - Started process (PID=34154) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:20,162] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:55:20,163] {logging_mixin.py:104} INFO - [2021-07-08 21:55:20,163] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:20,258] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:20,265] {logging_mixin.py:104} INFO - [2021-07-08 21:55:20,265] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:55:20,275] {logging_mixin.py:104} INFO - [2021-07-08 21:55:20,275] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:55:20,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 21:55:50,378] {scheduler_job.py:182} INFO - Started process (PID=34210) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:50,380] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:55:50,381] {logging_mixin.py:104} INFO - [2021-07-08 21:55:50,381] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:50,465] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:55:50,473] {logging_mixin.py:104} INFO - [2021-07-08 21:55:50,473] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:55:50,481] {logging_mixin.py:104} INFO - [2021-07-08 21:55:50,481] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:55:50,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 21:56:20,900] {scheduler_job.py:182} INFO - Started process (PID=34273) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:20,902] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:56:20,903] {logging_mixin.py:104} INFO - [2021-07-08 21:56:20,902] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:20,989] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:20,997] {logging_mixin.py:104} INFO - [2021-07-08 21:56:20,997] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:56:21,006] {logging_mixin.py:104} INFO - [2021-07-08 21:56:21,006] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:56:21,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 21:56:51,279] {scheduler_job.py:182} INFO - Started process (PID=34337) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:51,280] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:56:51,281] {logging_mixin.py:104} INFO - [2021-07-08 21:56:51,281] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:51,371] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:56:51,380] {logging_mixin.py:104} INFO - [2021-07-08 21:56:51,380] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:56:51,389] {logging_mixin.py:104} INFO - [2021-07-08 21:56:51,389] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:56:51,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 21:57:21,721] {scheduler_job.py:182} INFO - Started process (PID=34390) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:21,723] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:57:21,723] {logging_mixin.py:104} INFO - [2021-07-08 21:57:21,723] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:21,812] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:21,820] {logging_mixin.py:104} INFO - [2021-07-08 21:57:21,820] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:57:21,828] {logging_mixin.py:104} INFO - [2021-07-08 21:57:21,828] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:57:21,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 21:57:51,963] {scheduler_job.py:182} INFO - Started process (PID=34453) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:51,964] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:57:51,965] {logging_mixin.py:104} INFO - [2021-07-08 21:57:51,965] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:52,050] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:57:52,058] {logging_mixin.py:104} INFO - [2021-07-08 21:57:52,058] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:57:52,066] {logging_mixin.py:104} INFO - [2021-07-08 21:57:52,066] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:57:52,073] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 21:58:22,314] {scheduler_job.py:182} INFO - Started process (PID=34517) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:22,315] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:58:22,316] {logging_mixin.py:104} INFO - [2021-07-08 21:58:22,316] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:22,447] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:22,455] {logging_mixin.py:104} INFO - [2021-07-08 21:58:22,455] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:58:22,465] {logging_mixin.py:104} INFO - [2021-07-08 21:58:22,465] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:58:22,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-07-08 21:58:52,942] {scheduler_job.py:182} INFO - Started process (PID=34572) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:52,943] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:58:52,944] {logging_mixin.py:104} INFO - [2021-07-08 21:58:52,944] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:53,030] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:58:53,038] {logging_mixin.py:104} INFO - [2021-07-08 21:58:53,038] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:58:53,046] {logging_mixin.py:104} INFO - [2021-07-08 21:58:53,046] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:58:53,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 21:59:23,151] {scheduler_job.py:182} INFO - Started process (PID=34635) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:23,152] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:59:23,153] {logging_mixin.py:104} INFO - [2021-07-08 21:59:23,153] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:23,245] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:23,257] {logging_mixin.py:104} INFO - [2021-07-08 21:59:23,257] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:59:23,269] {logging_mixin.py:104} INFO - [2021-07-08 21:59:23,269] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:59:23,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 21:59:53,764] {scheduler_job.py:182} INFO - Started process (PID=34698) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:53,766] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 21:59:53,767] {logging_mixin.py:104} INFO - [2021-07-08 21:59:53,766] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:53,875] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 21:59:53,883] {logging_mixin.py:104} INFO - [2021-07-08 21:59:53,883] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 21:59:53,894] {logging_mixin.py:104} INFO - [2021-07-08 21:59:53,894] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 21:59:53,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-07-08 22:00:23,944] {scheduler_job.py:182} INFO - Started process (PID=34752) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:23,945] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:00:23,946] {logging_mixin.py:104} INFO - [2021-07-08 22:00:23,945] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:24,047] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:24,055] {logging_mixin.py:104} INFO - [2021-07-08 22:00:24,055] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:00:24,064] {logging_mixin.py:104} INFO - [2021-07-08 22:00:24,064] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:00:24,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 22:00:55,040] {scheduler_job.py:182} INFO - Started process (PID=34816) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:55,043] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:00:55,043] {logging_mixin.py:104} INFO - [2021-07-08 22:00:55,043] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:55,129] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:00:55,136] {logging_mixin.py:104} INFO - [2021-07-08 22:00:55,136] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:00:55,145] {logging_mixin.py:104} INFO - [2021-07-08 22:00:55,145] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:00:55,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:01:25,640] {scheduler_job.py:182} INFO - Started process (PID=34880) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:25,642] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:01:25,643] {logging_mixin.py:104} INFO - [2021-07-08 22:01:25,642] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:25,759] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:25,767] {logging_mixin.py:104} INFO - [2021-07-08 22:01:25,766] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:01:25,775] {logging_mixin.py:104} INFO - [2021-07-08 22:01:25,775] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:01:25,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 22:01:56,145] {scheduler_job.py:182} INFO - Started process (PID=34935) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:56,151] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:01:56,151] {logging_mixin.py:104} INFO - [2021-07-08 22:01:56,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:56,248] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:01:56,255] {logging_mixin.py:104} INFO - [2021-07-08 22:01:56,255] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:01:56,264] {logging_mixin.py:104} INFO - [2021-07-08 22:01:56,264] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:01:56,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 22:02:26,505] {scheduler_job.py:182} INFO - Started process (PID=34999) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:26,507] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:02:26,508] {logging_mixin.py:104} INFO - [2021-07-08 22:02:26,508] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:26,627] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:26,635] {logging_mixin.py:104} INFO - [2021-07-08 22:02:26,634] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:02:26,644] {logging_mixin.py:104} INFO - [2021-07-08 22:02:26,644] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:02:26,651] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-07-08 22:02:56,800] {scheduler_job.py:182} INFO - Started process (PID=35062) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:56,801] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:02:56,801] {logging_mixin.py:104} INFO - [2021-07-08 22:02:56,801] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:56,886] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:02:56,894] {logging_mixin.py:104} INFO - [2021-07-08 22:02:56,894] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:02:56,903] {logging_mixin.py:104} INFO - [2021-07-08 22:02:56,903] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:02:56,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:03:27,370] {scheduler_job.py:182} INFO - Started process (PID=35116) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:27,372] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:03:27,372] {logging_mixin.py:104} INFO - [2021-07-08 22:03:27,372] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:27,483] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:27,491] {logging_mixin.py:104} INFO - [2021-07-08 22:03:27,491] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:03:27,500] {logging_mixin.py:104} INFO - [2021-07-08 22:03:27,500] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:03:27,508] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-07-08 22:03:57,940] {scheduler_job.py:182} INFO - Started process (PID=35180) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:57,941] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:03:57,942] {logging_mixin.py:104} INFO - [2021-07-08 22:03:57,942] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:58,034] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:03:58,042] {logging_mixin.py:104} INFO - [2021-07-08 22:03:58,042] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:03:58,053] {logging_mixin.py:104} INFO - [2021-07-08 22:03:58,053] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:03:58,069] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 22:04:28,329] {scheduler_job.py:182} INFO - Started process (PID=35245) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:28,331] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:04:28,332] {logging_mixin.py:104} INFO - [2021-07-08 22:04:28,331] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:28,431] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:28,439] {logging_mixin.py:104} INFO - [2021-07-08 22:04:28,439] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:04:28,447] {logging_mixin.py:104} INFO - [2021-07-08 22:04:28,447] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:04:28,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 22:04:58,733] {scheduler_job.py:182} INFO - Started process (PID=35298) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:58,734] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:04:58,735] {logging_mixin.py:104} INFO - [2021-07-08 22:04:58,735] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:58,847] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:04:58,855] {logging_mixin.py:104} INFO - [2021-07-08 22:04:58,855] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:04:58,864] {logging_mixin.py:104} INFO - [2021-07-08 22:04:58,864] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:04:58,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 22:05:29,043] {scheduler_job.py:182} INFO - Started process (PID=35363) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:29,045] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:05:29,045] {logging_mixin.py:104} INFO - [2021-07-08 22:05:29,045] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:29,160] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:29,167] {logging_mixin.py:104} INFO - [2021-07-08 22:05:29,167] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:05:29,176] {logging_mixin.py:104} INFO - [2021-07-08 22:05:29,176] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:05:29,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 22:05:59,206] {scheduler_job.py:182} INFO - Started process (PID=35428) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:59,209] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:05:59,209] {logging_mixin.py:104} INFO - [2021-07-08 22:05:59,209] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:59,323] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:05:59,333] {logging_mixin.py:104} INFO - [2021-07-08 22:05:59,333] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:05:59,344] {logging_mixin.py:104} INFO - [2021-07-08 22:05:59,344] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:05:59,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-07-08 22:06:29,771] {scheduler_job.py:182} INFO - Started process (PID=35482) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:06:29,773] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:06:29,774] {logging_mixin.py:104} INFO - [2021-07-08 22:06:29,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:06:29,862] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:06:29,869] {logging_mixin.py:104} INFO - [2021-07-08 22:06:29,869] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:06:29,878] {logging_mixin.py:104} INFO - [2021-07-08 22:06:29,877] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:06:29,884] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 22:07:00,187] {scheduler_job.py:182} INFO - Started process (PID=35546) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:00,189] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:07:00,190] {logging_mixin.py:104} INFO - [2021-07-08 22:07:00,190] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:00,316] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:00,324] {logging_mixin.py:104} INFO - [2021-07-08 22:07:00,324] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:07:00,333] {logging_mixin.py:104} INFO - [2021-07-08 22:07:00,333] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:07:00,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.155 seconds
[2021-07-08 22:07:30,677] {scheduler_job.py:182} INFO - Started process (PID=35609) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:30,678] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:07:30,679] {logging_mixin.py:104} INFO - [2021-07-08 22:07:30,678] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:30,770] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:07:30,777] {logging_mixin.py:104} INFO - [2021-07-08 22:07:30,777] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:07:30,786] {logging_mixin.py:104} INFO - [2021-07-08 22:07:30,786] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:07:30,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:08:01,034] {scheduler_job.py:182} INFO - Started process (PID=35662) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:01,039] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:08:01,039] {logging_mixin.py:104} INFO - [2021-07-08 22:08:01,039] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:01,141] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:01,151] {logging_mixin.py:104} INFO - [2021-07-08 22:08:01,151] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:08:01,162] {logging_mixin.py:104} INFO - [2021-07-08 22:08:01,162] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:08:01,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 22:08:31,632] {scheduler_job.py:182} INFO - Started process (PID=35726) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:31,634] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:08:31,634] {logging_mixin.py:104} INFO - [2021-07-08 22:08:31,634] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:31,738] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:08:31,745] {logging_mixin.py:104} INFO - [2021-07-08 22:08:31,745] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:08:31,754] {logging_mixin.py:104} INFO - [2021-07-08 22:08:31,753] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:08:31,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 22:09:02,247] {scheduler_job.py:182} INFO - Started process (PID=35791) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:02,249] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:09:02,250] {logging_mixin.py:104} INFO - [2021-07-08 22:09:02,250] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:02,351] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:02,359] {logging_mixin.py:104} INFO - [2021-07-08 22:09:02,359] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:09:02,368] {logging_mixin.py:104} INFO - [2021-07-08 22:09:02,368] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:09:02,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 22:09:32,559] {scheduler_job.py:182} INFO - Started process (PID=35844) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:32,561] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:09:32,561] {logging_mixin.py:104} INFO - [2021-07-08 22:09:32,561] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:32,673] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:09:32,681] {logging_mixin.py:104} INFO - [2021-07-08 22:09:32,681] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:09:32,689] {logging_mixin.py:104} INFO - [2021-07-08 22:09:32,689] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:09:32,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-07-08 22:10:03,022] {scheduler_job.py:182} INFO - Started process (PID=35909) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:03,024] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:10:03,024] {logging_mixin.py:104} INFO - [2021-07-08 22:10:03,024] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:03,111] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:03,119] {logging_mixin.py:104} INFO - [2021-07-08 22:10:03,118] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:10:03,127] {logging_mixin.py:104} INFO - [2021-07-08 22:10:03,127] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:10:03,134] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 22:10:33,610] {scheduler_job.py:182} INFO - Started process (PID=35972) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:33,612] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:10:33,613] {logging_mixin.py:104} INFO - [2021-07-08 22:10:33,613] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:33,731] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:10:33,739] {logging_mixin.py:104} INFO - [2021-07-08 22:10:33,739] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:10:33,748] {logging_mixin.py:104} INFO - [2021-07-08 22:10:33,748] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:10:33,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-07-08 22:11:04,164] {scheduler_job.py:182} INFO - Started process (PID=36031) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:04,166] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:11:04,167] {logging_mixin.py:104} INFO - [2021-07-08 22:11:04,167] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:04,256] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:04,263] {logging_mixin.py:104} INFO - [2021-07-08 22:11:04,263] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:11:04,273] {logging_mixin.py:104} INFO - [2021-07-08 22:11:04,272] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:11:04,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:11:34,705] {scheduler_job.py:182} INFO - Started process (PID=36088) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:34,707] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:11:34,707] {logging_mixin.py:104} INFO - [2021-07-08 22:11:34,707] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:34,872] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:11:34,884] {logging_mixin.py:104} INFO - [2021-07-08 22:11:34,884] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:11:34,897] {logging_mixin.py:104} INFO - [2021-07-08 22:11:34,896] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:11:34,909] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.206 seconds
[2021-07-08 22:12:05,332] {scheduler_job.py:182} INFO - Started process (PID=36152) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:05,334] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:12:05,335] {logging_mixin.py:104} INFO - [2021-07-08 22:12:05,335] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:05,421] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:05,429] {logging_mixin.py:104} INFO - [2021-07-08 22:12:05,429] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:12:05,438] {logging_mixin.py:104} INFO - [2021-07-08 22:12:05,438] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:12:05,445] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 22:12:35,709] {scheduler_job.py:182} INFO - Started process (PID=36215) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:35,711] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:12:35,711] {logging_mixin.py:104} INFO - [2021-07-08 22:12:35,711] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:35,841] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:12:35,853] {logging_mixin.py:104} INFO - [2021-07-08 22:12:35,853] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:12:35,864] {logging_mixin.py:104} INFO - [2021-07-08 22:12:35,864] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:12:35,872] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.165 seconds
[2021-07-08 22:13:06,498] {scheduler_job.py:182} INFO - Started process (PID=36269) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:06,500] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:13:06,501] {logging_mixin.py:104} INFO - [2021-07-08 22:13:06,501] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:06,629] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:06,639] {logging_mixin.py:104} INFO - [2021-07-08 22:13:06,639] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:13:06,648] {logging_mixin.py:104} INFO - [2021-07-08 22:13:06,648] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:13:06,656] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-07-08 22:13:37,136] {scheduler_job.py:182} INFO - Started process (PID=36335) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:37,138] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:13:37,139] {logging_mixin.py:104} INFO - [2021-07-08 22:13:37,139] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:37,257] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:13:37,264] {logging_mixin.py:104} INFO - [2021-07-08 22:13:37,264] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:13:37,273] {logging_mixin.py:104} INFO - [2021-07-08 22:13:37,272] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:13:37,287] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 22:14:07,932] {scheduler_job.py:182} INFO - Started process (PID=36398) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:07,934] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:14:07,934] {logging_mixin.py:104} INFO - [2021-07-08 22:14:07,934] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:08,049] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:08,057] {logging_mixin.py:104} INFO - [2021-07-08 22:14:08,057] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:14:08,066] {logging_mixin.py:104} INFO - [2021-07-08 22:14:08,066] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:14:08,074] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 22:14:38,375] {scheduler_job.py:182} INFO - Started process (PID=36451) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:38,376] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:14:38,377] {logging_mixin.py:104} INFO - [2021-07-08 22:14:38,377] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:38,468] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:14:38,476] {logging_mixin.py:104} INFO - [2021-07-08 22:14:38,476] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:14:38,488] {logging_mixin.py:104} INFO - [2021-07-08 22:14:38,488] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:14:38,499] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 22:15:08,951] {scheduler_job.py:182} INFO - Started process (PID=36515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:08,952] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:15:08,953] {logging_mixin.py:104} INFO - [2021-07-08 22:15:08,953] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:09,088] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:09,095] {logging_mixin.py:104} INFO - [2021-07-08 22:15:09,095] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:15:09,104] {logging_mixin.py:104} INFO - [2021-07-08 22:15:09,104] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:15:09,111] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-07-08 22:15:39,161] {scheduler_job.py:182} INFO - Started process (PID=36578) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:39,163] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:15:39,164] {logging_mixin.py:104} INFO - [2021-07-08 22:15:39,164] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:39,273] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:15:39,283] {logging_mixin.py:104} INFO - [2021-07-08 22:15:39,283] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:15:39,294] {logging_mixin.py:104} INFO - [2021-07-08 22:15:39,294] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:15:39,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-07-08 22:16:09,725] {scheduler_job.py:182} INFO - Started process (PID=36632) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:09,726] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:16:09,727] {logging_mixin.py:104} INFO - [2021-07-08 22:16:09,727] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:09,814] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:09,821] {logging_mixin.py:104} INFO - [2021-07-08 22:16:09,821] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:16:09,830] {logging_mixin.py:104} INFO - [2021-07-08 22:16:09,830] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:16:09,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 22:16:40,286] {scheduler_job.py:182} INFO - Started process (PID=36696) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:40,288] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:16:40,289] {logging_mixin.py:104} INFO - [2021-07-08 22:16:40,289] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:40,402] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:16:40,410] {logging_mixin.py:104} INFO - [2021-07-08 22:16:40,410] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:16:40,419] {logging_mixin.py:104} INFO - [2021-07-08 22:16:40,419] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:16:40,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-07-08 22:17:10,740] {scheduler_job.py:182} INFO - Started process (PID=36760) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:10,742] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:17:10,742] {logging_mixin.py:104} INFO - [2021-07-08 22:17:10,742] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:10,854] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:10,865] {logging_mixin.py:104} INFO - [2021-07-08 22:17:10,865] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:17:10,876] {logging_mixin.py:104} INFO - [2021-07-08 22:17:10,876] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:17:10,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-07-08 22:17:41,175] {scheduler_job.py:182} INFO - Started process (PID=36814) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:41,182] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:17:41,183] {logging_mixin.py:104} INFO - [2021-07-08 22:17:41,183] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:41,301] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:17:41,308] {logging_mixin.py:104} INFO - [2021-07-08 22:17:41,308] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:17:41,317] {logging_mixin.py:104} INFO - [2021-07-08 22:17:41,316] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:17:41,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 22:18:11,653] {scheduler_job.py:182} INFO - Started process (PID=36877) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:11,654] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:18:11,655] {logging_mixin.py:104} INFO - [2021-07-08 22:18:11,655] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:11,837] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:11,845] {logging_mixin.py:104} INFO - [2021-07-08 22:18:11,845] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:18:11,856] {logging_mixin.py:104} INFO - [2021-07-08 22:18:11,856] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:18:11,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.214 seconds
[2021-07-08 22:18:42,082] {scheduler_job.py:182} INFO - Started process (PID=36940) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:42,084] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:18:42,084] {logging_mixin.py:104} INFO - [2021-07-08 22:18:42,084] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:42,170] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:18:42,177] {logging_mixin.py:104} INFO - [2021-07-08 22:18:42,177] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:18:42,186] {logging_mixin.py:104} INFO - [2021-07-08 22:18:42,186] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:18:42,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 22:19:12,527] {scheduler_job.py:182} INFO - Started process (PID=36994) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:12,528] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:19:12,529] {logging_mixin.py:104} INFO - [2021-07-08 22:19:12,529] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:12,619] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:12,628] {logging_mixin.py:104} INFO - [2021-07-08 22:19:12,628] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:19:12,640] {logging_mixin.py:104} INFO - [2021-07-08 22:19:12,640] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:19:12,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 22:19:43,016] {scheduler_job.py:182} INFO - Started process (PID=37057) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:43,018] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:19:43,018] {logging_mixin.py:104} INFO - [2021-07-08 22:19:43,018] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:43,103] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:19:43,111] {logging_mixin.py:104} INFO - [2021-07-08 22:19:43,110] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:19:43,120] {logging_mixin.py:104} INFO - [2021-07-08 22:19:43,120] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:19:43,128] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 22:20:13,446] {scheduler_job.py:182} INFO - Started process (PID=37120) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:13,447] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:20:13,447] {logging_mixin.py:104} INFO - [2021-07-08 22:20:13,447] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:13,561] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:13,569] {logging_mixin.py:104} INFO - [2021-07-08 22:20:13,569] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:20:13,578] {logging_mixin.py:104} INFO - [2021-07-08 22:20:13,578] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:20:13,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 22:20:43,696] {scheduler_job.py:182} INFO - Started process (PID=37173) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:43,698] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:20:43,698] {logging_mixin.py:104} INFO - [2021-07-08 22:20:43,698] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:43,811] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:20:43,819] {logging_mixin.py:104} INFO - [2021-07-08 22:20:43,819] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:20:43,828] {logging_mixin.py:104} INFO - [2021-07-08 22:20:43,828] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:20:43,836] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-07-08 22:21:14,271] {scheduler_job.py:182} INFO - Started process (PID=37238) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:14,273] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:21:14,274] {logging_mixin.py:104} INFO - [2021-07-08 22:21:14,274] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:14,397] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:14,404] {logging_mixin.py:104} INFO - [2021-07-08 22:21:14,404] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:21:14,415] {logging_mixin.py:104} INFO - [2021-07-08 22:21:14,415] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:21:14,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-07-08 22:21:44,827] {scheduler_job.py:182} INFO - Started process (PID=37302) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:44,829] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:21:44,830] {logging_mixin.py:104} INFO - [2021-07-08 22:21:44,830] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:44,950] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:21:44,959] {logging_mixin.py:104} INFO - [2021-07-08 22:21:44,959] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:21:44,968] {logging_mixin.py:104} INFO - [2021-07-08 22:21:44,968] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:21:44,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-07-08 22:22:15,317] {scheduler_job.py:182} INFO - Started process (PID=37355) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:15,318] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:22:15,319] {logging_mixin.py:104} INFO - [2021-07-08 22:22:15,319] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:15,452] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:15,460] {logging_mixin.py:104} INFO - [2021-07-08 22:22:15,460] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:22:15,470] {logging_mixin.py:104} INFO - [2021-07-08 22:22:15,470] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:22:15,480] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.165 seconds
[2021-07-08 22:22:45,932] {scheduler_job.py:182} INFO - Started process (PID=37418) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:45,934] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:22:45,935] {logging_mixin.py:104} INFO - [2021-07-08 22:22:45,934] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:46,110] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:22:46,119] {logging_mixin.py:104} INFO - [2021-07-08 22:22:46,119] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:22:46,128] {logging_mixin.py:104} INFO - [2021-07-08 22:22:46,128] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:22:46,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.209 seconds
[2021-07-08 22:23:16,858] {scheduler_job.py:182} INFO - Started process (PID=37472) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:23:16,859] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:23:16,859] {logging_mixin.py:104} INFO - [2021-07-08 22:23:16,859] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:23:17,058] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:23:17,079] {logging_mixin.py:104} INFO - [2021-07-08 22:23:17,079] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:23:17,096] {logging_mixin.py:104} INFO - [2021-07-08 22:23:17,096] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:23:17,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.255 seconds
[2021-07-08 22:25:32,685] {scheduler_job.py:182} INFO - Started process (PID=37504) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:25:32,688] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:25:32,689] {logging_mixin.py:104} INFO - [2021-07-08 22:25:32,688] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:25:32,989] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:25:33,007] {logging_mixin.py:104} INFO - [2021-07-08 22:25:33,007] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:25:33,026] {logging_mixin.py:104} INFO - [2021-07-08 22:25:33,026] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:25:33,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.360 seconds
[2021-07-08 22:26:03,144] {scheduler_job.py:182} INFO - Started process (PID=37557) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:03,146] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:26:03,146] {logging_mixin.py:104} INFO - [2021-07-08 22:26:03,146] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:03,262] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:03,272] {logging_mixin.py:104} INFO - [2021-07-08 22:26:03,272] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:26:03,283] {logging_mixin.py:104} INFO - [2021-07-08 22:26:03,283] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:26:03,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 22:26:33,806] {scheduler_job.py:182} INFO - Started process (PID=37620) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:33,808] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:26:33,809] {logging_mixin.py:104} INFO - [2021-07-08 22:26:33,809] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:33,944] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:26:33,954] {logging_mixin.py:104} INFO - [2021-07-08 22:26:33,954] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:26:33,966] {logging_mixin.py:104} INFO - [2021-07-08 22:26:33,966] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:26:33,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-07-08 22:27:04,403] {scheduler_job.py:182} INFO - Started process (PID=37687) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:04,407] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:27:04,407] {logging_mixin.py:104} INFO - [2021-07-08 22:27:04,407] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:04,576] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:04,587] {logging_mixin.py:104} INFO - [2021-07-08 22:27:04,587] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:27:04,599] {logging_mixin.py:104} INFO - [2021-07-08 22:27:04,599] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:27:04,608] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.208 seconds
[2021-07-08 22:27:35,106] {scheduler_job.py:182} INFO - Started process (PID=37740) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:35,109] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:27:35,110] {logging_mixin.py:104} INFO - [2021-07-08 22:27:35,110] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:35,461] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:27:35,490] {logging_mixin.py:104} INFO - [2021-07-08 22:27:35,490] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:27:35,516] {logging_mixin.py:104} INFO - [2021-07-08 22:27:35,516] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:27:35,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.437 seconds
[2021-07-08 22:28:05,957] {scheduler_job.py:182} INFO - Started process (PID=37805) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:05,960] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:28:05,968] {logging_mixin.py:104} INFO - [2021-07-08 22:28:05,968] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:10,003] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:10,029] {logging_mixin.py:104} INFO - [2021-07-08 22:28:10,028] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:28:10,057] {logging_mixin.py:104} INFO - [2021-07-08 22:28:10,057] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:28:10,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 4.133 seconds
[2021-07-08 22:28:40,833] {scheduler_job.py:182} INFO - Started process (PID=37858) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:40,835] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:28:40,836] {logging_mixin.py:104} INFO - [2021-07-08 22:28:40,836] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:41,035] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:28:41,045] {logging_mixin.py:104} INFO - [2021-07-08 22:28:41,045] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:28:41,058] {logging_mixin.py:104} INFO - [2021-07-08 22:28:41,058] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:28:41,070] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.240 seconds
[2021-07-08 22:29:12,042] {scheduler_job.py:182} INFO - Started process (PID=37921) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:29:12,047] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:29:12,048] {logging_mixin.py:104} INFO - [2021-07-08 22:29:12,047] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:29:13,562] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:29:15,473] {logging_mixin.py:104} INFO - [2021-07-08 22:29:15,392] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:29:26,871] {logging_mixin.py:104} INFO - [2021-07-08 22:29:26,859] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:29:26,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 14.921 seconds
[2021-07-08 22:30:31,993] {scheduler_job.py:182} INFO - Started process (PID=37975) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:30:32,014] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:30:32,034] {logging_mixin.py:104} INFO - [2021-07-08 22:30:32,034] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:30:51,989] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:30:52,020] {logging_mixin.py:104} INFO - [2021-07-08 22:30:52,020] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:30:52,052] {logging_mixin.py:104} INFO - [2021-07-08 22:30:52,052] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:30:52,073] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 20.129 seconds
[2021-07-08 22:31:22,245] {scheduler_job.py:182} INFO - Started process (PID=38028) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:22,246] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:31:22,247] {logging_mixin.py:104} INFO - [2021-07-08 22:31:22,247] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:22,434] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:22,447] {logging_mixin.py:104} INFO - [2021-07-08 22:31:22,447] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:31:22,459] {logging_mixin.py:104} INFO - [2021-07-08 22:31:22,459] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:31:22,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-07-08 22:31:52,563] {scheduler_job.py:182} INFO - Started process (PID=38091) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:52,566] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:31:52,570] {logging_mixin.py:104} INFO - [2021-07-08 22:31:52,569] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:58,103] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:31:58,191] {logging_mixin.py:104} INFO - [2021-07-08 22:31:58,191] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:31:58,231] {logging_mixin.py:104} INFO - [2021-07-08 22:31:58,231] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:31:58,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 5.721 seconds
[2021-07-08 22:32:28,719] {scheduler_job.py:182} INFO - Started process (PID=38144) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:32:28,720] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:32:28,721] {logging_mixin.py:104} INFO - [2021-07-08 22:32:28,721] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:32:29,010] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:32:29,043] {logging_mixin.py:104} INFO - [2021-07-08 22:32:29,043] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:32:29,118] {logging_mixin.py:104} INFO - [2021-07-08 22:32:29,106] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:32:29,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.888 seconds
[2021-07-08 22:33:27,512] {scheduler_job.py:182} INFO - Started process (PID=38160) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:27,514] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:33:27,515] {logging_mixin.py:104} INFO - [2021-07-08 22:33:27,515] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:27,901] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:27,915] {logging_mixin.py:104} INFO - [2021-07-08 22:33:27,914] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:33:27,934] {logging_mixin.py:104} INFO - [2021-07-08 22:33:27,933] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:33:27,944] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.440 seconds
[2021-07-08 22:33:58,664] {scheduler_job.py:182} INFO - Started process (PID=38224) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:58,665] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:33:58,666] {logging_mixin.py:104} INFO - [2021-07-08 22:33:58,666] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:58,984] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:33:59,001] {logging_mixin.py:104} INFO - [2021-07-08 22:33:59,001] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:33:59,017] {logging_mixin.py:104} INFO - [2021-07-08 22:33:59,017] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:33:59,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.368 seconds
[2021-07-08 22:34:35,017] {scheduler_job.py:182} INFO - Started process (PID=38277) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:34:35,041] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:34:35,045] {logging_mixin.py:104} INFO - [2021-07-08 22:34:35,044] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:35:04,403] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:35:06,143] {logging_mixin.py:104} INFO - [2021-07-08 22:35:06,142] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:35:06,170] {logging_mixin.py:104} INFO - [2021-07-08 22:35:06,170] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:35:06,196] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 31.221 seconds
[2021-07-08 22:35:36,392] {scheduler_job.py:182} INFO - Started process (PID=38331) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:35:36,393] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:35:36,393] {logging_mixin.py:104} INFO - [2021-07-08 22:35:36,393] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:35:36,692] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:35:36,710] {logging_mixin.py:104} INFO - [2021-07-08 22:35:36,710] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:35:36,722] {logging_mixin.py:104} INFO - [2021-07-08 22:35:36,722] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:35:36,734] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.345 seconds
[2021-07-08 22:36:07,039] {scheduler_job.py:182} INFO - Started process (PID=38394) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:07,041] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:36:07,041] {logging_mixin.py:104} INFO - [2021-07-08 22:36:07,041] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:07,341] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:07,355] {logging_mixin.py:104} INFO - [2021-07-08 22:36:07,355] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:36:07,370] {logging_mixin.py:104} INFO - [2021-07-08 22:36:07,369] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:36:07,380] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.344 seconds
[2021-07-08 22:36:37,715] {scheduler_job.py:182} INFO - Started process (PID=38448) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:37,716] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:36:37,717] {logging_mixin.py:104} INFO - [2021-07-08 22:36:37,717] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:39,428] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:36:39,444] {logging_mixin.py:104} INFO - [2021-07-08 22:36:39,444] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:36:39,461] {logging_mixin.py:104} INFO - [2021-07-08 22:36:39,461] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:36:39,470] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 1.758 seconds
[2021-07-08 22:37:37,108] {scheduler_job.py:182} INFO - Started process (PID=38486) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:37:37,123] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:37:37,151] {logging_mixin.py:104} INFO - [2021-07-08 22:37:37,151] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:37:37,631] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:37:37,657] {logging_mixin.py:104} INFO - [2021-07-08 22:37:37,656] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:37:37,704] {logging_mixin.py:104} INFO - [2021-07-08 22:37:37,704] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:37:37,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.640 seconds
[2021-07-08 22:38:08,416] {scheduler_job.py:182} INFO - Started process (PID=38551) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:08,419] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:38:08,420] {logging_mixin.py:104} INFO - [2021-07-08 22:38:08,420] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:14,443] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:14,820] {logging_mixin.py:104} INFO - [2021-07-08 22:38:14,809] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:38:15,443] {logging_mixin.py:104} INFO - [2021-07-08 22:38:15,414] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:38:16,336] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 7.921 seconds
[2021-07-08 22:38:46,691] {scheduler_job.py:182} INFO - Started process (PID=38605) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:46,692] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:38:46,693] {logging_mixin.py:104} INFO - [2021-07-08 22:38:46,693] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:46,838] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:38:46,848] {logging_mixin.py:104} INFO - [2021-07-08 22:38:46,848] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:38:46,858] {logging_mixin.py:104} INFO - [2021-07-08 22:38:46,858] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:38:46,868] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.179 seconds
[2021-07-08 22:39:17,230] {scheduler_job.py:182} INFO - Started process (PID=38658) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:17,232] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:39:17,232] {logging_mixin.py:104} INFO - [2021-07-08 22:39:17,232] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:17,433] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:17,441] {logging_mixin.py:104} INFO - [2021-07-08 22:39:17,441] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:39:17,450] {logging_mixin.py:104} INFO - [2021-07-08 22:39:17,450] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:39:17,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-07-08 22:39:47,712] {scheduler_job.py:182} INFO - Started process (PID=38723) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:47,941] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:39:47,941] {logging_mixin.py:104} INFO - [2021-07-08 22:39:47,941] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:48,234] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:39:48,257] {logging_mixin.py:104} INFO - [2021-07-08 22:39:48,257] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:39:48,269] {logging_mixin.py:104} INFO - [2021-07-08 22:39:48,269] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:39:48,280] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.619 seconds
[2021-07-08 22:40:19,026] {scheduler_job.py:182} INFO - Started process (PID=38756) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:19,027] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:40:19,028] {logging_mixin.py:104} INFO - [2021-07-08 22:40:19,028] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:19,195] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:19,204] {logging_mixin.py:104} INFO - [2021-07-08 22:40:19,204] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:40:19,215] {logging_mixin.py:104} INFO - [2021-07-08 22:40:19,215] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:40:19,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.202 seconds
[2021-07-08 22:40:49,618] {scheduler_job.py:182} INFO - Started process (PID=38820) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:49,619] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:40:49,620] {logging_mixin.py:104} INFO - [2021-07-08 22:40:49,620] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:49,740] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:40:49,748] {logging_mixin.py:104} INFO - [2021-07-08 22:40:49,748] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:40:49,757] {logging_mixin.py:104} INFO - [2021-07-08 22:40:49,757] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:40:49,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-07-08 22:41:20,148] {scheduler_job.py:182} INFO - Started process (PID=38885) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:20,150] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:41:20,150] {logging_mixin.py:104} INFO - [2021-07-08 22:41:20,150] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:20,268] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:20,276] {logging_mixin.py:104} INFO - [2021-07-08 22:41:20,276] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:41:20,285] {logging_mixin.py:104} INFO - [2021-07-08 22:41:20,285] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:41:20,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-07-08 22:41:51,071] {scheduler_job.py:182} INFO - Started process (PID=38939) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:51,072] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:41:51,073] {logging_mixin.py:104} INFO - [2021-07-08 22:41:51,073] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:51,292] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:41:51,304] {logging_mixin.py:104} INFO - [2021-07-08 22:41:51,304] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:41:51,315] {logging_mixin.py:104} INFO - [2021-07-08 22:41:51,315] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:41:51,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.256 seconds
[2021-07-08 22:42:27,665] {scheduler_job.py:182} INFO - Started process (PID=38986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:42:27,668] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:42:27,669] {logging_mixin.py:104} INFO - [2021-07-08 22:42:27,669] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:42:27,987] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:42:28,008] {logging_mixin.py:104} INFO - [2021-07-08 22:42:28,007] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:42:28,028] {logging_mixin.py:104} INFO - [2021-07-08 22:42:28,028] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:42:28,043] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.382 seconds
[2021-07-08 22:43:08,229] {scheduler_job.py:182} INFO - Started process (PID=39047) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:08,231] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:43:08,232] {logging_mixin.py:104} INFO - [2021-07-08 22:43:08,232] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:08,486] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:08,499] {logging_mixin.py:104} INFO - [2021-07-08 22:43:08,499] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:43:08,517] {logging_mixin.py:104} INFO - [2021-07-08 22:43:08,517] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:43:08,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.307 seconds
[2021-07-08 22:43:38,869] {scheduler_job.py:182} INFO - Started process (PID=39101) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:38,870] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:43:38,871] {logging_mixin.py:104} INFO - [2021-07-08 22:43:38,870] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:38,953] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:43:38,963] {logging_mixin.py:104} INFO - [2021-07-08 22:43:38,963] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:43:38,974] {logging_mixin.py:104} INFO - [2021-07-08 22:43:38,974] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:43:38,982] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 22:44:09,481] {scheduler_job.py:182} INFO - Started process (PID=39164) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:09,485] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:44:09,486] {logging_mixin.py:104} INFO - [2021-07-08 22:44:09,486] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:09,571] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:09,578] {logging_mixin.py:104} INFO - [2021-07-08 22:44:09,578] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:44:09,587] {logging_mixin.py:104} INFO - [2021-07-08 22:44:09,586] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:44:09,595] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 22:44:40,036] {scheduler_job.py:182} INFO - Started process (PID=39217) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:40,038] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:44:40,039] {logging_mixin.py:104} INFO - [2021-07-08 22:44:40,039] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:40,124] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:44:40,133] {logging_mixin.py:104} INFO - [2021-07-08 22:44:40,133] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:44:40,146] {logging_mixin.py:104} INFO - [2021-07-08 22:44:40,146] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:44:40,169] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 22:45:10,708] {scheduler_job.py:182} INFO - Started process (PID=39281) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:10,709] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:45:10,709] {logging_mixin.py:104} INFO - [2021-07-08 22:45:10,709] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:10,792] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:10,802] {logging_mixin.py:104} INFO - [2021-07-08 22:45:10,802] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:45:10,814] {logging_mixin.py:104} INFO - [2021-07-08 22:45:10,814] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:45:10,822] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 22:45:41,242] {scheduler_job.py:182} INFO - Started process (PID=39344) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:41,243] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:45:41,243] {logging_mixin.py:104} INFO - [2021-07-08 22:45:41,243] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:41,331] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:45:41,340] {logging_mixin.py:104} INFO - [2021-07-08 22:45:41,339] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:45:41,350] {logging_mixin.py:104} INFO - [2021-07-08 22:45:41,350] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:45:41,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:46:11,860] {scheduler_job.py:182} INFO - Started process (PID=39410) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:11,861] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:46:11,861] {logging_mixin.py:104} INFO - [2021-07-08 22:46:11,861] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:11,948] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:11,955] {logging_mixin.py:104} INFO - [2021-07-08 22:46:11,955] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:46:11,966] {logging_mixin.py:104} INFO - [2021-07-08 22:46:11,966] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:46:11,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 22:46:42,506] {scheduler_job.py:182} INFO - Started process (PID=39464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:42,508] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:46:42,508] {logging_mixin.py:104} INFO - [2021-07-08 22:46:42,508] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:42,591] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:46:42,600] {logging_mixin.py:104} INFO - [2021-07-08 22:46:42,600] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:46:42,609] {logging_mixin.py:104} INFO - [2021-07-08 22:46:42,609] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:46:42,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:47:12,913] {scheduler_job.py:182} INFO - Started process (PID=39528) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:12,914] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:47:12,915] {logging_mixin.py:104} INFO - [2021-07-08 22:47:12,914] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:12,998] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:13,008] {logging_mixin.py:104} INFO - [2021-07-08 22:47:13,008] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:47:13,020] {logging_mixin.py:104} INFO - [2021-07-08 22:47:13,019] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:47:13,029] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 22:47:43,605] {scheduler_job.py:182} INFO - Started process (PID=39592) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:43,606] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:47:43,607] {logging_mixin.py:104} INFO - [2021-07-08 22:47:43,607] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:43,690] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:47:43,697] {logging_mixin.py:104} INFO - [2021-07-08 22:47:43,697] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:47:43,706] {logging_mixin.py:104} INFO - [2021-07-08 22:47:43,706] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:47:43,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:48:14,131] {scheduler_job.py:182} INFO - Started process (PID=39645) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:14,133] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:48:14,133] {logging_mixin.py:104} INFO - [2021-07-08 22:48:14,133] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:14,216] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:14,225] {logging_mixin.py:104} INFO - [2021-07-08 22:48:14,225] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:48:14,236] {logging_mixin.py:104} INFO - [2021-07-08 22:48:14,236] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:48:14,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 22:48:44,826] {scheduler_job.py:182} INFO - Started process (PID=39711) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:44,827] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:48:44,828] {logging_mixin.py:104} INFO - [2021-07-08 22:48:44,828] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:44,914] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:48:44,921] {logging_mixin.py:104} INFO - [2021-07-08 22:48:44,921] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:48:44,931] {logging_mixin.py:104} INFO - [2021-07-08 22:48:44,931] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:48:44,939] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 22:49:15,342] {scheduler_job.py:182} INFO - Started process (PID=39775) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:15,343] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:49:15,344] {logging_mixin.py:104} INFO - [2021-07-08 22:49:15,343] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:15,433] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:15,441] {logging_mixin.py:104} INFO - [2021-07-08 22:49:15,441] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:49:15,451] {logging_mixin.py:104} INFO - [2021-07-08 22:49:15,451] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:49:15,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:49:45,978] {scheduler_job.py:182} INFO - Started process (PID=39828) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:45,980] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:49:45,981] {logging_mixin.py:104} INFO - [2021-07-08 22:49:45,981] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:46,066] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:49:46,074] {logging_mixin.py:104} INFO - [2021-07-08 22:49:46,074] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:49:46,083] {logging_mixin.py:104} INFO - [2021-07-08 22:49:46,082] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:49:46,090] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 22:50:16,591] {scheduler_job.py:182} INFO - Started process (PID=39893) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:16,592] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:50:16,592] {logging_mixin.py:104} INFO - [2021-07-08 22:50:16,592] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:16,676] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:16,684] {logging_mixin.py:104} INFO - [2021-07-08 22:50:16,684] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:50:16,693] {logging_mixin.py:104} INFO - [2021-07-08 22:50:16,693] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:50:16,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:50:47,184] {scheduler_job.py:182} INFO - Started process (PID=39957) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:47,185] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:50:47,186] {logging_mixin.py:104} INFO - [2021-07-08 22:50:47,186] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:47,268] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:50:47,276] {logging_mixin.py:104} INFO - [2021-07-08 22:50:47,276] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:50:47,285] {logging_mixin.py:104} INFO - [2021-07-08 22:50:47,284] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:50:47,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 22:51:17,743] {scheduler_job.py:182} INFO - Started process (PID=40020) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:17,744] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:51:17,745] {logging_mixin.py:104} INFO - [2021-07-08 22:51:17,745] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:17,833] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:17,842] {logging_mixin.py:104} INFO - [2021-07-08 22:51:17,842] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:51:17,852] {logging_mixin.py:104} INFO - [2021-07-08 22:51:17,852] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:51:17,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:51:48,367] {scheduler_job.py:182} INFO - Started process (PID=40073) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:48,368] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:51:48,369] {logging_mixin.py:104} INFO - [2021-07-08 22:51:48,369] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:48,451] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:51:48,458] {logging_mixin.py:104} INFO - [2021-07-08 22:51:48,458] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:51:48,467] {logging_mixin.py:104} INFO - [2021-07-08 22:51:48,466] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:51:48,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 22:52:19,053] {scheduler_job.py:182} INFO - Started process (PID=40141) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:19,054] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:52:19,055] {logging_mixin.py:104} INFO - [2021-07-08 22:52:19,055] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:19,137] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:19,145] {logging_mixin.py:104} INFO - [2021-07-08 22:52:19,145] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:52:19,153] {logging_mixin.py:104} INFO - [2021-07-08 22:52:19,153] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:52:19,162] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:52:49,685] {scheduler_job.py:182} INFO - Started process (PID=40206) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:49,686] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:52:49,687] {logging_mixin.py:104} INFO - [2021-07-08 22:52:49,687] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:49,776] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:52:49,784] {logging_mixin.py:104} INFO - [2021-07-08 22:52:49,784] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:52:49,793] {logging_mixin.py:104} INFO - [2021-07-08 22:52:49,793] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:52:49,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 22:53:20,364] {scheduler_job.py:182} INFO - Started process (PID=40259) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:20,365] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:53:20,366] {logging_mixin.py:104} INFO - [2021-07-08 22:53:20,365] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:20,451] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:20,459] {logging_mixin.py:104} INFO - [2021-07-08 22:53:20,459] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:53:20,468] {logging_mixin.py:104} INFO - [2021-07-08 22:53:20,468] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:53:20,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 22:53:51,009] {scheduler_job.py:182} INFO - Started process (PID=40323) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:51,010] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:53:51,010] {logging_mixin.py:104} INFO - [2021-07-08 22:53:51,010] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:51,094] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:53:51,104] {logging_mixin.py:104} INFO - [2021-07-08 22:53:51,103] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:53:51,115] {logging_mixin.py:104} INFO - [2021-07-08 22:53:51,114] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:53:51,124] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 22:54:21,545] {scheduler_job.py:182} INFO - Started process (PID=40387) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:21,546] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:54:21,547] {logging_mixin.py:104} INFO - [2021-07-08 22:54:21,547] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:21,629] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:21,637] {logging_mixin.py:104} INFO - [2021-07-08 22:54:21,637] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:54:21,646] {logging_mixin.py:104} INFO - [2021-07-08 22:54:21,646] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:54:21,654] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:54:52,161] {scheduler_job.py:182} INFO - Started process (PID=40440) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:52,163] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:54:52,164] {logging_mixin.py:104} INFO - [2021-07-08 22:54:52,164] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:52,246] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:54:52,254] {logging_mixin.py:104} INFO - [2021-07-08 22:54:52,254] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:54:52,263] {logging_mixin.py:104} INFO - [2021-07-08 22:54:52,262] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:54:52,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:55:22,898] {scheduler_job.py:182} INFO - Started process (PID=40503) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:22,899] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:55:22,899] {logging_mixin.py:104} INFO - [2021-07-08 22:55:22,899] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:22,985] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:22,993] {logging_mixin.py:104} INFO - [2021-07-08 22:55:22,993] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:55:23,003] {logging_mixin.py:104} INFO - [2021-07-08 22:55:23,003] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:55:23,010] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 22:55:53,705] {scheduler_job.py:182} INFO - Started process (PID=40567) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:53,706] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:55:53,707] {logging_mixin.py:104} INFO - [2021-07-08 22:55:53,707] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:53,789] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:55:53,797] {logging_mixin.py:104} INFO - [2021-07-08 22:55:53,796] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:55:53,806] {logging_mixin.py:104} INFO - [2021-07-08 22:55:53,806] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:55:53,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:56:24,348] {scheduler_job.py:182} INFO - Started process (PID=40630) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:24,349] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:56:24,350] {logging_mixin.py:104} INFO - [2021-07-08 22:56:24,350] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:24,445] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:24,454] {logging_mixin.py:104} INFO - [2021-07-08 22:56:24,453] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:56:24,464] {logging_mixin.py:104} INFO - [2021-07-08 22:56:24,463] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:56:24,474] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 22:56:55,198] {scheduler_job.py:182} INFO - Started process (PID=40684) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:55,199] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:56:55,200] {logging_mixin.py:104} INFO - [2021-07-08 22:56:55,200] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:55,284] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:56:55,292] {logging_mixin.py:104} INFO - [2021-07-08 22:56:55,292] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:56:55,301] {logging_mixin.py:104} INFO - [2021-07-08 22:56:55,300] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:56:55,308] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:57:25,887] {scheduler_job.py:182} INFO - Started process (PID=40747) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:25,889] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:57:25,889] {logging_mixin.py:104} INFO - [2021-07-08 22:57:25,889] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:25,973] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:25,981] {logging_mixin.py:104} INFO - [2021-07-08 22:57:25,980] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:57:25,990] {logging_mixin.py:104} INFO - [2021-07-08 22:57:25,990] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:57:25,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 22:57:56,482] {scheduler_job.py:182} INFO - Started process (PID=40811) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:56,484] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:57:56,485] {logging_mixin.py:104} INFO - [2021-07-08 22:57:56,485] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:56,566] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:57:56,574] {logging_mixin.py:104} INFO - [2021-07-08 22:57:56,574] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:57:56,582] {logging_mixin.py:104} INFO - [2021-07-08 22:57:56,582] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:57:56,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 22:58:27,145] {scheduler_job.py:182} INFO - Started process (PID=40865) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:27,146] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:58:27,147] {logging_mixin.py:104} INFO - [2021-07-08 22:58:27,147] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:27,229] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:27,237] {logging_mixin.py:104} INFO - [2021-07-08 22:58:27,237] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:58:27,246] {logging_mixin.py:104} INFO - [2021-07-08 22:58:27,246] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:58:27,254] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:58:57,788] {scheduler_job.py:182} INFO - Started process (PID=40928) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:57,789] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:58:57,790] {logging_mixin.py:104} INFO - [2021-07-08 22:58:57,790] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:57,872] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:58:57,880] {logging_mixin.py:104} INFO - [2021-07-08 22:58:57,880] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:58:57,888] {logging_mixin.py:104} INFO - [2021-07-08 22:58:57,888] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:58:57,896] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 22:59:28,614] {scheduler_job.py:182} INFO - Started process (PID=40991) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:28,615] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:59:28,616] {logging_mixin.py:104} INFO - [2021-07-08 22:59:28,616] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:28,699] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:28,709] {logging_mixin.py:104} INFO - [2021-07-08 22:59:28,709] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:59:28,720] {logging_mixin.py:104} INFO - [2021-07-08 22:59:28,720] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:59:28,730] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 22:59:59,220] {scheduler_job.py:182} INFO - Started process (PID=41056) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:59,223] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 22:59:59,224] {logging_mixin.py:104} INFO - [2021-07-08 22:59:59,224] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:59,343] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 22:59:59,354] {logging_mixin.py:104} INFO - [2021-07-08 22:59:59,354] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 22:59:59,367] {logging_mixin.py:104} INFO - [2021-07-08 22:59:59,367] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 22:59:59,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-07-08 23:00:30,066] {scheduler_job.py:182} INFO - Started process (PID=41109) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:00:30,067] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:00:30,068] {logging_mixin.py:104} INFO - [2021-07-08 23:00:30,067] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:00:30,150] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:00:30,158] {logging_mixin.py:104} INFO - [2021-07-08 23:00:30,158] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:00:30,167] {logging_mixin.py:104} INFO - [2021-07-08 23:00:30,166] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:00:30,175] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:01:00,746] {scheduler_job.py:182} INFO - Started process (PID=41173) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:00,747] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:01:00,748] {logging_mixin.py:104} INFO - [2021-07-08 23:01:00,748] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:00,834] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:00,844] {logging_mixin.py:104} INFO - [2021-07-08 23:01:00,844] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:01:00,855] {logging_mixin.py:104} INFO - [2021-07-08 23:01:00,855] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:01:00,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 23:01:31,397] {scheduler_job.py:182} INFO - Started process (PID=41237) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:31,398] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:01:31,399] {logging_mixin.py:104} INFO - [2021-07-08 23:01:31,399] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:31,490] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:01:31,498] {logging_mixin.py:104} INFO - [2021-07-08 23:01:31,497] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:01:31,507] {logging_mixin.py:104} INFO - [2021-07-08 23:01:31,507] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:01:31,516] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 23:02:02,157] {scheduler_job.py:182} INFO - Started process (PID=41291) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:02,158] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:02:02,158] {logging_mixin.py:104} INFO - [2021-07-08 23:02:02,158] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:02,241] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:02,249] {logging_mixin.py:104} INFO - [2021-07-08 23:02:02,249] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:02:02,257] {logging_mixin.py:104} INFO - [2021-07-08 23:02:02,257] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:02:02,265] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:02:32,739] {scheduler_job.py:182} INFO - Started process (PID=41355) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:32,740] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:02:32,741] {logging_mixin.py:104} INFO - [2021-07-08 23:02:32,741] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:32,829] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:02:32,840] {logging_mixin.py:104} INFO - [2021-07-08 23:02:32,840] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:02:32,850] {logging_mixin.py:104} INFO - [2021-07-08 23:02:32,850] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:02:32,858] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 23:03:03,398] {scheduler_job.py:182} INFO - Started process (PID=41418) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:03,399] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:03:03,400] {logging_mixin.py:104} INFO - [2021-07-08 23:03:03,400] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:03,483] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:03,494] {logging_mixin.py:104} INFO - [2021-07-08 23:03:03,493] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:03:03,505] {logging_mixin.py:104} INFO - [2021-07-08 23:03:03,505] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:03:03,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 23:03:34,010] {scheduler_job.py:182} INFO - Started process (PID=41471) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:34,011] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:03:34,012] {logging_mixin.py:104} INFO - [2021-07-08 23:03:34,012] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:34,101] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:03:34,109] {logging_mixin.py:104} INFO - [2021-07-08 23:03:34,109] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:03:34,118] {logging_mixin.py:104} INFO - [2021-07-08 23:03:34,118] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:03:34,126] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 23:04:04,697] {scheduler_job.py:182} INFO - Started process (PID=41534) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:04,698] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:04:04,698] {logging_mixin.py:104} INFO - [2021-07-08 23:04:04,698] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:04,781] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:04,788] {logging_mixin.py:104} INFO - [2021-07-08 23:04:04,788] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:04:04,797] {logging_mixin.py:104} INFO - [2021-07-08 23:04:04,797] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:04:04,806] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:04:35,331] {scheduler_job.py:182} INFO - Started process (PID=41597) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:35,333] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:04:35,333] {logging_mixin.py:104} INFO - [2021-07-08 23:04:35,333] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:35,416] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:04:35,424] {logging_mixin.py:104} INFO - [2021-07-08 23:04:35,424] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:04:35,432] {logging_mixin.py:104} INFO - [2021-07-08 23:04:35,432] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:04:35,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:05:05,870] {scheduler_job.py:182} INFO - Started process (PID=41660) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:05,872] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:05:05,872] {logging_mixin.py:104} INFO - [2021-07-08 23:05:05,872] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:05,960] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:05,968] {logging_mixin.py:104} INFO - [2021-07-08 23:05:05,968] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:05:05,977] {logging_mixin.py:104} INFO - [2021-07-08 23:05:05,977] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:05:05,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 23:05:36,577] {scheduler_job.py:182} INFO - Started process (PID=41714) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:36,578] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:05:36,578] {logging_mixin.py:104} INFO - [2021-07-08 23:05:36,578] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:36,661] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:05:36,669] {logging_mixin.py:104} INFO - [2021-07-08 23:05:36,669] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:05:36,678] {logging_mixin.py:104} INFO - [2021-07-08 23:05:36,678] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:05:36,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:06:07,187] {scheduler_job.py:182} INFO - Started process (PID=41777) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:07,188] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:06:07,188] {logging_mixin.py:104} INFO - [2021-07-08 23:06:07,188] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:07,277] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:07,287] {logging_mixin.py:104} INFO - [2021-07-08 23:06:07,287] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:06:07,298] {logging_mixin.py:104} INFO - [2021-07-08 23:06:07,298] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:06:07,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 23:06:37,858] {scheduler_job.py:182} INFO - Started process (PID=41841) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:37,859] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:06:37,860] {logging_mixin.py:104} INFO - [2021-07-08 23:06:37,860] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:37,943] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:06:37,950] {logging_mixin.py:104} INFO - [2021-07-08 23:06:37,950] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:06:37,959] {logging_mixin.py:104} INFO - [2021-07-08 23:06:37,959] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:06:37,967] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:07:08,541] {scheduler_job.py:182} INFO - Started process (PID=41894) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:08,543] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:07:08,543] {logging_mixin.py:104} INFO - [2021-07-08 23:07:08,543] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:08,626] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:08,634] {logging_mixin.py:104} INFO - [2021-07-08 23:07:08,634] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:07:08,643] {logging_mixin.py:104} INFO - [2021-07-08 23:07:08,642] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:07:08,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:07:39,242] {scheduler_job.py:182} INFO - Started process (PID=41957) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:39,243] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:07:39,244] {logging_mixin.py:104} INFO - [2021-07-08 23:07:39,244] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:39,325] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:07:39,333] {logging_mixin.py:104} INFO - [2021-07-08 23:07:39,333] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:07:39,342] {logging_mixin.py:104} INFO - [2021-07-08 23:07:39,342] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:07:39,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 23:08:09,841] {scheduler_job.py:182} INFO - Started process (PID=42022) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:09,842] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:08:09,843] {logging_mixin.py:104} INFO - [2021-07-08 23:08:09,843] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:09,926] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:09,936] {logging_mixin.py:104} INFO - [2021-07-08 23:08:09,936] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:08:09,947] {logging_mixin.py:104} INFO - [2021-07-08 23:08:09,947] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:08:09,956] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 23:08:40,589] {scheduler_job.py:182} INFO - Started process (PID=42082) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:40,590] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:08:40,591] {logging_mixin.py:104} INFO - [2021-07-08 23:08:40,591] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:40,683] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:08:40,694] {logging_mixin.py:104} INFO - [2021-07-08 23:08:40,694] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:08:40,705] {logging_mixin.py:104} INFO - [2021-07-08 23:08:40,705] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:08:40,714] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 23:09:11,440] {scheduler_job.py:182} INFO - Started process (PID=42138) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:11,441] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:09:11,442] {logging_mixin.py:104} INFO - [2021-07-08 23:09:11,441] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:11,525] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:11,535] {logging_mixin.py:104} INFO - [2021-07-08 23:09:11,535] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:09:11,545] {logging_mixin.py:104} INFO - [2021-07-08 23:09:11,545] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:09:11,553] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:09:42,044] {scheduler_job.py:182} INFO - Started process (PID=42204) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:42,045] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:09:42,046] {logging_mixin.py:104} INFO - [2021-07-08 23:09:42,046] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:42,141] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:09:42,149] {logging_mixin.py:104} INFO - [2021-07-08 23:09:42,149] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:09:42,160] {logging_mixin.py:104} INFO - [2021-07-08 23:09:42,160] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:09:42,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 23:10:12,845] {scheduler_job.py:182} INFO - Started process (PID=42267) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:12,846] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:10:12,847] {logging_mixin.py:104} INFO - [2021-07-08 23:10:12,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:12,930] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:12,938] {logging_mixin.py:104} INFO - [2021-07-08 23:10:12,938] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:10:12,947] {logging_mixin.py:104} INFO - [2021-07-08 23:10:12,947] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:10:12,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:10:43,513] {scheduler_job.py:182} INFO - Started process (PID=42321) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:43,514] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:10:43,515] {logging_mixin.py:104} INFO - [2021-07-08 23:10:43,514] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:43,597] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:10:43,604] {logging_mixin.py:104} INFO - [2021-07-08 23:10:43,604] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:10:43,613] {logging_mixin.py:104} INFO - [2021-07-08 23:10:43,613] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:10:43,621] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 23:11:14,090] {scheduler_job.py:182} INFO - Started process (PID=42384) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:14,091] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:11:14,091] {logging_mixin.py:104} INFO - [2021-07-08 23:11:14,091] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:14,173] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:14,180] {logging_mixin.py:104} INFO - [2021-07-08 23:11:14,180] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:11:14,189] {logging_mixin.py:104} INFO - [2021-07-08 23:11:14,189] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:11:14,197] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 23:11:44,784] {scheduler_job.py:182} INFO - Started process (PID=42447) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:44,785] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:11:44,786] {logging_mixin.py:104} INFO - [2021-07-08 23:11:44,786] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:44,868] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:11:44,875] {logging_mixin.py:104} INFO - [2021-07-08 23:11:44,875] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:11:44,883] {logging_mixin.py:104} INFO - [2021-07-08 23:11:44,883] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:11:44,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-07-08 23:12:15,249] {scheduler_job.py:182} INFO - Started process (PID=42500) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:15,250] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:12:15,251] {logging_mixin.py:104} INFO - [2021-07-08 23:12:15,251] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:15,333] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:15,341] {logging_mixin.py:104} INFO - [2021-07-08 23:12:15,340] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:12:15,350] {logging_mixin.py:104} INFO - [2021-07-08 23:12:15,349] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:12:15,358] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 23:12:46,218] {scheduler_job.py:182} INFO - Started process (PID=42564) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:46,219] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:12:46,220] {logging_mixin.py:104} INFO - [2021-07-08 23:12:46,220] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:46,302] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:12:46,310] {logging_mixin.py:104} INFO - [2021-07-08 23:12:46,310] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:12:46,318] {logging_mixin.py:104} INFO - [2021-07-08 23:12:46,318] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:12:46,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:13:16,882] {scheduler_job.py:182} INFO - Started process (PID=42628) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:16,883] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:13:16,884] {logging_mixin.py:104} INFO - [2021-07-08 23:13:16,884] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:16,973] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:16,983] {logging_mixin.py:104} INFO - [2021-07-08 23:13:16,983] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:13:16,994] {logging_mixin.py:104} INFO - [2021-07-08 23:13:16,994] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:13:17,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 23:13:47,840] {scheduler_job.py:182} INFO - Started process (PID=42692) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:47,841] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:13:47,841] {logging_mixin.py:104} INFO - [2021-07-08 23:13:47,841] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:47,928] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:13:47,935] {logging_mixin.py:104} INFO - [2021-07-08 23:13:47,935] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:13:47,944] {logging_mixin.py:104} INFO - [2021-07-08 23:13:47,944] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:13:47,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:14:18,464] {scheduler_job.py:182} INFO - Started process (PID=42746) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:18,465] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:14:18,466] {logging_mixin.py:104} INFO - [2021-07-08 23:14:18,465] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:18,549] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:18,558] {logging_mixin.py:104} INFO - [2021-07-08 23:14:18,558] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:14:18,568] {logging_mixin.py:104} INFO - [2021-07-08 23:14:18,568] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:14:18,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:14:49,207] {scheduler_job.py:182} INFO - Started process (PID=42809) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:49,209] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:14:49,210] {logging_mixin.py:104} INFO - [2021-07-08 23:14:49,209] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:49,307] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:14:49,315] {logging_mixin.py:104} INFO - [2021-07-08 23:14:49,315] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:14:49,325] {logging_mixin.py:104} INFO - [2021-07-08 23:14:49,325] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:14:49,332] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 23:15:19,858] {scheduler_job.py:182} INFO - Started process (PID=42875) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:19,859] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:15:19,860] {logging_mixin.py:104} INFO - [2021-07-08 23:15:19,860] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:19,943] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:19,951] {logging_mixin.py:104} INFO - [2021-07-08 23:15:19,951] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:15:19,960] {logging_mixin.py:104} INFO - [2021-07-08 23:15:19,960] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:15:19,968] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:15:50,660] {scheduler_job.py:182} INFO - Started process (PID=42930) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:50,661] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:15:50,662] {logging_mixin.py:104} INFO - [2021-07-08 23:15:50,662] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:50,779] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:15:50,787] {logging_mixin.py:104} INFO - [2021-07-08 23:15:50,787] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:15:50,797] {logging_mixin.py:104} INFO - [2021-07-08 23:15:50,797] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:15:50,805] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-07-08 23:16:21,546] {scheduler_job.py:182} INFO - Started process (PID=42993) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:21,547] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:16:21,548] {logging_mixin.py:104} INFO - [2021-07-08 23:16:21,548] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:21,631] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:21,639] {logging_mixin.py:104} INFO - [2021-07-08 23:16:21,639] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:16:21,650] {logging_mixin.py:104} INFO - [2021-07-08 23:16:21,649] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:16:21,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:16:52,147] {scheduler_job.py:182} INFO - Started process (PID=43057) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:52,148] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:16:52,149] {logging_mixin.py:104} INFO - [2021-07-08 23:16:52,149] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:52,278] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:16:52,290] {logging_mixin.py:104} INFO - [2021-07-08 23:16:52,290] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:16:52,303] {logging_mixin.py:104} INFO - [2021-07-08 23:16:52,303] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:16:52,313] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-07-08 23:17:22,886] {scheduler_job.py:182} INFO - Started process (PID=43121) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:22,887] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:17:22,888] {logging_mixin.py:104} INFO - [2021-07-08 23:17:22,887] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:22,986] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:22,998] {logging_mixin.py:104} INFO - [2021-07-08 23:17:22,997] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:17:23,008] {logging_mixin.py:104} INFO - [2021-07-08 23:17:23,008] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:17:23,016] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 23:17:53,630] {scheduler_job.py:182} INFO - Started process (PID=43174) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:53,631] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:17:53,632] {logging_mixin.py:104} INFO - [2021-07-08 23:17:53,632] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:53,715] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:17:53,723] {logging_mixin.py:104} INFO - [2021-07-08 23:17:53,722] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:17:53,731] {logging_mixin.py:104} INFO - [2021-07-08 23:17:53,731] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:17:53,740] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:18:24,337] {scheduler_job.py:182} INFO - Started process (PID=43238) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:24,338] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:18:24,338] {logging_mixin.py:104} INFO - [2021-07-08 23:18:24,338] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:24,423] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:24,430] {logging_mixin.py:104} INFO - [2021-07-08 23:18:24,430] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:18:24,439] {logging_mixin.py:104} INFO - [2021-07-08 23:18:24,439] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:18:24,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:18:54,871] {scheduler_job.py:182} INFO - Started process (PID=43300) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:54,873] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:18:54,873] {logging_mixin.py:104} INFO - [2021-07-08 23:18:54,873] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:54,957] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:18:54,964] {logging_mixin.py:104} INFO - [2021-07-08 23:18:54,964] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:18:54,973] {logging_mixin.py:104} INFO - [2021-07-08 23:18:54,973] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:18:54,981] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:19:25,513] {scheduler_job.py:182} INFO - Started process (PID=43353) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:25,514] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:19:25,515] {logging_mixin.py:104} INFO - [2021-07-08 23:19:25,515] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:25,615] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:25,623] {logging_mixin.py:104} INFO - [2021-07-08 23:19:25,623] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:19:25,632] {logging_mixin.py:104} INFO - [2021-07-08 23:19:25,632] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:19:25,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 23:19:56,348] {scheduler_job.py:182} INFO - Started process (PID=43418) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:56,351] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:19:56,351] {logging_mixin.py:104} INFO - [2021-07-08 23:19:56,351] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:56,433] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:19:56,441] {logging_mixin.py:104} INFO - [2021-07-08 23:19:56,441] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:19:56,450] {logging_mixin.py:104} INFO - [2021-07-08 23:19:56,449] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:19:56,458] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 23:20:27,036] {scheduler_job.py:182} INFO - Started process (PID=43482) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:27,037] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:20:27,037] {logging_mixin.py:104} INFO - [2021-07-08 23:20:27,037] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:27,121] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:27,128] {logging_mixin.py:104} INFO - [2021-07-08 23:20:27,128] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:20:27,137] {logging_mixin.py:104} INFO - [2021-07-08 23:20:27,137] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:20:27,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:20:57,845] {scheduler_job.py:182} INFO - Started process (PID=43535) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:57,846] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:20:57,847] {logging_mixin.py:104} INFO - [2021-07-08 23:20:57,847] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:57,946] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:20:57,953] {logging_mixin.py:104} INFO - [2021-07-08 23:20:57,953] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:20:57,962] {logging_mixin.py:104} INFO - [2021-07-08 23:20:57,962] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:20:57,969] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 23:21:28,643] {scheduler_job.py:182} INFO - Started process (PID=43598) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:28,644] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:21:28,645] {logging_mixin.py:104} INFO - [2021-07-08 23:21:28,645] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:28,730] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:28,738] {logging_mixin.py:104} INFO - [2021-07-08 23:21:28,738] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:21:28,747] {logging_mixin.py:104} INFO - [2021-07-08 23:21:28,747] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:21:28,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:21:59,304] {scheduler_job.py:182} INFO - Started process (PID=43663) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:59,305] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:21:59,306] {logging_mixin.py:104} INFO - [2021-07-08 23:21:59,305] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:59,389] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:21:59,396] {logging_mixin.py:104} INFO - [2021-07-08 23:21:59,396] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:21:59,405] {logging_mixin.py:104} INFO - [2021-07-08 23:21:59,405] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:21:59,413] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:22:30,048] {scheduler_job.py:182} INFO - Started process (PID=43726) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:22:30,049] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:22:30,050] {logging_mixin.py:104} INFO - [2021-07-08 23:22:30,050] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:22:30,147] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:22:30,158] {logging_mixin.py:104} INFO - [2021-07-08 23:22:30,158] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:22:30,168] {logging_mixin.py:104} INFO - [2021-07-08 23:22:30,168] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:22:30,177] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-07-08 23:23:00,763] {scheduler_job.py:182} INFO - Started process (PID=43780) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:00,764] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:23:00,765] {logging_mixin.py:104} INFO - [2021-07-08 23:23:00,765] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:00,860] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:00,870] {logging_mixin.py:104} INFO - [2021-07-08 23:23:00,870] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:23:00,882] {logging_mixin.py:104} INFO - [2021-07-08 23:23:00,882] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:23:00,891] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 23:23:31,658] {scheduler_job.py:182} INFO - Started process (PID=43843) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:31,659] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:23:31,659] {logging_mixin.py:104} INFO - [2021-07-08 23:23:31,659] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:31,742] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:23:31,752] {logging_mixin.py:104} INFO - [2021-07-08 23:23:31,752] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:23:31,763] {logging_mixin.py:104} INFO - [2021-07-08 23:23:31,763] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:23:31,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 23:24:02,283] {scheduler_job.py:182} INFO - Started process (PID=43905) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:02,285] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:24:02,285] {logging_mixin.py:104} INFO - [2021-07-08 23:24:02,285] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:02,377] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:02,385] {logging_mixin.py:104} INFO - [2021-07-08 23:24:02,384] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:24:02,396] {logging_mixin.py:104} INFO - [2021-07-08 23:24:02,395] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:24:02,404] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 23:24:33,002] {scheduler_job.py:182} INFO - Started process (PID=43959) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:33,003] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:24:33,004] {logging_mixin.py:104} INFO - [2021-07-08 23:24:33,004] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:33,086] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:24:33,094] {logging_mixin.py:104} INFO - [2021-07-08 23:24:33,094] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:24:33,103] {logging_mixin.py:104} INFO - [2021-07-08 23:24:33,102] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:24:33,110] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:25:03,841] {scheduler_job.py:182} INFO - Started process (PID=44023) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:03,842] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:25:03,843] {logging_mixin.py:104} INFO - [2021-07-08 23:25:03,843] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:03,924] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:03,932] {logging_mixin.py:104} INFO - [2021-07-08 23:25:03,932] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:25:03,941] {logging_mixin.py:104} INFO - [2021-07-08 23:25:03,940] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:25:03,948] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-07-08 23:25:34,501] {scheduler_job.py:182} INFO - Started process (PID=44086) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:34,502] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:25:34,503] {logging_mixin.py:104} INFO - [2021-07-08 23:25:34,503] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:34,590] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:25:34,598] {logging_mixin.py:104} INFO - [2021-07-08 23:25:34,597] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:25:34,607] {logging_mixin.py:104} INFO - [2021-07-08 23:25:34,606] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:25:34,614] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:26:05,294] {scheduler_job.py:182} INFO - Started process (PID=44152) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:05,295] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:26:05,296] {logging_mixin.py:104} INFO - [2021-07-08 23:26:05,296] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:05,384] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:05,392] {logging_mixin.py:104} INFO - [2021-07-08 23:26:05,392] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:26:05,402] {logging_mixin.py:104} INFO - [2021-07-08 23:26:05,402] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:26:05,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 23:26:36,172] {scheduler_job.py:182} INFO - Started process (PID=44206) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:36,173] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:26:36,174] {logging_mixin.py:104} INFO - [2021-07-08 23:26:36,174] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:36,336] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:26:36,346] {logging_mixin.py:104} INFO - [2021-07-08 23:26:36,346] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:26:36,357] {logging_mixin.py:104} INFO - [2021-07-08 23:26:36,357] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:26:36,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.198 seconds
[2021-07-08 23:27:06,772] {scheduler_job.py:182} INFO - Started process (PID=44270) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:06,773] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:27:06,774] {logging_mixin.py:104} INFO - [2021-07-08 23:27:06,774] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:06,877] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:06,884] {logging_mixin.py:104} INFO - [2021-07-08 23:27:06,884] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:27:06,895] {logging_mixin.py:104} INFO - [2021-07-08 23:27:06,895] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:27:06,903] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-07-08 23:27:37,443] {scheduler_job.py:182} INFO - Started process (PID=44334) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:37,444] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:27:37,445] {logging_mixin.py:104} INFO - [2021-07-08 23:27:37,445] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:37,534] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:27:37,543] {logging_mixin.py:104} INFO - [2021-07-08 23:27:37,543] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:27:37,554] {logging_mixin.py:104} INFO - [2021-07-08 23:27:37,554] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:27:37,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-07-08 23:28:08,146] {scheduler_job.py:182} INFO - Started process (PID=44389) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:08,148] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:28:08,148] {logging_mixin.py:104} INFO - [2021-07-08 23:28:08,148] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:08,231] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:08,241] {logging_mixin.py:104} INFO - [2021-07-08 23:28:08,241] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:28:08,252] {logging_mixin.py:104} INFO - [2021-07-08 23:28:08,252] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:28:08,260] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 23:28:38,961] {scheduler_job.py:182} INFO - Started process (PID=44453) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:38,963] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:28:38,963] {logging_mixin.py:104} INFO - [2021-07-08 23:28:38,963] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:39,046] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:28:39,053] {logging_mixin.py:104} INFO - [2021-07-08 23:28:39,053] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:28:39,062] {logging_mixin.py:104} INFO - [2021-07-08 23:28:39,062] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:28:39,071] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 23:29:09,593] {scheduler_job.py:182} INFO - Started process (PID=44516) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:09,594] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:29:09,595] {logging_mixin.py:104} INFO - [2021-07-08 23:29:09,595] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:09,678] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:09,686] {logging_mixin.py:104} INFO - [2021-07-08 23:29:09,686] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:29:09,694] {logging_mixin.py:104} INFO - [2021-07-08 23:29:09,694] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:29:09,702] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:29:40,490] {scheduler_job.py:182} INFO - Started process (PID=44570) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:40,492] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:29:40,492] {logging_mixin.py:104} INFO - [2021-07-08 23:29:40,492] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:40,574] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:29:40,583] {logging_mixin.py:104} INFO - [2021-07-08 23:29:40,583] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:29:40,594] {logging_mixin.py:104} INFO - [2021-07-08 23:29:40,594] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:29:40,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-07-08 23:30:11,232] {scheduler_job.py:182} INFO - Started process (PID=44636) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:11,237] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:30:11,237] {logging_mixin.py:104} INFO - [2021-07-08 23:30:11,237] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:11,386] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:11,395] {logging_mixin.py:104} INFO - [2021-07-08 23:30:11,395] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:30:11,405] {logging_mixin.py:104} INFO - [2021-07-08 23:30:11,405] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:30:11,414] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.184 seconds
[2021-07-08 23:30:41,855] {scheduler_job.py:182} INFO - Started process (PID=44699) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:41,857] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:30:41,857] {logging_mixin.py:104} INFO - [2021-07-08 23:30:41,857] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:41,940] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:30:41,947] {logging_mixin.py:104} INFO - [2021-07-08 23:30:41,947] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:30:41,956] {logging_mixin.py:104} INFO - [2021-07-08 23:30:41,956] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:30:41,964] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:31:12,546] {scheduler_job.py:182} INFO - Started process (PID=44762) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:12,548] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:31:12,549] {logging_mixin.py:104} INFO - [2021-07-08 23:31:12,548] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:12,647] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:12,656] {logging_mixin.py:104} INFO - [2021-07-08 23:31:12,656] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:31:12,666] {logging_mixin.py:104} INFO - [2021-07-08 23:31:12,665] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:31:12,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 23:31:43,246] {scheduler_job.py:182} INFO - Started process (PID=44815) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:43,247] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:31:43,248] {logging_mixin.py:104} INFO - [2021-07-08 23:31:43,247] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:43,336] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:31:43,344] {logging_mixin.py:104} INFO - [2021-07-08 23:31:43,344] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:31:43,358] {logging_mixin.py:104} INFO - [2021-07-08 23:31:43,358] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:31:43,370] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 23:32:13,948] {scheduler_job.py:182} INFO - Started process (PID=44879) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:13,950] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:32:13,951] {logging_mixin.py:104} INFO - [2021-07-08 23:32:13,951] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:14,038] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:14,047] {logging_mixin.py:104} INFO - [2021-07-08 23:32:14,047] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:32:14,058] {logging_mixin.py:104} INFO - [2021-07-08 23:32:14,058] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:32:14,072] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 23:32:44,648] {scheduler_job.py:182} INFO - Started process (PID=44942) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:44,650] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:32:44,650] {logging_mixin.py:104} INFO - [2021-07-08 23:32:44,650] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:44,742] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:32:44,749] {logging_mixin.py:104} INFO - [2021-07-08 23:32:44,749] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:32:44,759] {logging_mixin.py:104} INFO - [2021-07-08 23:32:44,759] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:32:44,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 23:33:15,420] {scheduler_job.py:182} INFO - Started process (PID=44996) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:15,422] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:33:15,422] {logging_mixin.py:104} INFO - [2021-07-08 23:33:15,422] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:15,508] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:15,516] {logging_mixin.py:104} INFO - [2021-07-08 23:33:15,516] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:33:15,525] {logging_mixin.py:104} INFO - [2021-07-08 23:33:15,524] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:33:15,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 23:33:46,169] {scheduler_job.py:182} INFO - Started process (PID=45062) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:46,174] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:33:46,175] {logging_mixin.py:104} INFO - [2021-07-08 23:33:46,174] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:46,277] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:33:46,285] {logging_mixin.py:104} INFO - [2021-07-08 23:33:46,285] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:33:46,294] {logging_mixin.py:104} INFO - [2021-07-08 23:33:46,294] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:33:46,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 23:34:16,952] {scheduler_job.py:182} INFO - Started process (PID=45125) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:16,954] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:34:16,955] {logging_mixin.py:104} INFO - [2021-07-08 23:34:16,954] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:17,039] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:17,047] {logging_mixin.py:104} INFO - [2021-07-08 23:34:17,046] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:34:17,055] {logging_mixin.py:104} INFO - [2021-07-08 23:34:17,055] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:34:17,063] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 23:34:47,649] {scheduler_job.py:182} INFO - Started process (PID=45188) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:47,651] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:34:47,652] {logging_mixin.py:104} INFO - [2021-07-08 23:34:47,651] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:47,739] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:34:47,749] {logging_mixin.py:104} INFO - [2021-07-08 23:34:47,749] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:34:47,760] {logging_mixin.py:104} INFO - [2021-07-08 23:34:47,760] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:34:47,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-07-08 23:35:18,223] {scheduler_job.py:182} INFO - Started process (PID=45241) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:18,229] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:35:18,229] {logging_mixin.py:104} INFO - [2021-07-08 23:35:18,229] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:18,313] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:18,322] {logging_mixin.py:104} INFO - [2021-07-08 23:35:18,322] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:35:18,334] {logging_mixin.py:104} INFO - [2021-07-08 23:35:18,334] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:35:18,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 23:35:49,169] {scheduler_job.py:182} INFO - Started process (PID=45304) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:49,170] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:35:49,171] {logging_mixin.py:104} INFO - [2021-07-08 23:35:49,171] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:49,255] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:35:49,262] {logging_mixin.py:104} INFO - [2021-07-08 23:35:49,262] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:35:49,271] {logging_mixin.py:104} INFO - [2021-07-08 23:35:49,270] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:35:49,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:36:19,858] {scheduler_job.py:182} INFO - Started process (PID=45369) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:19,859] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:36:19,860] {logging_mixin.py:104} INFO - [2021-07-08 23:36:19,859] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:19,945] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:19,953] {logging_mixin.py:104} INFO - [2021-07-08 23:36:19,953] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:36:19,963] {logging_mixin.py:104} INFO - [2021-07-08 23:36:19,963] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:36:19,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:36:50,824] {scheduler_job.py:182} INFO - Started process (PID=45423) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:50,826] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:36:50,827] {logging_mixin.py:104} INFO - [2021-07-08 23:36:50,827] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:50,911] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:36:50,919] {logging_mixin.py:104} INFO - [2021-07-08 23:36:50,919] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:36:50,928] {logging_mixin.py:104} INFO - [2021-07-08 23:36:50,928] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:36:50,938] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 23:37:21,765] {scheduler_job.py:182} INFO - Started process (PID=45488) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:21,768] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:37:21,769] {logging_mixin.py:104} INFO - [2021-07-08 23:37:21,769] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:21,851] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:21,859] {logging_mixin.py:104} INFO - [2021-07-08 23:37:21,859] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:37:21,868] {logging_mixin.py:104} INFO - [2021-07-08 23:37:21,867] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:37:21,876] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-07-08 23:37:52,422] {scheduler_job.py:182} INFO - Started process (PID=45552) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:52,426] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:37:52,427] {logging_mixin.py:104} INFO - [2021-07-08 23:37:52,427] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:52,512] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:37:52,519] {logging_mixin.py:104} INFO - [2021-07-08 23:37:52,519] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:37:52,528] {logging_mixin.py:104} INFO - [2021-07-08 23:37:52,528] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:37:52,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-07-08 23:38:23,095] {scheduler_job.py:182} INFO - Started process (PID=45614) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:23,096] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:38:23,097] {logging_mixin.py:104} INFO - [2021-07-08 23:38:23,097] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:23,185] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:23,193] {logging_mixin.py:104} INFO - [2021-07-08 23:38:23,192] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:38:23,202] {logging_mixin.py:104} INFO - [2021-07-08 23:38:23,202] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:38:23,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-07-08 23:38:53,741] {scheduler_job.py:182} INFO - Started process (PID=45669) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:53,742] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:38:53,743] {logging_mixin.py:104} INFO - [2021-07-08 23:38:53,743] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:53,826] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:38:53,836] {logging_mixin.py:104} INFO - [2021-07-08 23:38:53,836] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:38:53,847] {logging_mixin.py:104} INFO - [2021-07-08 23:38:53,847] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:38:53,856] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-07-08 23:39:24,753] {scheduler_job.py:182} INFO - Started process (PID=45731) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:24,756] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:39:24,757] {logging_mixin.py:104} INFO - [2021-07-08 23:39:24,756] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:24,840] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:24,848] {logging_mixin.py:104} INFO - [2021-07-08 23:39:24,848] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:39:24,856] {logging_mixin.py:104} INFO - [2021-07-08 23:39:24,856] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:39:24,866] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:39:55,580] {scheduler_job.py:182} INFO - Started process (PID=45794) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:55,582] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:39:55,583] {logging_mixin.py:104} INFO - [2021-07-08 23:39:55,582] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:55,725] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:39:55,735] {logging_mixin.py:104} INFO - [2021-07-08 23:39:55,735] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:39:55,746] {logging_mixin.py:104} INFO - [2021-07-08 23:39:55,745] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:39:55,754] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-07-08 23:40:26,405] {scheduler_job.py:182} INFO - Started process (PID=45847) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:26,407] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:40:26,408] {logging_mixin.py:104} INFO - [2021-07-08 23:40:26,408] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:26,491] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:26,498] {logging_mixin.py:104} INFO - [2021-07-08 23:40:26,498] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:40:26,506] {logging_mixin.py:104} INFO - [2021-07-08 23:40:26,506] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:40:26,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:40:57,237] {scheduler_job.py:182} INFO - Started process (PID=45910) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:57,238] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:40:57,239] {logging_mixin.py:104} INFO - [2021-07-08 23:40:57,238] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:57,322] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:40:57,330] {logging_mixin.py:104} INFO - [2021-07-08 23:40:57,330] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:40:57,339] {logging_mixin.py:104} INFO - [2021-07-08 23:40:57,339] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:40:57,347] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:41:27,918] {scheduler_job.py:182} INFO - Started process (PID=45974) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:27,923] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:41:27,924] {logging_mixin.py:104} INFO - [2021-07-08 23:41:27,924] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:28,009] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:28,016] {logging_mixin.py:104} INFO - [2021-07-08 23:41:28,016] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:41:28,025] {logging_mixin.py:104} INFO - [2021-07-08 23:41:28,025] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:41:28,032] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-07-08 23:41:58,693] {scheduler_job.py:182} INFO - Started process (PID=46035) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:58,694] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:41:58,695] {logging_mixin.py:104} INFO - [2021-07-08 23:41:58,695] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:58,798] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:41:58,809] {logging_mixin.py:104} INFO - [2021-07-08 23:41:58,809] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:41:58,820] {logging_mixin.py:104} INFO - [2021-07-08 23:41:58,820] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:41:58,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-07-08 23:42:29,425] {scheduler_job.py:182} INFO - Started process (PID=46092) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:42:29,427] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:42:29,427] {logging_mixin.py:104} INFO - [2021-07-08 23:42:29,427] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:42:29,526] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:42:29,534] {logging_mixin.py:104} INFO - [2021-07-08 23:42:29,534] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:42:29,543] {logging_mixin.py:104} INFO - [2021-07-08 23:42:29,542] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:42:29,551] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 23:43:00,474] {scheduler_job.py:182} INFO - Started process (PID=46156) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:00,480] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:43:00,480] {logging_mixin.py:104} INFO - [2021-07-08 23:43:00,480] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:00,565] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:00,572] {logging_mixin.py:104} INFO - [2021-07-08 23:43:00,572] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:43:00,581] {logging_mixin.py:104} INFO - [2021-07-08 23:43:00,581] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:43:00,590] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 23:43:31,218] {scheduler_job.py:182} INFO - Started process (PID=46221) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:31,220] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:43:31,220] {logging_mixin.py:104} INFO - [2021-07-08 23:43:31,220] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:31,304] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:43:31,312] {logging_mixin.py:104} INFO - [2021-07-08 23:43:31,312] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:43:31,321] {logging_mixin.py:104} INFO - [2021-07-08 23:43:31,321] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:43:31,329] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:44:01,830] {scheduler_job.py:182} INFO - Started process (PID=46275) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:01,831] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:44:01,832] {logging_mixin.py:104} INFO - [2021-07-08 23:44:01,832] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:01,915] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:01,922] {logging_mixin.py:104} INFO - [2021-07-08 23:44:01,922] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:44:01,931] {logging_mixin.py:104} INFO - [2021-07-08 23:44:01,931] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:44:01,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-07-08 23:44:32,723] {scheduler_job.py:182} INFO - Started process (PID=46338) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:32,724] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:44:32,725] {logging_mixin.py:104} INFO - [2021-07-08 23:44:32,725] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:32,807] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:44:32,815] {logging_mixin.py:104} INFO - [2021-07-08 23:44:32,815] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:44:32,824] {logging_mixin.py:104} INFO - [2021-07-08 23:44:32,824] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:44:32,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-07-08 23:45:03,406] {scheduler_job.py:182} INFO - Started process (PID=46401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:03,412] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:45:03,412] {logging_mixin.py:104} INFO - [2021-07-08 23:45:03,412] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:03,536] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:03,545] {logging_mixin.py:104} INFO - [2021-07-08 23:45:03,545] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:45:03,558] {logging_mixin.py:104} INFO - [2021-07-08 23:45:03,558] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:45:03,566] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-07-08 23:45:34,458] {scheduler_job.py:182} INFO - Started process (PID=46454) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:34,460] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:45:34,461] {logging_mixin.py:104} INFO - [2021-07-08 23:45:34,461] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:34,548] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:45:34,556] {logging_mixin.py:104} INFO - [2021-07-08 23:45:34,556] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:45:34,565] {logging_mixin.py:104} INFO - [2021-07-08 23:45:34,565] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:45:34,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-07-08 23:46:05,369] {scheduler_job.py:182} INFO - Started process (PID=46518) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:05,370] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:46:05,371] {logging_mixin.py:104} INFO - [2021-07-08 23:46:05,371] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:05,486] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:05,495] {logging_mixin.py:104} INFO - [2021-07-08 23:46:05,495] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:46:05,507] {logging_mixin.py:104} INFO - [2021-07-08 23:46:05,507] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:46:05,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-07-08 23:46:36,085] {scheduler_job.py:182} INFO - Started process (PID=46581) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:36,086] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:46:36,087] {logging_mixin.py:104} INFO - [2021-07-08 23:46:36,087] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:36,179] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:46:36,188] {logging_mixin.py:104} INFO - [2021-07-08 23:46:36,187] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:46:36,198] {logging_mixin.py:104} INFO - [2021-07-08 23:46:36,198] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:46:36,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-07-08 23:47:06,730] {scheduler_job.py:182} INFO - Started process (PID=46645) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:06,731] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:47:06,732] {logging_mixin.py:104} INFO - [2021-07-08 23:47:06,732] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:06,825] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:06,837] {logging_mixin.py:104} INFO - [2021-07-08 23:47:06,837] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:47:06,849] {logging_mixin.py:104} INFO - [2021-07-08 23:47:06,849] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:47:06,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 23:47:37,383] {scheduler_job.py:182} INFO - Started process (PID=46699) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:37,384] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:47:37,385] {logging_mixin.py:104} INFO - [2021-07-08 23:47:37,385] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:37,470] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:47:37,478] {logging_mixin.py:104} INFO - [2021-07-08 23:47:37,478] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:47:37,487] {logging_mixin.py:104} INFO - [2021-07-08 23:47:37,487] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:47:37,495] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-07-08 23:48:08,045] {scheduler_job.py:182} INFO - Started process (PID=46762) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:08,047] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:48:08,048] {logging_mixin.py:104} INFO - [2021-07-08 23:48:08,048] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:08,150] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:08,158] {logging_mixin.py:104} INFO - [2021-07-08 23:48:08,158] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:48:08,168] {logging_mixin.py:104} INFO - [2021-07-08 23:48:08,167] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:48:08,176] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 23:48:38,788] {scheduler_job.py:182} INFO - Started process (PID=46825) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:38,793] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:48:38,793] {logging_mixin.py:104} INFO - [2021-07-08 23:48:38,793] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:38,912] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:48:38,923] {logging_mixin.py:104} INFO - [2021-07-08 23:48:38,923] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:48:38,935] {logging_mixin.py:104} INFO - [2021-07-08 23:48:38,935] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:48:38,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.170 seconds
[2021-07-08 23:49:09,671] {scheduler_job.py:182} INFO - Started process (PID=46879) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:09,672] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:49:09,673] {logging_mixin.py:104} INFO - [2021-07-08 23:49:09,673] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:09,768] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:09,778] {logging_mixin.py:104} INFO - [2021-07-08 23:49:09,778] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:49:09,789] {logging_mixin.py:104} INFO - [2021-07-08 23:49:09,789] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:49:09,801] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 23:49:40,604] {scheduler_job.py:182} INFO - Started process (PID=46945) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:40,609] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:49:40,610] {logging_mixin.py:104} INFO - [2021-07-08 23:49:40,610] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:40,707] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:49:40,715] {logging_mixin.py:104} INFO - [2021-07-08 23:49:40,714] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:49:40,724] {logging_mixin.py:104} INFO - [2021-07-08 23:49:40,724] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:49:40,731] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-07-08 23:50:11,426] {scheduler_job.py:182} INFO - Started process (PID=47008) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:11,428] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:50:11,428] {logging_mixin.py:104} INFO - [2021-07-08 23:50:11,428] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:11,521] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:11,530] {logging_mixin.py:104} INFO - [2021-07-08 23:50:11,530] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:50:11,539] {logging_mixin.py:104} INFO - [2021-07-08 23:50:11,539] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:50:11,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 23:50:42,196] {scheduler_job.py:182} INFO - Started process (PID=47071) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:42,200] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:50:42,201] {logging_mixin.py:104} INFO - [2021-07-08 23:50:42,201] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:42,298] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:50:42,308] {logging_mixin.py:104} INFO - [2021-07-08 23:50:42,308] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:50:42,321] {logging_mixin.py:104} INFO - [2021-07-08 23:50:42,321] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:50:42,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-07-08 23:51:12,815] {scheduler_job.py:182} INFO - Started process (PID=47124) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:12,816] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:51:12,817] {logging_mixin.py:104} INFO - [2021-07-08 23:51:12,817] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:12,917] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:12,927] {logging_mixin.py:104} INFO - [2021-07-08 23:51:12,927] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:51:12,938] {logging_mixin.py:104} INFO - [2021-07-08 23:51:12,938] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:51:12,947] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-07-08 23:51:43,646] {scheduler_job.py:182} INFO - Started process (PID=47188) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:43,648] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:51:43,649] {logging_mixin.py:104} INFO - [2021-07-08 23:51:43,649] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:43,740] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:51:43,749] {logging_mixin.py:104} INFO - [2021-07-08 23:51:43,748] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:51:43,758] {logging_mixin.py:104} INFO - [2021-07-08 23:51:43,758] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:51:43,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 23:52:14,231] {scheduler_job.py:182} INFO - Started process (PID=47251) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:14,233] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:52:14,233] {logging_mixin.py:104} INFO - [2021-07-08 23:52:14,233] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:14,342] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:14,352] {logging_mixin.py:104} INFO - [2021-07-08 23:52:14,352] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:52:14,363] {logging_mixin.py:104} INFO - [2021-07-08 23:52:14,363] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:52:14,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-07-08 23:52:45,089] {scheduler_job.py:182} INFO - Started process (PID=47304) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:45,093] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:52:45,094] {logging_mixin.py:104} INFO - [2021-07-08 23:52:45,094] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:45,180] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:52:45,189] {logging_mixin.py:104} INFO - [2021-07-08 23:52:45,189] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:52:45,200] {logging_mixin.py:104} INFO - [2021-07-08 23:52:45,200] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:52:45,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-07-08 23:53:15,890] {scheduler_job.py:182} INFO - Started process (PID=47367) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:15,894] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:53:15,895] {logging_mixin.py:104} INFO - [2021-07-08 23:53:15,895] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:15,992] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:16,000] {logging_mixin.py:104} INFO - [2021-07-08 23:53:16,000] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:53:16,010] {logging_mixin.py:104} INFO - [2021-07-08 23:53:16,010] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:53:16,018] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-07-08 23:53:46,549] {scheduler_job.py:182} INFO - Started process (PID=47431) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:46,552] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:53:46,553] {logging_mixin.py:104} INFO - [2021-07-08 23:53:46,553] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:46,646] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:53:46,654] {logging_mixin.py:104} INFO - [2021-07-08 23:53:46,654] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:53:46,663] {logging_mixin.py:104} INFO - [2021-07-08 23:53:46,663] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:53:46,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-07-08 23:54:17,266] {scheduler_job.py:182} INFO - Started process (PID=47491) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:17,267] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:54:17,268] {logging_mixin.py:104} INFO - [2021-07-08 23:54:17,268] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:17,398] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:17,409] {logging_mixin.py:104} INFO - [2021-07-08 23:54:17,409] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:54:17,422] {logging_mixin.py:104} INFO - [2021-07-08 23:54:17,421] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:54:17,432] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-07-08 23:54:47,986] {scheduler_job.py:182} INFO - Started process (PID=47547) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:47,989] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:54:47,990] {logging_mixin.py:104} INFO - [2021-07-08 23:54:47,990] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:48,082] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:54:48,091] {logging_mixin.py:104} INFO - [2021-07-08 23:54:48,091] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:54:48,100] {logging_mixin.py:104} INFO - [2021-07-08 23:54:48,100] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:54:48,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-07-08 23:55:18,765] {scheduler_job.py:182} INFO - Started process (PID=47612) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:18,768] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:55:18,768] {logging_mixin.py:104} INFO - [2021-07-08 23:55:18,768] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:18,862] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:18,871] {logging_mixin.py:104} INFO - [2021-07-08 23:55:18,871] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:55:18,880] {logging_mixin.py:104} INFO - [2021-07-08 23:55:18,880] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:55:18,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 23:55:49,494] {scheduler_job.py:182} INFO - Started process (PID=47677) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:49,496] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:55:49,497] {logging_mixin.py:104} INFO - [2021-07-08 23:55:49,497] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:49,606] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:55:49,617] {logging_mixin.py:104} INFO - [2021-07-08 23:55:49,617] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:55:49,631] {logging_mixin.py:104} INFO - [2021-07-08 23:55:49,630] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:55:49,642] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-07-08 23:56:20,332] {scheduler_job.py:182} INFO - Started process (PID=47731) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:20,334] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:56:20,335] {logging_mixin.py:104} INFO - [2021-07-08 23:56:20,334] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:20,429] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:20,437] {logging_mixin.py:104} INFO - [2021-07-08 23:56:20,437] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:56:20,446] {logging_mixin.py:104} INFO - [2021-07-08 23:56:20,446] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:56:20,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-07-08 23:56:51,028] {scheduler_job.py:182} INFO - Started process (PID=47794) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:51,031] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:56:51,032] {logging_mixin.py:104} INFO - [2021-07-08 23:56:51,032] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:51,125] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:56:51,133] {logging_mixin.py:104} INFO - [2021-07-08 23:56:51,132] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:56:51,142] {logging_mixin.py:104} INFO - [2021-07-08 23:56:51,142] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:56:51,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-07-08 23:57:21,792] {scheduler_job.py:182} INFO - Started process (PID=47859) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:21,793] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:57:21,794] {logging_mixin.py:104} INFO - [2021-07-08 23:57:21,794] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:21,889] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:21,899] {logging_mixin.py:104} INFO - [2021-07-08 23:57:21,899] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:57:21,911] {logging_mixin.py:104} INFO - [2021-07-08 23:57:21,911] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:57:21,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-07-08 23:57:52,716] {scheduler_job.py:182} INFO - Started process (PID=47912) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:52,719] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:57:52,720] {logging_mixin.py:104} INFO - [2021-07-08 23:57:52,720] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:52,837] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:57:52,845] {logging_mixin.py:104} INFO - [2021-07-08 23:57:52,845] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:57:52,855] {logging_mixin.py:104} INFO - [2021-07-08 23:57:52,855] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:57:52,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-07-08 23:58:23,570] {scheduler_job.py:182} INFO - Started process (PID=47978) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:23,571] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:58:23,572] {logging_mixin.py:104} INFO - [2021-07-08 23:58:23,572] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:23,663] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:23,672] {logging_mixin.py:104} INFO - [2021-07-08 23:58:23,671] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:58:23,681] {logging_mixin.py:104} INFO - [2021-07-08 23:58:23,681] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:58:23,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-07-08 23:58:54,467] {scheduler_job.py:182} INFO - Started process (PID=48042) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:54,468] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:58:54,469] {logging_mixin.py:104} INFO - [2021-07-08 23:58:54,468] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:54,568] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:58:54,576] {logging_mixin.py:104} INFO - [2021-07-08 23:58:54,576] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:58:54,586] {logging_mixin.py:104} INFO - [2021-07-08 23:58:54,585] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:58:54,594] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-07-08 23:59:25,131] {scheduler_job.py:182} INFO - Started process (PID=48105) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:25,132] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:59:25,133] {logging_mixin.py:104} INFO - [2021-07-08 23:59:25,133] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:25,248] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:25,259] {logging_mixin.py:104} INFO - [2021-07-08 23:59:25,259] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:59:25,272] {logging_mixin.py:104} INFO - [2021-07-08 23:59:25,272] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:59:25,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-07-08 23:59:56,107] {scheduler_job.py:182} INFO - Started process (PID=48159) to work on /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:56,109] {scheduler_job.py:633} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-07-08 23:59:56,110] {logging_mixin.py:104} INFO - [2021-07-08 23:59:56,110] {dagbag.py:496} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:56,206] {scheduler_job.py:643} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-07-08 23:59:56,215] {logging_mixin.py:104} INFO - [2021-07-08 23:59:56,215] {dag.py:1833} INFO - Sync 1 DAGs
[2021-07-08 23:59:56,225] {logging_mixin.py:104} INFO - [2021-07-08 23:59:56,225] {dag.py:2306} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-07-08 00:00:00+00:00
[2021-07-08 23:59:56,233] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
