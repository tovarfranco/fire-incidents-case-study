[2021-08-28 00:00:15,397] {scheduler_job.py:182} INFO - Started process (PID=3909) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:15,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:00:15,398] {logging_mixin.py:104} INFO - [2021-08-28 00:00:15,398] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:15,487] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:15,497] {logging_mixin.py:104} INFO - [2021-08-28 00:00:15,497] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:00:15,506] {logging_mixin.py:104} INFO - [2021-08-28 00:00:15,506] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:00:15.506082+00:00
[2021-08-28 00:00:15,518] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-28 00:00:45,625] {scheduler_job.py:182} INFO - Started process (PID=3912) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:45,626] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:00:45,626] {logging_mixin.py:104} INFO - [2021-08-28 00:00:45,626] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:45,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:00:45,721] {logging_mixin.py:104} INFO - [2021-08-28 00:00:45,720] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:00:45,730] {logging_mixin.py:104} INFO - [2021-08-28 00:00:45,730] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:00:45.730532+00:00
[2021-08-28 00:00:45,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:01:15,849] {scheduler_job.py:182} INFO - Started process (PID=3915) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:15,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:01:15,850] {logging_mixin.py:104} INFO - [2021-08-28 00:01:15,850] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:15,935] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:15,942] {logging_mixin.py:104} INFO - [2021-08-28 00:01:15,942] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:01:15,951] {logging_mixin.py:104} INFO - [2021-08-28 00:01:15,951] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:01:15.951367+00:00
[2021-08-28 00:01:15,958] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 00:01:46,085] {scheduler_job.py:182} INFO - Started process (PID=3918) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:46,086] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:01:46,086] {logging_mixin.py:104} INFO - [2021-08-28 00:01:46,086] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:46,179] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:01:46,188] {logging_mixin.py:104} INFO - [2021-08-28 00:01:46,188] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:01:46,199] {logging_mixin.py:104} INFO - [2021-08-28 00:01:46,199] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:01:46.199761+00:00
[2021-08-28 00:01:46,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-28 00:02:16,305] {scheduler_job.py:182} INFO - Started process (PID=3921) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:16,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:02:16,306] {logging_mixin.py:104} INFO - [2021-08-28 00:02:16,306] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:16,393] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:16,400] {logging_mixin.py:104} INFO - [2021-08-28 00:02:16,400] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:02:16,410] {logging_mixin.py:104} INFO - [2021-08-28 00:02:16,410] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:02:16.410765+00:00
[2021-08-28 00:02:16,416] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:02:46,520] {scheduler_job.py:182} INFO - Started process (PID=3924) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:46,521] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:02:46,521] {logging_mixin.py:104} INFO - [2021-08-28 00:02:46,521] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:46,608] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:02:46,616] {logging_mixin.py:104} INFO - [2021-08-28 00:02:46,616] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:02:46,627] {logging_mixin.py:104} INFO - [2021-08-28 00:02:46,627] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:02:46.627361+00:00
[2021-08-28 00:02:46,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:03:16,747] {scheduler_job.py:182} INFO - Started process (PID=3927) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:16,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:03:16,748] {logging_mixin.py:104} INFO - [2021-08-28 00:03:16,748] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:16,835] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:16,842] {logging_mixin.py:104} INFO - [2021-08-28 00:03:16,842] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:03:16,852] {logging_mixin.py:104} INFO - [2021-08-28 00:03:16,852] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:03:16.852524+00:00
[2021-08-28 00:03:16,859] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:03:46,968] {scheduler_job.py:182} INFO - Started process (PID=3930) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:46,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:03:46,969] {logging_mixin.py:104} INFO - [2021-08-28 00:03:46,969] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:47,056] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:03:47,065] {logging_mixin.py:104} INFO - [2021-08-28 00:03:47,065] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:03:47,077] {logging_mixin.py:104} INFO - [2021-08-28 00:03:47,077] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:03:47.076997+00:00
[2021-08-28 00:03:47,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 00:04:17,194] {scheduler_job.py:182} INFO - Started process (PID=3933) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:17,195] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:04:17,195] {logging_mixin.py:104} INFO - [2021-08-28 00:04:17,195] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:17,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:17,290] {logging_mixin.py:104} INFO - [2021-08-28 00:04:17,290] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:04:17,300] {logging_mixin.py:104} INFO - [2021-08-28 00:04:17,300] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:04:17.300501+00:00
[2021-08-28 00:04:17,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:04:47,447] {scheduler_job.py:182} INFO - Started process (PID=3936) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:47,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:04:47,448] {logging_mixin.py:104} INFO - [2021-08-28 00:04:47,448] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:47,536] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:04:47,545] {logging_mixin.py:104} INFO - [2021-08-28 00:04:47,545] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:04:47,558] {logging_mixin.py:104} INFO - [2021-08-28 00:04:47,558] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:04:47.557959+00:00
[2021-08-28 00:04:47,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 00:05:17,656] {scheduler_job.py:182} INFO - Started process (PID=3939) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:17,657] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:05:17,657] {logging_mixin.py:104} INFO - [2021-08-28 00:05:17,657] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:17,743] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:17,750] {logging_mixin.py:104} INFO - [2021-08-28 00:05:17,750] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:05:17,760] {logging_mixin.py:104} INFO - [2021-08-28 00:05:17,760] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:05:17.760479+00:00
[2021-08-28 00:05:17,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:05:47,879] {scheduler_job.py:182} INFO - Started process (PID=3942) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:47,880] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:05:47,880] {logging_mixin.py:104} INFO - [2021-08-28 00:05:47,880] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:47,967] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:05:47,975] {logging_mixin.py:104} INFO - [2021-08-28 00:05:47,975] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:05:47,985] {logging_mixin.py:104} INFO - [2021-08-28 00:05:47,985] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:05:47.985176+00:00
[2021-08-28 00:05:47,991] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:06:18,103] {scheduler_job.py:182} INFO - Started process (PID=3945) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:18,104] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:06:18,104] {logging_mixin.py:104} INFO - [2021-08-28 00:06:18,104] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:18,202] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:18,211] {logging_mixin.py:104} INFO - [2021-08-28 00:06:18,210] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:06:18,221] {logging_mixin.py:104} INFO - [2021-08-28 00:06:18,221] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:06:18.221403+00:00
[2021-08-28 00:06:18,228] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-28 00:06:48,336] {scheduler_job.py:182} INFO - Started process (PID=3948) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:48,336] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:06:48,337] {logging_mixin.py:104} INFO - [2021-08-28 00:06:48,337] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:48,422] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:06:48,430] {logging_mixin.py:104} INFO - [2021-08-28 00:06:48,430] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:06:48,440] {logging_mixin.py:104} INFO - [2021-08-28 00:06:48,440] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:06:48.439993+00:00
[2021-08-28 00:06:48,446] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:07:18,557] {scheduler_job.py:182} INFO - Started process (PID=3951) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:18,558] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:07:18,558] {logging_mixin.py:104} INFO - [2021-08-28 00:07:18,558] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:18,644] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:18,652] {logging_mixin.py:104} INFO - [2021-08-28 00:07:18,652] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:07:18,662] {logging_mixin.py:104} INFO - [2021-08-28 00:07:18,662] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:07:18.661956+00:00
[2021-08-28 00:07:18,668] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:07:48,777] {scheduler_job.py:182} INFO - Started process (PID=3954) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:48,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:07:48,778] {logging_mixin.py:104} INFO - [2021-08-28 00:07:48,778] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:48,863] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:07:48,871] {logging_mixin.py:104} INFO - [2021-08-28 00:07:48,871] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:07:48,881] {logging_mixin.py:104} INFO - [2021-08-28 00:07:48,881] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:07:48.880981+00:00
[2021-08-28 00:07:48,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:08:19,004] {scheduler_job.py:182} INFO - Started process (PID=3957) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:19,004] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:08:19,005] {logging_mixin.py:104} INFO - [2021-08-28 00:08:19,005] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:19,089] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:19,096] {logging_mixin.py:104} INFO - [2021-08-28 00:08:19,096] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:08:19,106] {logging_mixin.py:104} INFO - [2021-08-28 00:08:19,106] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:08:19.106404+00:00
[2021-08-28 00:08:19,112] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 00:08:49,228] {scheduler_job.py:182} INFO - Started process (PID=3960) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:49,229] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:08:49,230] {logging_mixin.py:104} INFO - [2021-08-28 00:08:49,229] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:49,316] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:08:49,324] {logging_mixin.py:104} INFO - [2021-08-28 00:08:49,324] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:08:49,334] {logging_mixin.py:104} INFO - [2021-08-28 00:08:49,333] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:08:49.333832+00:00
[2021-08-28 00:08:49,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:09:19,442] {scheduler_job.py:182} INFO - Started process (PID=3963) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:19,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:09:19,443] {logging_mixin.py:104} INFO - [2021-08-28 00:09:19,443] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:19,528] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:19,536] {logging_mixin.py:104} INFO - [2021-08-28 00:09:19,536] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:09:19,546] {logging_mixin.py:104} INFO - [2021-08-28 00:09:19,546] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:09:19.546182+00:00
[2021-08-28 00:09:19,552] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:09:49,691] {scheduler_job.py:182} INFO - Started process (PID=3966) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:49,692] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:09:49,692] {logging_mixin.py:104} INFO - [2021-08-28 00:09:49,692] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:49,779] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:09:49,786] {logging_mixin.py:104} INFO - [2021-08-28 00:09:49,786] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:09:49,796] {logging_mixin.py:104} INFO - [2021-08-28 00:09:49,796] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:09:49.796005+00:00
[2021-08-28 00:09:49,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:10:19,923] {scheduler_job.py:182} INFO - Started process (PID=3969) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:19,924] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:10:19,924] {logging_mixin.py:104} INFO - [2021-08-28 00:10:19,924] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:20,013] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:20,020] {logging_mixin.py:104} INFO - [2021-08-28 00:10:20,020] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:10:20,030] {logging_mixin.py:104} INFO - [2021-08-28 00:10:20,030] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:10:20.030221+00:00
[2021-08-28 00:10:20,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:10:50,163] {scheduler_job.py:182} INFO - Started process (PID=3972) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:50,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:10:50,164] {logging_mixin.py:104} INFO - [2021-08-28 00:10:50,164] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:50,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:10:50,255] {logging_mixin.py:104} INFO - [2021-08-28 00:10:50,255] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:10:50,265] {logging_mixin.py:104} INFO - [2021-08-28 00:10:50,265] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:10:50.265151+00:00
[2021-08-28 00:10:50,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:11:20,376] {scheduler_job.py:182} INFO - Started process (PID=3975) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:20,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:11:20,377] {logging_mixin.py:104} INFO - [2021-08-28 00:11:20,377] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:20,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:20,470] {logging_mixin.py:104} INFO - [2021-08-28 00:11:20,470] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:11:20,480] {logging_mixin.py:104} INFO - [2021-08-28 00:11:20,480] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:11:20.480209+00:00
[2021-08-28 00:11:20,486] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:11:50,599] {scheduler_job.py:182} INFO - Started process (PID=3978) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:50,600] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:11:50,601] {logging_mixin.py:104} INFO - [2021-08-28 00:11:50,601] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:50,695] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:11:50,703] {logging_mixin.py:104} INFO - [2021-08-28 00:11:50,703] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:11:50,712] {logging_mixin.py:104} INFO - [2021-08-28 00:11:50,712] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:11:50.712390+00:00
[2021-08-28 00:11:50,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 00:12:20,828] {scheduler_job.py:182} INFO - Started process (PID=3981) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:20,828] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:12:20,829] {logging_mixin.py:104} INFO - [2021-08-28 00:12:20,829] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:20,917] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:20,925] {logging_mixin.py:104} INFO - [2021-08-28 00:12:20,925] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:12:20,934] {logging_mixin.py:104} INFO - [2021-08-28 00:12:20,934] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:12:20.934602+00:00
[2021-08-28 00:12:20,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:12:51,051] {scheduler_job.py:182} INFO - Started process (PID=3984) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:51,052] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:12:51,052] {logging_mixin.py:104} INFO - [2021-08-28 00:12:51,052] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:51,139] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:12:51,147] {logging_mixin.py:104} INFO - [2021-08-28 00:12:51,147] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:12:51,156] {logging_mixin.py:104} INFO - [2021-08-28 00:12:51,156] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:12:51.156780+00:00
[2021-08-28 00:12:51,165] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:13:21,279] {scheduler_job.py:182} INFO - Started process (PID=3987) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:21,279] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:13:21,280] {logging_mixin.py:104} INFO - [2021-08-28 00:13:21,279] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:21,366] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:21,373] {logging_mixin.py:104} INFO - [2021-08-28 00:13:21,373] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:13:21,382] {logging_mixin.py:104} INFO - [2021-08-28 00:13:21,382] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:13:21.382742+00:00
[2021-08-28 00:13:21,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:13:51,500] {scheduler_job.py:182} INFO - Started process (PID=3990) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:51,501] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:13:51,501] {logging_mixin.py:104} INFO - [2021-08-28 00:13:51,501] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:51,589] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:13:51,598] {logging_mixin.py:104} INFO - [2021-08-28 00:13:51,598] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:13:51,610] {logging_mixin.py:104} INFO - [2021-08-28 00:13:51,610] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:13:51.610216+00:00
[2021-08-28 00:13:51,617] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:14:21,731] {scheduler_job.py:182} INFO - Started process (PID=3993) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:21,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:14:21,732] {logging_mixin.py:104} INFO - [2021-08-28 00:14:21,732] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:21,823] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:21,831] {logging_mixin.py:104} INFO - [2021-08-28 00:14:21,831] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:14:21,843] {logging_mixin.py:104} INFO - [2021-08-28 00:14:21,843] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:14:21.843255+00:00
[2021-08-28 00:14:21,850] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 00:14:51,974] {scheduler_job.py:182} INFO - Started process (PID=3996) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:51,974] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:14:51,975] {logging_mixin.py:104} INFO - [2021-08-28 00:14:51,975] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:52,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:14:52,070] {logging_mixin.py:104} INFO - [2021-08-28 00:14:52,070] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:14:52,080] {logging_mixin.py:104} INFO - [2021-08-28 00:14:52,080] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:14:52.080187+00:00
[2021-08-28 00:14:52,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:15:22,202] {scheduler_job.py:182} INFO - Started process (PID=3999) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:22,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:15:22,203] {logging_mixin.py:104} INFO - [2021-08-28 00:15:22,203] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:22,288] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:22,295] {logging_mixin.py:104} INFO - [2021-08-28 00:15:22,295] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:15:22,304] {logging_mixin.py:104} INFO - [2021-08-28 00:15:22,304] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:15:22.304754+00:00
[2021-08-28 00:15:22,311] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:15:52,424] {scheduler_job.py:182} INFO - Started process (PID=4002) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:52,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:15:52,425] {logging_mixin.py:104} INFO - [2021-08-28 00:15:52,425] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:52,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:15:52,520] {logging_mixin.py:104} INFO - [2021-08-28 00:15:52,520] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:15:52,531] {logging_mixin.py:104} INFO - [2021-08-28 00:15:52,531] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:15:52.531483+00:00
[2021-08-28 00:15:52,538] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 00:16:22,648] {scheduler_job.py:182} INFO - Started process (PID=4005) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:22,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:16:22,649] {logging_mixin.py:104} INFO - [2021-08-28 00:16:22,649] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:22,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:22,742] {logging_mixin.py:104} INFO - [2021-08-28 00:16:22,741] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:16:22,751] {logging_mixin.py:104} INFO - [2021-08-28 00:16:22,751] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:16:22.751270+00:00
[2021-08-28 00:16:22,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:16:52,862] {scheduler_job.py:182} INFO - Started process (PID=4008) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:52,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:16:52,863] {logging_mixin.py:104} INFO - [2021-08-28 00:16:52,863] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:52,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:16:52,956] {logging_mixin.py:104} INFO - [2021-08-28 00:16:52,956] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:16:52,968] {logging_mixin.py:104} INFO - [2021-08-28 00:16:52,968] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:16:52.968278+00:00
[2021-08-28 00:16:52,975] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:17:23,084] {scheduler_job.py:182} INFO - Started process (PID=4011) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:23,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:17:23,085] {logging_mixin.py:104} INFO - [2021-08-28 00:17:23,085] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:23,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:23,181] {logging_mixin.py:104} INFO - [2021-08-28 00:17:23,181] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:17:23,192] {logging_mixin.py:104} INFO - [2021-08-28 00:17:23,192] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:17:23.192703+00:00
[2021-08-28 00:17:23,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:17:53,302] {scheduler_job.py:182} INFO - Started process (PID=4014) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:53,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:17:53,303] {logging_mixin.py:104} INFO - [2021-08-28 00:17:53,303] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:53,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:17:53,400] {logging_mixin.py:104} INFO - [2021-08-28 00:17:53,400] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:17:53,411] {logging_mixin.py:104} INFO - [2021-08-28 00:17:53,411] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:17:53.411437+00:00
[2021-08-28 00:17:53,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 00:18:23,525] {scheduler_job.py:182} INFO - Started process (PID=4017) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:23,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:18:23,526] {logging_mixin.py:104} INFO - [2021-08-28 00:18:23,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:23,613] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:23,620] {logging_mixin.py:104} INFO - [2021-08-28 00:18:23,620] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:18:23,630] {logging_mixin.py:104} INFO - [2021-08-28 00:18:23,630] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:18:23.630499+00:00
[2021-08-28 00:18:23,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:18:53,752] {scheduler_job.py:182} INFO - Started process (PID=4020) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:53,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:18:53,753] {logging_mixin.py:104} INFO - [2021-08-28 00:18:53,753] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:53,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:18:53,846] {logging_mixin.py:104} INFO - [2021-08-28 00:18:53,846] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:18:53,855] {logging_mixin.py:104} INFO - [2021-08-28 00:18:53,855] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:18:53.855212+00:00
[2021-08-28 00:18:53,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 00:19:23,966] {scheduler_job.py:182} INFO - Started process (PID=4023) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:23,967] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:19:23,967] {logging_mixin.py:104} INFO - [2021-08-28 00:19:23,967] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:24,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:24,061] {logging_mixin.py:104} INFO - [2021-08-28 00:19:24,061] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:19:24,071] {logging_mixin.py:104} INFO - [2021-08-28 00:19:24,070] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:19:24.070829+00:00
[2021-08-28 00:19:24,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:19:54,209] {scheduler_job.py:182} INFO - Started process (PID=4026) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:54,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:19:54,210] {logging_mixin.py:104} INFO - [2021-08-28 00:19:54,210] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:54,297] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:19:54,304] {logging_mixin.py:104} INFO - [2021-08-28 00:19:54,304] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:19:54,313] {logging_mixin.py:104} INFO - [2021-08-28 00:19:54,313] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:19:54.313582+00:00
[2021-08-28 00:19:54,319] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:20:24,432] {scheduler_job.py:182} INFO - Started process (PID=4029) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:24,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:20:24,433] {logging_mixin.py:104} INFO - [2021-08-28 00:20:24,433] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:24,519] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:24,527] {logging_mixin.py:104} INFO - [2021-08-28 00:20:24,527] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:20:24,537] {logging_mixin.py:104} INFO - [2021-08-28 00:20:24,537] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:20:24.537013+00:00
[2021-08-28 00:20:24,542] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:20:54,646] {scheduler_job.py:182} INFO - Started process (PID=4032) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:54,647] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:20:54,647] {logging_mixin.py:104} INFO - [2021-08-28 00:20:54,647] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:54,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:20:54,740] {logging_mixin.py:104} INFO - [2021-08-28 00:20:54,740] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:20:54,750] {logging_mixin.py:104} INFO - [2021-08-28 00:20:54,750] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:20:54.750227+00:00
[2021-08-28 00:20:54,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:21:24,868] {scheduler_job.py:182} INFO - Started process (PID=4035) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:24,869] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:21:24,869] {logging_mixin.py:104} INFO - [2021-08-28 00:21:24,869] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:24,954] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:24,961] {logging_mixin.py:104} INFO - [2021-08-28 00:21:24,961] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:21:24,971] {logging_mixin.py:104} INFO - [2021-08-28 00:21:24,971] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:21:24.971517+00:00
[2021-08-28 00:21:24,978] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:21:55,079] {scheduler_job.py:182} INFO - Started process (PID=4038) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:55,080] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:21:55,080] {logging_mixin.py:104} INFO - [2021-08-28 00:21:55,080] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:55,167] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:21:55,174] {logging_mixin.py:104} INFO - [2021-08-28 00:21:55,174] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:21:55,184] {logging_mixin.py:104} INFO - [2021-08-28 00:21:55,184] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:21:55.183974+00:00
[2021-08-28 00:21:55,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:22:25,299] {scheduler_job.py:182} INFO - Started process (PID=4041) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:25,300] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:22:25,300] {logging_mixin.py:104} INFO - [2021-08-28 00:22:25,300] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:25,388] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:25,395] {logging_mixin.py:104} INFO - [2021-08-28 00:22:25,395] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:22:25,406] {logging_mixin.py:104} INFO - [2021-08-28 00:22:25,406] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:22:25.406679+00:00
[2021-08-28 00:22:25,413] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:22:55,525] {scheduler_job.py:182} INFO - Started process (PID=4044) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:55,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:22:55,526] {logging_mixin.py:104} INFO - [2021-08-28 00:22:55,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:55,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:22:55,617] {logging_mixin.py:104} INFO - [2021-08-28 00:22:55,617] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:22:55,627] {logging_mixin.py:104} INFO - [2021-08-28 00:22:55,627] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:22:55.626976+00:00
[2021-08-28 00:22:55,633] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 00:23:25,742] {scheduler_job.py:182} INFO - Started process (PID=4047) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:25,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:23:25,743] {logging_mixin.py:104} INFO - [2021-08-28 00:23:25,743] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:25,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:25,836] {logging_mixin.py:104} INFO - [2021-08-28 00:23:25,835] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:23:25,845] {logging_mixin.py:104} INFO - [2021-08-28 00:23:25,845] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:23:25.845589+00:00
[2021-08-28 00:23:25,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:23:55,974] {scheduler_job.py:182} INFO - Started process (PID=4050) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:55,975] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:23:55,975] {logging_mixin.py:104} INFO - [2021-08-28 00:23:55,975] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:56,061] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:23:56,068] {logging_mixin.py:104} INFO - [2021-08-28 00:23:56,067] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:23:56,077] {logging_mixin.py:104} INFO - [2021-08-28 00:23:56,077] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:23:56.076909+00:00
[2021-08-28 00:23:56,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:24:26,197] {scheduler_job.py:182} INFO - Started process (PID=4053) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:26,198] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:24:26,198] {logging_mixin.py:104} INFO - [2021-08-28 00:24:26,198] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:26,283] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:26,290] {logging_mixin.py:104} INFO - [2021-08-28 00:24:26,290] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:24:26,300] {logging_mixin.py:104} INFO - [2021-08-28 00:24:26,300] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:24:26.300413+00:00
[2021-08-28 00:24:26,307] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:24:56,441] {scheduler_job.py:182} INFO - Started process (PID=4056) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:56,442] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:24:56,442] {logging_mixin.py:104} INFO - [2021-08-28 00:24:56,442] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:56,530] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:24:56,539] {logging_mixin.py:104} INFO - [2021-08-28 00:24:56,539] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:24:56,550] {logging_mixin.py:104} INFO - [2021-08-28 00:24:56,550] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:24:56.550565+00:00
[2021-08-28 00:24:56,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 00:25:26,666] {scheduler_job.py:182} INFO - Started process (PID=4059) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:26,667] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:25:26,667] {logging_mixin.py:104} INFO - [2021-08-28 00:25:26,667] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:26,753] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:26,762] {logging_mixin.py:104} INFO - [2021-08-28 00:25:26,762] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:25:26,775] {logging_mixin.py:104} INFO - [2021-08-28 00:25:26,775] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:25:26.775491+00:00
[2021-08-28 00:25:26,782] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:25:56,886] {scheduler_job.py:182} INFO - Started process (PID=4062) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:56,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:25:56,887] {logging_mixin.py:104} INFO - [2021-08-28 00:25:56,887] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:56,973] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:25:56,981] {logging_mixin.py:104} INFO - [2021-08-28 00:25:56,981] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:25:56,990] {logging_mixin.py:104} INFO - [2021-08-28 00:25:56,990] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:25:56.990481+00:00
[2021-08-28 00:25:56,996] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:26:27,109] {scheduler_job.py:182} INFO - Started process (PID=4065) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:27,109] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:26:27,110] {logging_mixin.py:104} INFO - [2021-08-28 00:26:27,110] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:27,198] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:27,205] {logging_mixin.py:104} INFO - [2021-08-28 00:26:27,205] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:26:27,215] {logging_mixin.py:104} INFO - [2021-08-28 00:26:27,215] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:26:27.214919+00:00
[2021-08-28 00:26:27,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:26:57,332] {scheduler_job.py:182} INFO - Started process (PID=4068) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:57,333] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:26:57,333] {logging_mixin.py:104} INFO - [2021-08-28 00:26:57,333] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:57,420] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:26:57,427] {logging_mixin.py:104} INFO - [2021-08-28 00:26:57,427] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:26:57,436] {logging_mixin.py:104} INFO - [2021-08-28 00:26:57,436] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:26:57.436658+00:00
[2021-08-28 00:26:57,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:27:27,559] {scheduler_job.py:182} INFO - Started process (PID=4071) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:27,560] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:27:27,560] {logging_mixin.py:104} INFO - [2021-08-28 00:27:27,560] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:27,647] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:27,656] {logging_mixin.py:104} INFO - [2021-08-28 00:27:27,656] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:27:27,669] {logging_mixin.py:104} INFO - [2021-08-28 00:27:27,669] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:27:27.669557+00:00
[2021-08-28 00:27:27,676] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 00:27:57,789] {scheduler_job.py:182} INFO - Started process (PID=4074) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:57,790] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:27:57,790] {logging_mixin.py:104} INFO - [2021-08-28 00:27:57,790] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:57,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:27:57,882] {logging_mixin.py:104} INFO - [2021-08-28 00:27:57,882] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:27:57,892] {logging_mixin.py:104} INFO - [2021-08-28 00:27:57,892] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:27:57.892240+00:00
[2021-08-28 00:27:57,898] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:28:28,010] {scheduler_job.py:182} INFO - Started process (PID=4077) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:28,010] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:28:28,011] {logging_mixin.py:104} INFO - [2021-08-28 00:28:28,011] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:28,096] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:28,103] {logging_mixin.py:104} INFO - [2021-08-28 00:28:28,103] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:28:28,113] {logging_mixin.py:104} INFO - [2021-08-28 00:28:28,113] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:28:28.113159+00:00
[2021-08-28 00:28:28,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:28:58,230] {scheduler_job.py:182} INFO - Started process (PID=4080) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:58,231] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:28:58,232] {logging_mixin.py:104} INFO - [2021-08-28 00:28:58,231] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:58,328] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:28:58,337] {logging_mixin.py:104} INFO - [2021-08-28 00:28:58,337] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:28:58,349] {logging_mixin.py:104} INFO - [2021-08-28 00:28:58,349] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:28:58.349140+00:00
[2021-08-28 00:28:58,357] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-08-28 00:29:28,468] {scheduler_job.py:182} INFO - Started process (PID=4083) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:28,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:29:28,469] {logging_mixin.py:104} INFO - [2021-08-28 00:29:28,469] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:28,552] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:28,561] {logging_mixin.py:104} INFO - [2021-08-28 00:29:28,560] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:29:28,570] {logging_mixin.py:104} INFO - [2021-08-28 00:29:28,570] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:29:28.570447+00:00
[2021-08-28 00:29:28,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 00:29:58,708] {scheduler_job.py:182} INFO - Started process (PID=4086) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:58,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:29:58,709] {logging_mixin.py:104} INFO - [2021-08-28 00:29:58,709] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:58,793] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:29:58,801] {logging_mixin.py:104} INFO - [2021-08-28 00:29:58,801] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:29:58,811] {logging_mixin.py:104} INFO - [2021-08-28 00:29:58,811] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:29:58.811440+00:00
[2021-08-28 00:29:58,818] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:30:28,934] {scheduler_job.py:182} INFO - Started process (PID=4089) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:28,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:30:28,935] {logging_mixin.py:104} INFO - [2021-08-28 00:30:28,935] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:29,024] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:29,031] {logging_mixin.py:104} INFO - [2021-08-28 00:30:29,031] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:30:29,040] {logging_mixin.py:104} INFO - [2021-08-28 00:30:29,040] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:30:29.040640+00:00
[2021-08-28 00:30:29,046] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:30:59,160] {scheduler_job.py:182} INFO - Started process (PID=4092) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:59,161] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:30:59,161] {logging_mixin.py:104} INFO - [2021-08-28 00:30:59,161] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:59,257] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:30:59,265] {logging_mixin.py:104} INFO - [2021-08-28 00:30:59,265] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:30:59,276] {logging_mixin.py:104} INFO - [2021-08-28 00:30:59,276] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:30:59.276380+00:00
[2021-08-28 00:30:59,283] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-08-28 00:31:29,405] {scheduler_job.py:182} INFO - Started process (PID=4095) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:29,406] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:31:29,406] {logging_mixin.py:104} INFO - [2021-08-28 00:31:29,406] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:29,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:29,507] {logging_mixin.py:104} INFO - [2021-08-28 00:31:29,507] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:31:29,517] {logging_mixin.py:104} INFO - [2021-08-28 00:31:29,517] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:31:29.517491+00:00
[2021-08-28 00:31:29,525] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 00:31:59,644] {scheduler_job.py:182} INFO - Started process (PID=4098) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:59,645] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:31:59,646] {logging_mixin.py:104} INFO - [2021-08-28 00:31:59,646] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:59,732] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:31:59,740] {logging_mixin.py:104} INFO - [2021-08-28 00:31:59,740] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:31:59,750] {logging_mixin.py:104} INFO - [2021-08-28 00:31:59,750] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:31:59.750213+00:00
[2021-08-28 00:31:59,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:32:29,851] {scheduler_job.py:182} INFO - Started process (PID=4101) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:32:29,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:32:29,852] {logging_mixin.py:104} INFO - [2021-08-28 00:32:29,852] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:32:29,945] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:32:29,953] {logging_mixin.py:104} INFO - [2021-08-28 00:32:29,953] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:32:29,964] {logging_mixin.py:104} INFO - [2021-08-28 00:32:29,964] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:32:29.964654+00:00
[2021-08-28 00:32:29,971] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 00:33:00,080] {scheduler_job.py:182} INFO - Started process (PID=4104) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:00,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:33:00,081] {logging_mixin.py:104} INFO - [2021-08-28 00:33:00,081] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:00,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:00,193] {logging_mixin.py:104} INFO - [2021-08-28 00:33:00,193] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:33:00,205] {logging_mixin.py:104} INFO - [2021-08-28 00:33:00,205] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:33:00.205006+00:00
[2021-08-28 00:33:00,211] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-08-28 00:33:30,313] {scheduler_job.py:182} INFO - Started process (PID=4107) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:30,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:33:30,314] {logging_mixin.py:104} INFO - [2021-08-28 00:33:30,314] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:30,405] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:33:30,413] {logging_mixin.py:104} INFO - [2021-08-28 00:33:30,413] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:33:30,424] {logging_mixin.py:104} INFO - [2021-08-28 00:33:30,424] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:33:30.423928+00:00
[2021-08-28 00:33:30,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 00:34:00,537] {scheduler_job.py:182} INFO - Started process (PID=4110) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:00,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:34:00,538] {logging_mixin.py:104} INFO - [2021-08-28 00:34:00,538] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:00,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:00,637] {logging_mixin.py:104} INFO - [2021-08-28 00:34:00,637] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:34:00,658] {logging_mixin.py:104} INFO - [2021-08-28 00:34:00,658] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:34:00.658660+00:00
[2021-08-28 00:34:00,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-28 00:34:30,802] {scheduler_job.py:182} INFO - Started process (PID=4113) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:30,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:34:30,803] {logging_mixin.py:104} INFO - [2021-08-28 00:34:30,803] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:30,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:34:30,905] {logging_mixin.py:104} INFO - [2021-08-28 00:34:30,905] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:34:30,919] {logging_mixin.py:104} INFO - [2021-08-28 00:34:30,919] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:34:30.918892+00:00
[2021-08-28 00:34:30,926] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-28 00:35:01,031] {scheduler_job.py:182} INFO - Started process (PID=4116) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:01,032] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:35:01,032] {logging_mixin.py:104} INFO - [2021-08-28 00:35:01,032] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:01,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:01,130] {logging_mixin.py:104} INFO - [2021-08-28 00:35:01,130] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:35:01,141] {logging_mixin.py:104} INFO - [2021-08-28 00:35:01,141] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:35:01.141470+00:00
[2021-08-28 00:35:01,147] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:35:31,260] {scheduler_job.py:182} INFO - Started process (PID=4119) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:31,261] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:35:31,261] {logging_mixin.py:104} INFO - [2021-08-28 00:35:31,261] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:31,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:35:31,412] {logging_mixin.py:104} INFO - [2021-08-28 00:35:31,412] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:35:31,425] {logging_mixin.py:104} INFO - [2021-08-28 00:35:31,425] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:35:31.425549+00:00
[2021-08-28 00:35:31,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-08-28 00:36:01,539] {scheduler_job.py:182} INFO - Started process (PID=4122) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:01,539] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:36:01,540] {logging_mixin.py:104} INFO - [2021-08-28 00:36:01,540] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:01,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:01,641] {logging_mixin.py:104} INFO - [2021-08-28 00:36:01,641] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:36:01,654] {logging_mixin.py:104} INFO - [2021-08-28 00:36:01,653] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:36:01.653853+00:00
[2021-08-28 00:36:01,662] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-08-28 00:36:31,774] {scheduler_job.py:182} INFO - Started process (PID=4125) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:31,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:36:31,775] {logging_mixin.py:104} INFO - [2021-08-28 00:36:31,775] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:31,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:36:31,871] {logging_mixin.py:104} INFO - [2021-08-28 00:36:31,871] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:36:31,883] {logging_mixin.py:104} INFO - [2021-08-28 00:36:31,883] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:36:31.882886+00:00
[2021-08-28 00:36:31,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:37:01,996] {scheduler_job.py:182} INFO - Started process (PID=4128) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:01,997] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:37:01,998] {logging_mixin.py:104} INFO - [2021-08-28 00:37:01,998] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:02,084] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:02,092] {logging_mixin.py:104} INFO - [2021-08-28 00:37:02,092] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:37:02,102] {logging_mixin.py:104} INFO - [2021-08-28 00:37:02,102] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:37:02.102752+00:00
[2021-08-28 00:37:02,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:37:32,223] {scheduler_job.py:182} INFO - Started process (PID=4131) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:32,224] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:37:32,224] {logging_mixin.py:104} INFO - [2021-08-28 00:37:32,224] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:32,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:37:32,319] {logging_mixin.py:104} INFO - [2021-08-28 00:37:32,319] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:37:32,329] {logging_mixin.py:104} INFO - [2021-08-28 00:37:32,329] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:37:32.329369+00:00
[2021-08-28 00:37:32,335] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:38:02,437] {scheduler_job.py:182} INFO - Started process (PID=4134) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:02,438] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:38:02,438] {logging_mixin.py:104} INFO - [2021-08-28 00:38:02,438] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:02,524] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:02,531] {logging_mixin.py:104} INFO - [2021-08-28 00:38:02,531] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:38:02,541] {logging_mixin.py:104} INFO - [2021-08-28 00:38:02,541] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:38:02.541259+00:00
[2021-08-28 00:38:02,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:38:32,664] {scheduler_job.py:182} INFO - Started process (PID=4137) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:32,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:38:32,665] {logging_mixin.py:104} INFO - [2021-08-28 00:38:32,665] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:32,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:38:32,760] {logging_mixin.py:104} INFO - [2021-08-28 00:38:32,760] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:38:32,770] {logging_mixin.py:104} INFO - [2021-08-28 00:38:32,770] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:38:32.770362+00:00
[2021-08-28 00:38:32,777] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:39:02,893] {scheduler_job.py:182} INFO - Started process (PID=4140) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:02,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:39:02,894] {logging_mixin.py:104} INFO - [2021-08-28 00:39:02,894] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:02,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:02,987] {logging_mixin.py:104} INFO - [2021-08-28 00:39:02,987] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:39:02,997] {logging_mixin.py:104} INFO - [2021-08-28 00:39:02,997] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:39:02.996956+00:00
[2021-08-28 00:39:03,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:39:33,159] {scheduler_job.py:182} INFO - Started process (PID=4143) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:33,160] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:39:33,160] {logging_mixin.py:104} INFO - [2021-08-28 00:39:33,160] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:33,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:39:33,255] {logging_mixin.py:104} INFO - [2021-08-28 00:39:33,255] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:39:33,265] {logging_mixin.py:104} INFO - [2021-08-28 00:39:33,265] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:39:33.265253+00:00
[2021-08-28 00:39:33,271] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:40:03,392] {scheduler_job.py:182} INFO - Started process (PID=4146) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:03,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:40:03,393] {logging_mixin.py:104} INFO - [2021-08-28 00:40:03,393] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:03,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:03,494] {logging_mixin.py:104} INFO - [2021-08-28 00:40:03,494] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:40:03,506] {logging_mixin.py:104} INFO - [2021-08-28 00:40:03,505] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:40:03.505791+00:00
[2021-08-28 00:40:03,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-28 00:40:33,625] {scheduler_job.py:182} INFO - Started process (PID=4149) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:33,626] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:40:33,626] {logging_mixin.py:104} INFO - [2021-08-28 00:40:33,626] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:33,714] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:40:33,723] {logging_mixin.py:104} INFO - [2021-08-28 00:40:33,723] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:40:33,735] {logging_mixin.py:104} INFO - [2021-08-28 00:40:33,735] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:40:33.734934+00:00
[2021-08-28 00:40:33,740] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 00:41:03,849] {scheduler_job.py:182} INFO - Started process (PID=4152) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:03,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:41:03,850] {logging_mixin.py:104} INFO - [2021-08-28 00:41:03,850] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:03,935] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:03,943] {logging_mixin.py:104} INFO - [2021-08-28 00:41:03,943] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:41:03,953] {logging_mixin.py:104} INFO - [2021-08-28 00:41:03,952] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:41:03.952827+00:00
[2021-08-28 00:41:03,959] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:41:34,076] {scheduler_job.py:182} INFO - Started process (PID=4155) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:34,077] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:41:34,077] {logging_mixin.py:104} INFO - [2021-08-28 00:41:34,077] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:34,165] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:41:34,172] {logging_mixin.py:104} INFO - [2021-08-28 00:41:34,172] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:41:34,181] {logging_mixin.py:104} INFO - [2021-08-28 00:41:34,181] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:41:34.181761+00:00
[2021-08-28 00:41:34,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:42:04,294] {scheduler_job.py:182} INFO - Started process (PID=4158) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:04,295] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:42:04,295] {logging_mixin.py:104} INFO - [2021-08-28 00:42:04,295] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:04,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:04,391] {logging_mixin.py:104} INFO - [2021-08-28 00:42:04,391] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:42:04,401] {logging_mixin.py:104} INFO - [2021-08-28 00:42:04,401] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:42:04.400925+00:00
[2021-08-28 00:42:04,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:42:34,534] {scheduler_job.py:182} INFO - Started process (PID=4161) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:34,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:42:34,535] {logging_mixin.py:104} INFO - [2021-08-28 00:42:34,535] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:34,624] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:42:34,631] {logging_mixin.py:104} INFO - [2021-08-28 00:42:34,631] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:42:34,642] {logging_mixin.py:104} INFO - [2021-08-28 00:42:34,641] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:42:34.641838+00:00
[2021-08-28 00:42:34,648] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:43:04,773] {scheduler_job.py:182} INFO - Started process (PID=4164) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:04,774] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:43:04,774] {logging_mixin.py:104} INFO - [2021-08-28 00:43:04,774] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:04,867] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:04,874] {logging_mixin.py:104} INFO - [2021-08-28 00:43:04,874] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:43:04,883] {logging_mixin.py:104} INFO - [2021-08-28 00:43:04,883] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:43:04.883747+00:00
[2021-08-28 00:43:04,890] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 00:43:34,992] {scheduler_job.py:182} INFO - Started process (PID=4167) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:34,993] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:43:34,994] {logging_mixin.py:104} INFO - [2021-08-28 00:43:34,994] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:35,088] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:43:35,099] {logging_mixin.py:104} INFO - [2021-08-28 00:43:35,099] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:43:35,114] {logging_mixin.py:104} INFO - [2021-08-28 00:43:35,114] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:43:35.114199+00:00
[2021-08-28 00:43:35,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-28 00:44:05,251] {scheduler_job.py:182} INFO - Started process (PID=4170) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:05,252] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:44:05,252] {logging_mixin.py:104} INFO - [2021-08-28 00:44:05,252] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:05,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:05,360] {logging_mixin.py:104} INFO - [2021-08-28 00:44:05,360] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:44:05,376] {logging_mixin.py:104} INFO - [2021-08-28 00:44:05,376] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:44:05.376181+00:00
[2021-08-28 00:44:05,384] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-08-28 00:44:35,543] {scheduler_job.py:182} INFO - Started process (PID=4173) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:35,544] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:44:35,544] {logging_mixin.py:104} INFO - [2021-08-28 00:44:35,544] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:35,651] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:44:35,662] {logging_mixin.py:104} INFO - [2021-08-28 00:44:35,661] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:44:35,677] {logging_mixin.py:104} INFO - [2021-08-28 00:44:35,676] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:44:35.676855+00:00
[2021-08-28 00:44:35,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-08-28 00:45:05,823] {scheduler_job.py:182} INFO - Started process (PID=4176) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:05,824] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:45:05,824] {logging_mixin.py:104} INFO - [2021-08-28 00:45:05,824] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:05,923] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:05,935] {logging_mixin.py:104} INFO - [2021-08-28 00:45:05,935] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:45:05,949] {logging_mixin.py:104} INFO - [2021-08-28 00:45:05,948] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:45:05.948844+00:00
[2021-08-28 00:45:05,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-08-28 00:45:36,063] {scheduler_job.py:182} INFO - Started process (PID=4179) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:36,063] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:45:36,064] {logging_mixin.py:104} INFO - [2021-08-28 00:45:36,064] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:36,188] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:45:36,202] {logging_mixin.py:104} INFO - [2021-08-28 00:45:36,202] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:45:36,214] {logging_mixin.py:104} INFO - [2021-08-28 00:45:36,214] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:45:36.213933+00:00
[2021-08-28 00:45:36,223] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-08-28 00:46:06,335] {scheduler_job.py:182} INFO - Started process (PID=4182) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:06,335] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:46:06,336] {logging_mixin.py:104} INFO - [2021-08-28 00:46:06,336] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:06,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:06,432] {logging_mixin.py:104} INFO - [2021-08-28 00:46:06,432] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:46:06,446] {logging_mixin.py:104} INFO - [2021-08-28 00:46:06,446] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:46:06.446478+00:00
[2021-08-28 00:46:06,453] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 00:46:36,560] {scheduler_job.py:182} INFO - Started process (PID=4185) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:36,561] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:46:36,561] {logging_mixin.py:104} INFO - [2021-08-28 00:46:36,561] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:36,648] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:46:36,655] {logging_mixin.py:104} INFO - [2021-08-28 00:46:36,655] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:46:36,665] {logging_mixin.py:104} INFO - [2021-08-28 00:46:36,665] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:46:36.664908+00:00
[2021-08-28 00:46:36,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:47:06,787] {scheduler_job.py:182} INFO - Started process (PID=4188) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:06,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:47:06,789] {logging_mixin.py:104} INFO - [2021-08-28 00:47:06,789] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:06,877] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:06,884] {logging_mixin.py:104} INFO - [2021-08-28 00:47:06,884] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:47:06,894] {logging_mixin.py:104} INFO - [2021-08-28 00:47:06,894] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:47:06.894550+00:00
[2021-08-28 00:47:06,901] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 00:47:37,008] {scheduler_job.py:182} INFO - Started process (PID=4191) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:37,009] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:47:37,009] {logging_mixin.py:104} INFO - [2021-08-28 00:47:37,009] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:37,096] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:47:37,104] {logging_mixin.py:104} INFO - [2021-08-28 00:47:37,104] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:47:37,113] {logging_mixin.py:104} INFO - [2021-08-28 00:47:37,113] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:47:37.113697+00:00
[2021-08-28 00:47:37,120] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:48:07,240] {scheduler_job.py:182} INFO - Started process (PID=4194) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:07,240] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:48:07,241] {logging_mixin.py:104} INFO - [2021-08-28 00:48:07,241] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:07,327] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:07,335] {logging_mixin.py:104} INFO - [2021-08-28 00:48:07,334] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:48:07,344] {logging_mixin.py:104} INFO - [2021-08-28 00:48:07,344] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:48:07.344485+00:00
[2021-08-28 00:48:07,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:48:37,446] {scheduler_job.py:182} INFO - Started process (PID=4197) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:37,447] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:48:37,447] {logging_mixin.py:104} INFO - [2021-08-28 00:48:37,447] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:37,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:48:37,539] {logging_mixin.py:104} INFO - [2021-08-28 00:48:37,539] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:48:37,549] {logging_mixin.py:104} INFO - [2021-08-28 00:48:37,549] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:48:37.549005+00:00
[2021-08-28 00:48:37,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:49:07,670] {scheduler_job.py:182} INFO - Started process (PID=4200) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:07,671] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:49:07,671] {logging_mixin.py:104} INFO - [2021-08-28 00:49:07,671] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:07,758] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:07,766] {logging_mixin.py:104} INFO - [2021-08-28 00:49:07,766] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:49:07,776] {logging_mixin.py:104} INFO - [2021-08-28 00:49:07,776] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:49:07.776249+00:00
[2021-08-28 00:49:07,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:49:37,900] {scheduler_job.py:182} INFO - Started process (PID=4203) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:37,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:49:37,901] {logging_mixin.py:104} INFO - [2021-08-28 00:49:37,901] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:37,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:49:37,997] {logging_mixin.py:104} INFO - [2021-08-28 00:49:37,997] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:49:38,006] {logging_mixin.py:104} INFO - [2021-08-28 00:49:38,006] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:49:38.006709+00:00
[2021-08-28 00:49:38,013] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:50:08,130] {scheduler_job.py:182} INFO - Started process (PID=4206) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:08,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:50:08,131] {logging_mixin.py:104} INFO - [2021-08-28 00:50:08,131] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:08,216] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:08,224] {logging_mixin.py:104} INFO - [2021-08-28 00:50:08,223] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:50:08,233] {logging_mixin.py:104} INFO - [2021-08-28 00:50:08,233] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:50:08.233707+00:00
[2021-08-28 00:50:08,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:50:38,354] {scheduler_job.py:182} INFO - Started process (PID=4209) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:38,355] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:50:38,355] {logging_mixin.py:104} INFO - [2021-08-28 00:50:38,355] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:38,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:50:38,448] {logging_mixin.py:104} INFO - [2021-08-28 00:50:38,448] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:50:38,457] {logging_mixin.py:104} INFO - [2021-08-28 00:50:38,457] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:50:38.457599+00:00
[2021-08-28 00:50:38,464] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:51:08,580] {scheduler_job.py:182} INFO - Started process (PID=4212) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:08,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:51:08,581] {logging_mixin.py:104} INFO - [2021-08-28 00:51:08,581] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:08,667] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:08,674] {logging_mixin.py:104} INFO - [2021-08-28 00:51:08,674] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:51:08,684] {logging_mixin.py:104} INFO - [2021-08-28 00:51:08,684] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:51:08.683980+00:00
[2021-08-28 00:51:08,690] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:51:38,802] {scheduler_job.py:182} INFO - Started process (PID=4215) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:38,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:51:38,803] {logging_mixin.py:104} INFO - [2021-08-28 00:51:38,803] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:38,895] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:51:38,903] {logging_mixin.py:104} INFO - [2021-08-28 00:51:38,903] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:51:38,922] {logging_mixin.py:104} INFO - [2021-08-28 00:51:38,922] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:51:38.922665+00:00
[2021-08-28 00:51:38,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-08-28 00:52:09,041] {scheduler_job.py:182} INFO - Started process (PID=4218) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:09,042] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:52:09,043] {logging_mixin.py:104} INFO - [2021-08-28 00:52:09,043] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:09,127] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:09,134] {logging_mixin.py:104} INFO - [2021-08-28 00:52:09,134] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:52:09,144] {logging_mixin.py:104} INFO - [2021-08-28 00:52:09,144] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:52:09.144216+00:00
[2021-08-28 00:52:09,151] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:52:39,261] {scheduler_job.py:182} INFO - Started process (PID=4221) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:39,262] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:52:39,262] {logging_mixin.py:104} INFO - [2021-08-28 00:52:39,262] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:39,349] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:52:39,358] {logging_mixin.py:104} INFO - [2021-08-28 00:52:39,358] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:52:39,370] {logging_mixin.py:104} INFO - [2021-08-28 00:52:39,370] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:52:39.370101+00:00
[2021-08-28 00:52:39,377] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 00:53:09,490] {scheduler_job.py:182} INFO - Started process (PID=4224) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:09,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:53:09,491] {logging_mixin.py:104} INFO - [2021-08-28 00:53:09,491] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:09,579] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:09,586] {logging_mixin.py:104} INFO - [2021-08-28 00:53:09,586] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:53:09,596] {logging_mixin.py:104} INFO - [2021-08-28 00:53:09,596] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:53:09.595971+00:00
[2021-08-28 00:53:09,602] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 00:53:39,715] {scheduler_job.py:182} INFO - Started process (PID=4227) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:39,716] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:53:39,716] {logging_mixin.py:104} INFO - [2021-08-28 00:53:39,716] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:39,808] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:53:39,816] {logging_mixin.py:104} INFO - [2021-08-28 00:53:39,816] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:53:39,828] {logging_mixin.py:104} INFO - [2021-08-28 00:53:39,828] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:53:39.828361+00:00
[2021-08-28 00:53:39,835] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 00:54:09,944] {scheduler_job.py:182} INFO - Started process (PID=4230) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:09,945] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:54:09,945] {logging_mixin.py:104} INFO - [2021-08-28 00:54:09,945] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:10,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:10,038] {logging_mixin.py:104} INFO - [2021-08-28 00:54:10,038] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:54:10,048] {logging_mixin.py:104} INFO - [2021-08-28 00:54:10,048] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:54:10.047909+00:00
[2021-08-28 00:54:10,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:54:40,187] {scheduler_job.py:182} INFO - Started process (PID=4233) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:40,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:54:40,188] {logging_mixin.py:104} INFO - [2021-08-28 00:54:40,188] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:40,272] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:54:40,280] {logging_mixin.py:104} INFO - [2021-08-28 00:54:40,279] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:54:40,289] {logging_mixin.py:104} INFO - [2021-08-28 00:54:40,289] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:54:40.289583+00:00
[2021-08-28 00:54:40,296] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:55:10,394] {scheduler_job.py:182} INFO - Started process (PID=4236) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:10,395] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:55:10,395] {logging_mixin.py:104} INFO - [2021-08-28 00:55:10,395] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:10,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:10,489] {logging_mixin.py:104} INFO - [2021-08-28 00:55:10,489] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:55:10,499] {logging_mixin.py:104} INFO - [2021-08-28 00:55:10,498] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:55:10.498821+00:00
[2021-08-28 00:55:10,505] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:55:40,614] {scheduler_job.py:182} INFO - Started process (PID=4239) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:40,614] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:55:40,615] {logging_mixin.py:104} INFO - [2021-08-28 00:55:40,615] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:40,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:55:40,708] {logging_mixin.py:104} INFO - [2021-08-28 00:55:40,708] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:55:40,718] {logging_mixin.py:104} INFO - [2021-08-28 00:55:40,718] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:55:40.717979+00:00
[2021-08-28 00:55:40,724] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 00:56:10,836] {scheduler_job.py:182} INFO - Started process (PID=4242) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:10,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:56:10,837] {logging_mixin.py:104} INFO - [2021-08-28 00:56:10,837] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:10,932] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:10,941] {logging_mixin.py:104} INFO - [2021-08-28 00:56:10,941] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:56:10,952] {logging_mixin.py:104} INFO - [2021-08-28 00:56:10,952] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:56:10.952518+00:00
[2021-08-28 00:56:10,960] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-08-28 00:56:41,071] {scheduler_job.py:182} INFO - Started process (PID=4245) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:41,071] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:56:41,072] {logging_mixin.py:104} INFO - [2021-08-28 00:56:41,072] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:41,157] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:56:41,165] {logging_mixin.py:104} INFO - [2021-08-28 00:56:41,165] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:56:41,174] {logging_mixin.py:104} INFO - [2021-08-28 00:56:41,174] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:56:41.174798+00:00
[2021-08-28 00:56:41,181] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 00:57:11,295] {scheduler_job.py:182} INFO - Started process (PID=4248) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:11,296] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:57:11,296] {logging_mixin.py:104} INFO - [2021-08-28 00:57:11,296] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:11,383] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:11,392] {logging_mixin.py:104} INFO - [2021-08-28 00:57:11,392] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:57:11,403] {logging_mixin.py:104} INFO - [2021-08-28 00:57:11,403] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:57:11.403447+00:00
[2021-08-28 00:57:11,410] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 00:57:41,525] {scheduler_job.py:182} INFO - Started process (PID=4251) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:41,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:57:41,526] {logging_mixin.py:104} INFO - [2021-08-28 00:57:41,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:41,616] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:57:41,624] {logging_mixin.py:104} INFO - [2021-08-28 00:57:41,624] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:57:41,634] {logging_mixin.py:104} INFO - [2021-08-28 00:57:41,634] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:57:41.633934+00:00
[2021-08-28 00:57:41,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 00:58:11,770] {scheduler_job.py:182} INFO - Started process (PID=4254) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:11,771] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:58:11,771] {logging_mixin.py:104} INFO - [2021-08-28 00:58:11,771] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:11,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:11,869] {logging_mixin.py:104} INFO - [2021-08-28 00:58:11,869] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:58:11,879] {logging_mixin.py:104} INFO - [2021-08-28 00:58:11,878] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:58:11.878826+00:00
[2021-08-28 00:58:11,885] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 00:58:41,981] {scheduler_job.py:182} INFO - Started process (PID=4257) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:41,982] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:58:41,982] {logging_mixin.py:104} INFO - [2021-08-28 00:58:41,982] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:42,068] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:58:42,076] {logging_mixin.py:104} INFO - [2021-08-28 00:58:42,076] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:58:42,086] {logging_mixin.py:104} INFO - [2021-08-28 00:58:42,086] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:58:42.086659+00:00
[2021-08-28 00:58:42,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 00:59:12,205] {scheduler_job.py:182} INFO - Started process (PID=4260) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:12,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:59:12,206] {logging_mixin.py:104} INFO - [2021-08-28 00:59:12,206] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:12,292] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:12,299] {logging_mixin.py:104} INFO - [2021-08-28 00:59:12,299] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:59:12,309] {logging_mixin.py:104} INFO - [2021-08-28 00:59:12,309] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:59:12.309023+00:00
[2021-08-28 00:59:12,315] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 00:59:42,431] {scheduler_job.py:182} INFO - Started process (PID=4263) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:42,431] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 00:59:42,432] {logging_mixin.py:104} INFO - [2021-08-28 00:59:42,432] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:42,517] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 00:59:42,524] {logging_mixin.py:104} INFO - [2021-08-28 00:59:42,524] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 00:59:42,533] {logging_mixin.py:104} INFO - [2021-08-28 00:59:42,533] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 00:59:42.533395+00:00
[2021-08-28 00:59:42,539] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:00:12,648] {scheduler_job.py:182} INFO - Started process (PID=4266) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:12,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:00:12,649] {logging_mixin.py:104} INFO - [2021-08-28 01:00:12,648] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:12,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:12,742] {logging_mixin.py:104} INFO - [2021-08-28 01:00:12,742] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:00:12,751] {logging_mixin.py:104} INFO - [2021-08-28 01:00:12,751] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:00:12.751561+00:00
[2021-08-28 01:00:12,758] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:00:42,875] {scheduler_job.py:182} INFO - Started process (PID=4269) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:42,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:00:42,876] {logging_mixin.py:104} INFO - [2021-08-28 01:00:42,876] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:42,961] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:00:42,970] {logging_mixin.py:104} INFO - [2021-08-28 01:00:42,970] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:00:42,980] {logging_mixin.py:104} INFO - [2021-08-28 01:00:42,980] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:00:42.980056+00:00
[2021-08-28 01:00:42,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:01:13,099] {scheduler_job.py:182} INFO - Started process (PID=4272) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:13,100] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:01:13,100] {logging_mixin.py:104} INFO - [2021-08-28 01:01:13,100] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:13,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:13,192] {logging_mixin.py:104} INFO - [2021-08-28 01:01:13,192] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:01:13,202] {logging_mixin.py:104} INFO - [2021-08-28 01:01:13,202] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:01:13.202356+00:00
[2021-08-28 01:01:13,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:01:43,310] {scheduler_job.py:182} INFO - Started process (PID=4275) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:43,310] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:01:43,311] {logging_mixin.py:104} INFO - [2021-08-28 01:01:43,310] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:43,398] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:01:43,405] {logging_mixin.py:104} INFO - [2021-08-28 01:01:43,405] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:01:43,415] {logging_mixin.py:104} INFO - [2021-08-28 01:01:43,415] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:01:43.415092+00:00
[2021-08-28 01:01:43,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:02:13,538] {scheduler_job.py:182} INFO - Started process (PID=4278) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:13,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:02:13,539] {logging_mixin.py:104} INFO - [2021-08-28 01:02:13,539] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:13,625] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:13,633] {logging_mixin.py:104} INFO - [2021-08-28 01:02:13,632] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:02:13,643] {logging_mixin.py:104} INFO - [2021-08-28 01:02:13,643] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:02:13.643343+00:00
[2021-08-28 01:02:13,649] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:02:43,757] {scheduler_job.py:182} INFO - Started process (PID=4281) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:43,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:02:43,758] {logging_mixin.py:104} INFO - [2021-08-28 01:02:43,758] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:43,846] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:02:43,853] {logging_mixin.py:104} INFO - [2021-08-28 01:02:43,853] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:02:43,863] {logging_mixin.py:104} INFO - [2021-08-28 01:02:43,863] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:02:43.863618+00:00
[2021-08-28 01:02:43,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:03:13,978] {scheduler_job.py:182} INFO - Started process (PID=4284) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:13,978] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:03:13,979] {logging_mixin.py:104} INFO - [2021-08-28 01:03:13,979] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:14,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:14,073] {logging_mixin.py:104} INFO - [2021-08-28 01:03:14,073] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:03:14,083] {logging_mixin.py:104} INFO - [2021-08-28 01:03:14,083] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:03:14.083705+00:00
[2021-08-28 01:03:14,091] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:03:44,209] {scheduler_job.py:182} INFO - Started process (PID=4287) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:44,210] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:03:44,210] {logging_mixin.py:104} INFO - [2021-08-28 01:03:44,210] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:44,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:03:44,303] {logging_mixin.py:104} INFO - [2021-08-28 01:03:44,303] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:03:44,315] {logging_mixin.py:104} INFO - [2021-08-28 01:03:44,315] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:03:44.315044+00:00
[2021-08-28 01:03:44,322] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:04:14,431] {scheduler_job.py:182} INFO - Started process (PID=4290) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:14,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:04:14,432] {logging_mixin.py:104} INFO - [2021-08-28 01:04:14,432] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:14,519] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:14,526] {logging_mixin.py:104} INFO - [2021-08-28 01:04:14,526] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:04:14,536] {logging_mixin.py:104} INFO - [2021-08-28 01:04:14,536] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:04:14.536628+00:00
[2021-08-28 01:04:14,543] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:04:44,681] {scheduler_job.py:182} INFO - Started process (PID=4293) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:44,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:04:44,682] {logging_mixin.py:104} INFO - [2021-08-28 01:04:44,682] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:44,767] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:04:44,774] {logging_mixin.py:104} INFO - [2021-08-28 01:04:44,774] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:04:44,784] {logging_mixin.py:104} INFO - [2021-08-28 01:04:44,784] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:04:44.784632+00:00
[2021-08-28 01:04:44,791] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:05:14,903] {scheduler_job.py:182} INFO - Started process (PID=4296) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:14,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:05:14,904] {logging_mixin.py:104} INFO - [2021-08-28 01:05:14,904] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:14,987] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:14,994] {logging_mixin.py:104} INFO - [2021-08-28 01:05:14,994] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:05:15,005] {logging_mixin.py:104} INFO - [2021-08-28 01:05:15,004] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:05:15.004856+00:00
[2021-08-28 01:05:15,011] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:05:45,113] {scheduler_job.py:182} INFO - Started process (PID=4299) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:45,114] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:05:45,114] {logging_mixin.py:104} INFO - [2021-08-28 01:05:45,114] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:45,211] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:05:45,220] {logging_mixin.py:104} INFO - [2021-08-28 01:05:45,219] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:05:45,229] {logging_mixin.py:104} INFO - [2021-08-28 01:05:45,229] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:05:45.229300+00:00
[2021-08-28 01:05:45,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-08-28 01:06:15,353] {scheduler_job.py:182} INFO - Started process (PID=4302) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:15,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:06:15,354] {logging_mixin.py:104} INFO - [2021-08-28 01:06:15,354] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:15,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:15,449] {logging_mixin.py:104} INFO - [2021-08-28 01:06:15,449] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:06:15,460] {logging_mixin.py:104} INFO - [2021-08-28 01:06:15,460] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:06:15.459919+00:00
[2021-08-28 01:06:15,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:06:45,574] {scheduler_job.py:182} INFO - Started process (PID=4305) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:45,574] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:06:45,575] {logging_mixin.py:104} INFO - [2021-08-28 01:06:45,575] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:45,658] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:06:45,666] {logging_mixin.py:104} INFO - [2021-08-28 01:06:45,666] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:06:45,676] {logging_mixin.py:104} INFO - [2021-08-28 01:06:45,676] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:06:45.676106+00:00
[2021-08-28 01:06:45,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:07:15,795] {scheduler_job.py:182} INFO - Started process (PID=4308) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:15,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:07:15,796] {logging_mixin.py:104} INFO - [2021-08-28 01:07:15,796] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:15,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:15,894] {logging_mixin.py:104} INFO - [2021-08-28 01:07:15,894] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:07:15,904] {logging_mixin.py:104} INFO - [2021-08-28 01:07:15,904] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:07:15.904552+00:00
[2021-08-28 01:07:15,911] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:07:46,024] {scheduler_job.py:182} INFO - Started process (PID=4311) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:46,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:07:46,025] {logging_mixin.py:104} INFO - [2021-08-28 01:07:46,025] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:46,110] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:07:46,118] {logging_mixin.py:104} INFO - [2021-08-28 01:07:46,118] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:07:46,127] {logging_mixin.py:104} INFO - [2021-08-28 01:07:46,127] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:07:46.127816+00:00
[2021-08-28 01:07:46,133] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:08:16,253] {scheduler_job.py:182} INFO - Started process (PID=4314) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:16,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:08:16,254] {logging_mixin.py:104} INFO - [2021-08-28 01:08:16,254] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:16,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:16,351] {logging_mixin.py:104} INFO - [2021-08-28 01:08:16,351] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:08:16,364] {logging_mixin.py:104} INFO - [2021-08-28 01:08:16,364] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:08:16.364000+00:00
[2021-08-28 01:08:16,371] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 01:08:46,470] {scheduler_job.py:182} INFO - Started process (PID=4317) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:46,471] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:08:46,471] {logging_mixin.py:104} INFO - [2021-08-28 01:08:46,471] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:46,557] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:08:46,564] {logging_mixin.py:104} INFO - [2021-08-28 01:08:46,564] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:08:46,574] {logging_mixin.py:104} INFO - [2021-08-28 01:08:46,574] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:08:46.574501+00:00
[2021-08-28 01:08:46,581] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:09:16,689] {scheduler_job.py:182} INFO - Started process (PID=4320) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:16,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:09:16,690] {logging_mixin.py:104} INFO - [2021-08-28 01:09:16,690] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:16,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:16,783] {logging_mixin.py:104} INFO - [2021-08-28 01:09:16,783] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:09:16,792] {logging_mixin.py:104} INFO - [2021-08-28 01:09:16,792] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:09:16.792638+00:00
[2021-08-28 01:09:16,798] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:09:46,950] {scheduler_job.py:182} INFO - Started process (PID=4323) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:46,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:09:46,951] {logging_mixin.py:104} INFO - [2021-08-28 01:09:46,951] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:47,053] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:09:47,062] {logging_mixin.py:104} INFO - [2021-08-28 01:09:47,061] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:09:47,072] {logging_mixin.py:104} INFO - [2021-08-28 01:09:47,072] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:09:47.072733+00:00
[2021-08-28 01:09:47,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-08-28 01:10:17,181] {scheduler_job.py:182} INFO - Started process (PID=4326) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:17,182] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:10:17,182] {logging_mixin.py:104} INFO - [2021-08-28 01:10:17,182] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:17,267] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:17,274] {logging_mixin.py:104} INFO - [2021-08-28 01:10:17,274] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:10:17,283] {logging_mixin.py:104} INFO - [2021-08-28 01:10:17,283] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:10:17.283769+00:00
[2021-08-28 01:10:17,289] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:10:47,405] {scheduler_job.py:182} INFO - Started process (PID=4329) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:47,406] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:10:47,406] {logging_mixin.py:104} INFO - [2021-08-28 01:10:47,406] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:47,492] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:10:47,499] {logging_mixin.py:104} INFO - [2021-08-28 01:10:47,499] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:10:47,509] {logging_mixin.py:104} INFO - [2021-08-28 01:10:47,508] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:10:47.508826+00:00
[2021-08-28 01:10:47,515] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:11:17,628] {scheduler_job.py:182} INFO - Started process (PID=4332) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:17,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:11:17,629] {logging_mixin.py:104} INFO - [2021-08-28 01:11:17,629] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:17,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:17,722] {logging_mixin.py:104} INFO - [2021-08-28 01:11:17,722] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:11:17,732] {logging_mixin.py:104} INFO - [2021-08-28 01:11:17,731] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:11:17.731825+00:00
[2021-08-28 01:11:17,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:11:47,845] {scheduler_job.py:182} INFO - Started process (PID=4335) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:47,845] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:11:47,846] {logging_mixin.py:104} INFO - [2021-08-28 01:11:47,846] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:47,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:11:47,955] {logging_mixin.py:104} INFO - [2021-08-28 01:11:47,955] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:11:47,966] {logging_mixin.py:104} INFO - [2021-08-28 01:11:47,966] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:11:47.966743+00:00
[2021-08-28 01:11:47,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-28 01:12:18,077] {scheduler_job.py:182} INFO - Started process (PID=4338) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:18,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:12:18,078] {logging_mixin.py:104} INFO - [2021-08-28 01:12:18,078] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:18,183] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:18,193] {logging_mixin.py:104} INFO - [2021-08-28 01:12:18,193] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:12:18,203] {logging_mixin.py:104} INFO - [2021-08-28 01:12:18,203] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:12:18.203550+00:00
[2021-08-28 01:12:18,210] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-08-28 01:12:48,317] {scheduler_job.py:182} INFO - Started process (PID=4341) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:48,318] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:12:48,318] {logging_mixin.py:104} INFO - [2021-08-28 01:12:48,318] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:48,407] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:12:48,416] {logging_mixin.py:104} INFO - [2021-08-28 01:12:48,416] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:12:48,427] {logging_mixin.py:104} INFO - [2021-08-28 01:12:48,427] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:12:48.427355+00:00
[2021-08-28 01:12:48,433] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:13:18,542] {scheduler_job.py:182} INFO - Started process (PID=4344) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:18,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:13:18,543] {logging_mixin.py:104} INFO - [2021-08-28 01:13:18,543] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:18,636] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:18,644] {logging_mixin.py:104} INFO - [2021-08-28 01:13:18,644] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:13:18,654] {logging_mixin.py:104} INFO - [2021-08-28 01:13:18,654] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:13:18.654575+00:00
[2021-08-28 01:13:18,661] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 01:13:48,772] {scheduler_job.py:182} INFO - Started process (PID=4347) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:48,772] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:13:48,773] {logging_mixin.py:104} INFO - [2021-08-28 01:13:48,773] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:48,864] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:13:48,872] {logging_mixin.py:104} INFO - [2021-08-28 01:13:48,872] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:13:48,882] {logging_mixin.py:104} INFO - [2021-08-28 01:13:48,882] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:13:48.882272+00:00
[2021-08-28 01:13:48,889] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 01:14:19,000] {scheduler_job.py:182} INFO - Started process (PID=4350) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:19,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:14:19,002] {logging_mixin.py:104} INFO - [2021-08-28 01:14:19,001] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:19,093] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:19,101] {logging_mixin.py:104} INFO - [2021-08-28 01:14:19,100] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:14:19,111] {logging_mixin.py:104} INFO - [2021-08-28 01:14:19,111] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:14:19.111668+00:00
[2021-08-28 01:14:19,118] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 01:14:49,219] {scheduler_job.py:182} INFO - Started process (PID=4353) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:49,220] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:14:49,220] {logging_mixin.py:104} INFO - [2021-08-28 01:14:49,220] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:49,311] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:14:49,319] {logging_mixin.py:104} INFO - [2021-08-28 01:14:49,319] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:14:49,330] {logging_mixin.py:104} INFO - [2021-08-28 01:14:49,330] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:14:49.330040+00:00
[2021-08-28 01:14:49,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 01:15:19,435] {scheduler_job.py:182} INFO - Started process (PID=4356) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:19,436] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:15:19,436] {logging_mixin.py:104} INFO - [2021-08-28 01:15:19,436] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:19,525] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:19,532] {logging_mixin.py:104} INFO - [2021-08-28 01:15:19,532] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:15:19,543] {logging_mixin.py:104} INFO - [2021-08-28 01:15:19,543] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:15:19.543013+00:00
[2021-08-28 01:15:19,550] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:15:49,656] {scheduler_job.py:182} INFO - Started process (PID=4359) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:49,657] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:15:49,658] {logging_mixin.py:104} INFO - [2021-08-28 01:15:49,658] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:49,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:15:49,756] {logging_mixin.py:104} INFO - [2021-08-28 01:15:49,756] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:15:49,767] {logging_mixin.py:104} INFO - [2021-08-28 01:15:49,767] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:15:49.767182+00:00
[2021-08-28 01:15:49,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 01:16:19,883] {scheduler_job.py:182} INFO - Started process (PID=4362) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:19,884] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:16:19,885] {logging_mixin.py:104} INFO - [2021-08-28 01:16:19,884] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:19,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:19,997] {logging_mixin.py:104} INFO - [2021-08-28 01:16:19,997] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:16:20,007] {logging_mixin.py:104} INFO - [2021-08-28 01:16:20,007] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:16:20.007155+00:00
[2021-08-28 01:16:20,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-28 01:16:50,131] {scheduler_job.py:182} INFO - Started process (PID=4365) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:50,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:16:50,132] {logging_mixin.py:104} INFO - [2021-08-28 01:16:50,131] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:50,226] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:16:50,233] {logging_mixin.py:104} INFO - [2021-08-28 01:16:50,233] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:16:50,243] {logging_mixin.py:104} INFO - [2021-08-28 01:16:50,243] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:16:50.243464+00:00
[2021-08-28 01:16:50,250] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 01:17:20,360] {scheduler_job.py:182} INFO - Started process (PID=4368) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:20,360] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:17:20,361] {logging_mixin.py:104} INFO - [2021-08-28 01:17:20,360] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:20,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:20,454] {logging_mixin.py:104} INFO - [2021-08-28 01:17:20,454] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:17:20,465] {logging_mixin.py:104} INFO - [2021-08-28 01:17:20,464] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:17:20.464842+00:00
[2021-08-28 01:17:20,473] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:17:50,591] {scheduler_job.py:182} INFO - Started process (PID=4371) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:50,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:17:50,592] {logging_mixin.py:104} INFO - [2021-08-28 01:17:50,592] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:50,679] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:17:50,686] {logging_mixin.py:104} INFO - [2021-08-28 01:17:50,686] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:17:50,696] {logging_mixin.py:104} INFO - [2021-08-28 01:17:50,696] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:17:50.696640+00:00
[2021-08-28 01:17:50,703] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:18:20,818] {scheduler_job.py:182} INFO - Started process (PID=4374) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:20,819] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:18:20,819] {logging_mixin.py:104} INFO - [2021-08-28 01:18:20,819] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:20,905] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:20,912] {logging_mixin.py:104} INFO - [2021-08-28 01:18:20,912] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:18:20,922] {logging_mixin.py:104} INFO - [2021-08-28 01:18:20,922] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:18:20.922372+00:00
[2021-08-28 01:18:20,929] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:18:51,049] {scheduler_job.py:182} INFO - Started process (PID=4377) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:51,050] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:18:51,050] {logging_mixin.py:104} INFO - [2021-08-28 01:18:51,050] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:51,135] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:18:51,142] {logging_mixin.py:104} INFO - [2021-08-28 01:18:51,142] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:18:51,152] {logging_mixin.py:104} INFO - [2021-08-28 01:18:51,152] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:18:51.152329+00:00
[2021-08-28 01:18:51,159] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:19:21,270] {scheduler_job.py:182} INFO - Started process (PID=4380) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:21,270] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:19:21,271] {logging_mixin.py:104} INFO - [2021-08-28 01:19:21,271] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:21,356] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:21,364] {logging_mixin.py:104} INFO - [2021-08-28 01:19:21,364] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:19:21,373] {logging_mixin.py:104} INFO - [2021-08-28 01:19:21,373] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:19:21.373534+00:00
[2021-08-28 01:19:21,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:19:51,513] {scheduler_job.py:182} INFO - Started process (PID=4383) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:51,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:19:51,514] {logging_mixin.py:104} INFO - [2021-08-28 01:19:51,514] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:51,601] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:19:51,610] {logging_mixin.py:104} INFO - [2021-08-28 01:19:51,610] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:19:51,622] {logging_mixin.py:104} INFO - [2021-08-28 01:19:51,622] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:19:51.622316+00:00
[2021-08-28 01:19:51,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 01:20:21,733] {scheduler_job.py:182} INFO - Started process (PID=4386) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:21,733] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:20:21,734] {logging_mixin.py:104} INFO - [2021-08-28 01:20:21,734] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:21,827] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:21,835] {logging_mixin.py:104} INFO - [2021-08-28 01:20:21,835] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:20:21,847] {logging_mixin.py:104} INFO - [2021-08-28 01:20:21,847] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:20:21.846931+00:00
[2021-08-28 01:20:21,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-28 01:20:51,951] {scheduler_job.py:182} INFO - Started process (PID=4389) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:51,951] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:20:51,952] {logging_mixin.py:104} INFO - [2021-08-28 01:20:51,952] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:52,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:20:52,046] {logging_mixin.py:104} INFO - [2021-08-28 01:20:52,046] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:20:52,055] {logging_mixin.py:104} INFO - [2021-08-28 01:20:52,055] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:20:52.055755+00:00
[2021-08-28 01:20:52,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:21:22,177] {scheduler_job.py:182} INFO - Started process (PID=4392) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:22,178] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:21:22,178] {logging_mixin.py:104} INFO - [2021-08-28 01:21:22,178] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:22,264] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:22,272] {logging_mixin.py:104} INFO - [2021-08-28 01:21:22,272] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:21:22,281] {logging_mixin.py:104} INFO - [2021-08-28 01:21:22,281] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:21:22.281468+00:00
[2021-08-28 01:21:22,288] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:21:52,394] {scheduler_job.py:182} INFO - Started process (PID=4395) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:52,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:21:52,395] {logging_mixin.py:104} INFO - [2021-08-28 01:21:52,395] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:52,481] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:21:52,488] {logging_mixin.py:104} INFO - [2021-08-28 01:21:52,488] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:21:52,498] {logging_mixin.py:104} INFO - [2021-08-28 01:21:52,498] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:21:52.498165+00:00
[2021-08-28 01:21:52,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:22:22,610] {scheduler_job.py:182} INFO - Started process (PID=4398) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:22,611] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:22:22,611] {logging_mixin.py:104} INFO - [2021-08-28 01:22:22,611] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:22,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:22,704] {logging_mixin.py:104} INFO - [2021-08-28 01:22:22,704] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:22:22,714] {logging_mixin.py:104} INFO - [2021-08-28 01:22:22,713] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:22:22.713889+00:00
[2021-08-28 01:22:22,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:22:52,843] {scheduler_job.py:182} INFO - Started process (PID=4401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:52,844] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:22:52,844] {logging_mixin.py:104} INFO - [2021-08-28 01:22:52,844] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:52,929] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:22:52,937] {logging_mixin.py:104} INFO - [2021-08-28 01:22:52,937] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:22:52,946] {logging_mixin.py:104} INFO - [2021-08-28 01:22:52,946] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:22:52.946669+00:00
[2021-08-28 01:22:52,953] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:23:23,067] {scheduler_job.py:182} INFO - Started process (PID=4404) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:23,067] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:23:23,068] {logging_mixin.py:104} INFO - [2021-08-28 01:23:23,068] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:23,156] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:23,164] {logging_mixin.py:104} INFO - [2021-08-28 01:23:23,164] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:23:23,174] {logging_mixin.py:104} INFO - [2021-08-28 01:23:23,174] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:23:23.173964+00:00
[2021-08-28 01:23:23,182] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:23:53,308] {scheduler_job.py:182} INFO - Started process (PID=4407) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:53,309] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:23:53,309] {logging_mixin.py:104} INFO - [2021-08-28 01:23:53,309] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:53,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:23:53,402] {logging_mixin.py:104} INFO - [2021-08-28 01:23:53,402] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:23:53,411] {logging_mixin.py:104} INFO - [2021-08-28 01:23:53,411] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:23:53.411719+00:00
[2021-08-28 01:23:53,418] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:24:23,525] {scheduler_job.py:182} INFO - Started process (PID=4410) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:23,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:24:23,526] {logging_mixin.py:104} INFO - [2021-08-28 01:24:23,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:23,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:23,623] {logging_mixin.py:104} INFO - [2021-08-28 01:24:23,622] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:24:23,634] {logging_mixin.py:104} INFO - [2021-08-28 01:24:23,634] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:24:23.634253+00:00
[2021-08-28 01:24:23,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:24:53,757] {scheduler_job.py:182} INFO - Started process (PID=4413) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:53,758] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:24:53,758] {logging_mixin.py:104} INFO - [2021-08-28 01:24:53,758] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:53,843] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:24:53,850] {logging_mixin.py:104} INFO - [2021-08-28 01:24:53,850] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:24:53,860] {logging_mixin.py:104} INFO - [2021-08-28 01:24:53,860] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:24:53.860339+00:00
[2021-08-28 01:24:53,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:25:23,975] {scheduler_job.py:182} INFO - Started process (PID=4416) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:23,976] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:25:23,976] {logging_mixin.py:104} INFO - [2021-08-28 01:25:23,976] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:24,063] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:24,070] {logging_mixin.py:104} INFO - [2021-08-28 01:25:24,070] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:25:24,080] {logging_mixin.py:104} INFO - [2021-08-28 01:25:24,080] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:25:24.080309+00:00
[2021-08-28 01:25:24,087] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:25:54,199] {scheduler_job.py:182} INFO - Started process (PID=4419) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:54,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:25:54,200] {logging_mixin.py:104} INFO - [2021-08-28 01:25:54,200] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:54,286] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:25:54,294] {logging_mixin.py:104} INFO - [2021-08-28 01:25:54,294] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:25:54,303] {logging_mixin.py:104} INFO - [2021-08-28 01:25:54,303] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:25:54.303674+00:00
[2021-08-28 01:25:54,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:26:24,412] {scheduler_job.py:182} INFO - Started process (PID=4422) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:24,412] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:26:24,413] {logging_mixin.py:104} INFO - [2021-08-28 01:26:24,413] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:24,499] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:24,507] {logging_mixin.py:104} INFO - [2021-08-28 01:26:24,506] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:26:24,516] {logging_mixin.py:104} INFO - [2021-08-28 01:26:24,516] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:26:24.516389+00:00
[2021-08-28 01:26:24,523] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:26:54,635] {scheduler_job.py:182} INFO - Started process (PID=4425) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:54,636] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:26:54,636] {logging_mixin.py:104} INFO - [2021-08-28 01:26:54,636] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:54,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:26:54,728] {logging_mixin.py:104} INFO - [2021-08-28 01:26:54,728] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:26:54,738] {logging_mixin.py:104} INFO - [2021-08-28 01:26:54,738] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:26:54.738064+00:00
[2021-08-28 01:26:54,744] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:27:24,854] {scheduler_job.py:182} INFO - Started process (PID=4428) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:24,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:27:24,855] {logging_mixin.py:104} INFO - [2021-08-28 01:27:24,855] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:24,951] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:24,958] {logging_mixin.py:104} INFO - [2021-08-28 01:27:24,958] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:27:24,968] {logging_mixin.py:104} INFO - [2021-08-28 01:27:24,968] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:27:24.968258+00:00
[2021-08-28 01:27:24,974] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 01:27:55,095] {scheduler_job.py:182} INFO - Started process (PID=4431) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:55,095] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:27:55,096] {logging_mixin.py:104} INFO - [2021-08-28 01:27:55,096] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:55,181] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:27:55,188] {logging_mixin.py:104} INFO - [2021-08-28 01:27:55,188] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:27:55,197] {logging_mixin.py:104} INFO - [2021-08-28 01:27:55,197] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:27:55.197649+00:00
[2021-08-28 01:27:55,203] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:28:25,315] {scheduler_job.py:182} INFO - Started process (PID=4434) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:25,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:28:25,316] {logging_mixin.py:104} INFO - [2021-08-28 01:28:25,316] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:25,403] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:25,410] {logging_mixin.py:104} INFO - [2021-08-28 01:28:25,410] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:28:25,420] {logging_mixin.py:104} INFO - [2021-08-28 01:28:25,420] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:28:25.419975+00:00
[2021-08-28 01:28:25,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:28:55,534] {scheduler_job.py:182} INFO - Started process (PID=4437) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:55,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:28:55,535] {logging_mixin.py:104} INFO - [2021-08-28 01:28:55,535] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:55,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:28:55,627] {logging_mixin.py:104} INFO - [2021-08-28 01:28:55,627] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:28:55,637] {logging_mixin.py:104} INFO - [2021-08-28 01:28:55,637] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:28:55.637167+00:00
[2021-08-28 01:28:55,644] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:29:25,754] {scheduler_job.py:182} INFO - Started process (PID=4440) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:25,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:29:25,755] {logging_mixin.py:104} INFO - [2021-08-28 01:29:25,755] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:25,839] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:25,846] {logging_mixin.py:104} INFO - [2021-08-28 01:29:25,846] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:29:25,856] {logging_mixin.py:104} INFO - [2021-08-28 01:29:25,856] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:29:25.856249+00:00
[2021-08-28 01:29:25,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:29:55,989] {scheduler_job.py:182} INFO - Started process (PID=4443) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:55,989] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:29:55,990] {logging_mixin.py:104} INFO - [2021-08-28 01:29:55,990] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:56,076] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:29:56,085] {logging_mixin.py:104} INFO - [2021-08-28 01:29:56,085] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:29:56,097] {logging_mixin.py:104} INFO - [2021-08-28 01:29:56,097] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:29:56.097060+00:00
[2021-08-28 01:29:56,104] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 01:30:26,213] {scheduler_job.py:182} INFO - Started process (PID=4446) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:26,214] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:30:26,214] {logging_mixin.py:104} INFO - [2021-08-28 01:30:26,214] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:26,305] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:26,312] {logging_mixin.py:104} INFO - [2021-08-28 01:30:26,312] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:30:26,321] {logging_mixin.py:104} INFO - [2021-08-28 01:30:26,321] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:30:26.321634+00:00
[2021-08-28 01:30:26,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:30:56,436] {scheduler_job.py:182} INFO - Started process (PID=4449) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:56,437] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:30:56,437] {logging_mixin.py:104} INFO - [2021-08-28 01:30:56,437] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:56,527] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:30:56,536] {logging_mixin.py:104} INFO - [2021-08-28 01:30:56,535] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:30:56,547] {logging_mixin.py:104} INFO - [2021-08-28 01:30:56,547] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:30:56.547370+00:00
[2021-08-28 01:30:56,554] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 01:31:26,660] {scheduler_job.py:182} INFO - Started process (PID=4452) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:26,661] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:31:26,661] {logging_mixin.py:104} INFO - [2021-08-28 01:31:26,661] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:26,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:26,756] {logging_mixin.py:104} INFO - [2021-08-28 01:31:26,756] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:31:26,767] {logging_mixin.py:104} INFO - [2021-08-28 01:31:26,767] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:31:26.767046+00:00
[2021-08-28 01:31:26,774] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:31:56,885] {scheduler_job.py:182} INFO - Started process (PID=4455) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:56,886] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:31:56,887] {logging_mixin.py:104} INFO - [2021-08-28 01:31:56,887] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:56,972] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:31:56,980] {logging_mixin.py:104} INFO - [2021-08-28 01:31:56,980] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:31:56,990] {logging_mixin.py:104} INFO - [2021-08-28 01:31:56,990] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:31:56.990048+00:00
[2021-08-28 01:31:56,997] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:32:27,104] {scheduler_job.py:182} INFO - Started process (PID=4458) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:27,105] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:32:27,105] {logging_mixin.py:104} INFO - [2021-08-28 01:32:27,105] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:27,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:27,201] {logging_mixin.py:104} INFO - [2021-08-28 01:32:27,201] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:32:27,211] {logging_mixin.py:104} INFO - [2021-08-28 01:32:27,211] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:32:27.211662+00:00
[2021-08-28 01:32:27,218] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:32:57,335] {scheduler_job.py:182} INFO - Started process (PID=4461) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:57,336] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:32:57,336] {logging_mixin.py:104} INFO - [2021-08-28 01:32:57,336] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:57,423] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:32:57,431] {logging_mixin.py:104} INFO - [2021-08-28 01:32:57,431] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:32:57,441] {logging_mixin.py:104} INFO - [2021-08-28 01:32:57,441] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:32:57.441554+00:00
[2021-08-28 01:32:57,448] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:33:27,563] {scheduler_job.py:182} INFO - Started process (PID=4464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:27,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:33:27,564] {logging_mixin.py:104} INFO - [2021-08-28 01:33:27,563] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:27,651] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:27,660] {logging_mixin.py:104} INFO - [2021-08-28 01:33:27,660] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:33:27,673] {logging_mixin.py:104} INFO - [2021-08-28 01:33:27,673] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:33:27.673318+00:00
[2021-08-28 01:33:27,680] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 01:33:57,783] {scheduler_job.py:182} INFO - Started process (PID=4467) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:57,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:33:57,784] {logging_mixin.py:104} INFO - [2021-08-28 01:33:57,784] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:57,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:33:57,878] {logging_mixin.py:104} INFO - [2021-08-28 01:33:57,877] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:33:57,888] {logging_mixin.py:104} INFO - [2021-08-28 01:33:57,888] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:33:57.888289+00:00
[2021-08-28 01:33:57,895] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:34:28,006] {scheduler_job.py:182} INFO - Started process (PID=4470) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:28,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:34:28,007] {logging_mixin.py:104} INFO - [2021-08-28 01:34:28,006] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:28,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:28,100] {logging_mixin.py:104} INFO - [2021-08-28 01:34:28,099] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:34:28,110] {logging_mixin.py:104} INFO - [2021-08-28 01:34:28,110] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:34:28.110143+00:00
[2021-08-28 01:34:28,116] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:34:58,253] {scheduler_job.py:182} INFO - Started process (PID=4473) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:58,254] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:34:58,254] {logging_mixin.py:104} INFO - [2021-08-28 01:34:58,254] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:58,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:34:58,349] {logging_mixin.py:104} INFO - [2021-08-28 01:34:58,349] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:34:58,360] {logging_mixin.py:104} INFO - [2021-08-28 01:34:58,360] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:34:58.359876+00:00
[2021-08-28 01:34:58,367] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:35:28,479] {scheduler_job.py:182} INFO - Started process (PID=4476) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:28,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:35:28,480] {logging_mixin.py:104} INFO - [2021-08-28 01:35:28,480] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:28,565] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:28,573] {logging_mixin.py:104} INFO - [2021-08-28 01:35:28,573] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:35:28,582] {logging_mixin.py:104} INFO - [2021-08-28 01:35:28,582] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:35:28.582778+00:00
[2021-08-28 01:35:28,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:35:58,731] {scheduler_job.py:182} INFO - Started process (PID=4479) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:58,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:35:58,732] {logging_mixin.py:104} INFO - [2021-08-28 01:35:58,732] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:58,845] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:35:58,853] {logging_mixin.py:104} INFO - [2021-08-28 01:35:58,853] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:35:58,863] {logging_mixin.py:104} INFO - [2021-08-28 01:35:58,863] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:35:58.862918+00:00
[2021-08-28 01:35:58,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-08-28 01:36:28,941] {scheduler_job.py:182} INFO - Started process (PID=4482) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:28,942] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:36:28,942] {logging_mixin.py:104} INFO - [2021-08-28 01:36:28,942] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:29,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:29,038] {logging_mixin.py:104} INFO - [2021-08-28 01:36:29,038] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:36:29,048] {logging_mixin.py:104} INFO - [2021-08-28 01:36:29,047] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:36:29.047849+00:00
[2021-08-28 01:36:29,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:36:59,170] {scheduler_job.py:182} INFO - Started process (PID=4485) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:59,171] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:36:59,172] {logging_mixin.py:104} INFO - [2021-08-28 01:36:59,172] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:59,258] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:36:59,268] {logging_mixin.py:104} INFO - [2021-08-28 01:36:59,267] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:36:59,279] {logging_mixin.py:104} INFO - [2021-08-28 01:36:59,279] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:36:59.278924+00:00
[2021-08-28 01:36:59,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 01:37:29,399] {scheduler_job.py:182} INFO - Started process (PID=4488) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:29,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:37:29,400] {logging_mixin.py:104} INFO - [2021-08-28 01:37:29,400] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:29,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:29,493] {logging_mixin.py:104} INFO - [2021-08-28 01:37:29,493] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:37:29,502] {logging_mixin.py:104} INFO - [2021-08-28 01:37:29,502] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:37:29.502692+00:00
[2021-08-28 01:37:29,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:37:59,623] {scheduler_job.py:182} INFO - Started process (PID=4491) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:59,624] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:37:59,624] {logging_mixin.py:104} INFO - [2021-08-28 01:37:59,624] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:59,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:37:59,720] {logging_mixin.py:104} INFO - [2021-08-28 01:37:59,720] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:37:59,730] {logging_mixin.py:104} INFO - [2021-08-28 01:37:59,730] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:37:59.730219+00:00
[2021-08-28 01:37:59,737] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:38:29,862] {scheduler_job.py:182} INFO - Started process (PID=4494) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:38:29,863] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:38:29,863] {logging_mixin.py:104} INFO - [2021-08-28 01:38:29,863] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:38:29,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:38:29,957] {logging_mixin.py:104} INFO - [2021-08-28 01:38:29,957] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:38:29,966] {logging_mixin.py:104} INFO - [2021-08-28 01:38:29,966] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:38:29.966499+00:00
[2021-08-28 01:38:29,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:39:00,070] {scheduler_job.py:182} INFO - Started process (PID=4497) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:00,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:39:00,070] {logging_mixin.py:104} INFO - [2021-08-28 01:39:00,070] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:00,163] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:00,171] {logging_mixin.py:104} INFO - [2021-08-28 01:39:00,171] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:39:00,181] {logging_mixin.py:104} INFO - [2021-08-28 01:39:00,181] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:39:00.181078+00:00
[2021-08-28 01:39:00,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 01:39:30,298] {scheduler_job.py:182} INFO - Started process (PID=4500) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:30,299] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:39:30,300] {logging_mixin.py:104} INFO - [2021-08-28 01:39:30,299] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:30,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:39:30,391] {logging_mixin.py:104} INFO - [2021-08-28 01:39:30,391] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:39:30,401] {logging_mixin.py:104} INFO - [2021-08-28 01:39:30,401] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:39:30.401074+00:00
[2021-08-28 01:39:30,407] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:40:00,540] {scheduler_job.py:182} INFO - Started process (PID=4503) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:00,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:40:00,541] {logging_mixin.py:104} INFO - [2021-08-28 01:40:00,541] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:00,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:00,638] {logging_mixin.py:104} INFO - [2021-08-28 01:40:00,638] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:40:00,649] {logging_mixin.py:104} INFO - [2021-08-28 01:40:00,649] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:40:00.649682+00:00
[2021-08-28 01:40:00,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:40:30,763] {scheduler_job.py:182} INFO - Started process (PID=4506) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:30,763] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:40:30,764] {logging_mixin.py:104} INFO - [2021-08-28 01:40:30,764] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:30,852] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:40:30,860] {logging_mixin.py:104} INFO - [2021-08-28 01:40:30,859] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:40:30,869] {logging_mixin.py:104} INFO - [2021-08-28 01:40:30,869] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:40:30.869409+00:00
[2021-08-28 01:40:30,875] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:41:00,972] {scheduler_job.py:182} INFO - Started process (PID=4509) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:00,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:41:00,973] {logging_mixin.py:104} INFO - [2021-08-28 01:41:00,973] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:01,059] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:01,067] {logging_mixin.py:104} INFO - [2021-08-28 01:41:01,067] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:41:01,076] {logging_mixin.py:104} INFO - [2021-08-28 01:41:01,076] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:41:01.076400+00:00
[2021-08-28 01:41:01,083] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:41:31,193] {scheduler_job.py:182} INFO - Started process (PID=4512) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:31,194] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:41:31,194] {logging_mixin.py:104} INFO - [2021-08-28 01:41:31,194] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:31,280] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:41:31,287] {logging_mixin.py:104} INFO - [2021-08-28 01:41:31,287] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:41:31,297] {logging_mixin.py:104} INFO - [2021-08-28 01:41:31,297] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:41:31.297082+00:00
[2021-08-28 01:41:31,304] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:42:01,419] {scheduler_job.py:182} INFO - Started process (PID=4515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:01,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:42:01,421] {logging_mixin.py:104} INFO - [2021-08-28 01:42:01,421] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:01,506] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:01,513] {logging_mixin.py:104} INFO - [2021-08-28 01:42:01,513] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:42:01,523] {logging_mixin.py:104} INFO - [2021-08-28 01:42:01,523] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:42:01.523180+00:00
[2021-08-28 01:42:01,530] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:42:31,644] {scheduler_job.py:182} INFO - Started process (PID=4518) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:31,645] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:42:31,645] {logging_mixin.py:104} INFO - [2021-08-28 01:42:31,645] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:31,733] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:42:31,741] {logging_mixin.py:104} INFO - [2021-08-28 01:42:31,741] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:42:31,751] {logging_mixin.py:104} INFO - [2021-08-28 01:42:31,751] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:42:31.751049+00:00
[2021-08-28 01:42:31,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:43:01,874] {scheduler_job.py:182} INFO - Started process (PID=4521) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:01,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:43:01,876] {logging_mixin.py:104} INFO - [2021-08-28 01:43:01,875] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:01,961] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:01,970] {logging_mixin.py:104} INFO - [2021-08-28 01:43:01,970] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:43:01,980] {logging_mixin.py:104} INFO - [2021-08-28 01:43:01,980] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:43:01.980074+00:00
[2021-08-28 01:43:01,987] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:43:32,099] {scheduler_job.py:182} INFO - Started process (PID=4524) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:32,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:43:32,100] {logging_mixin.py:104} INFO - [2021-08-28 01:43:32,100] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:32,185] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:43:32,192] {logging_mixin.py:104} INFO - [2021-08-28 01:43:32,192] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:43:32,202] {logging_mixin.py:104} INFO - [2021-08-28 01:43:32,201] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:43:32.201814+00:00
[2021-08-28 01:43:32,208] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:44:02,325] {scheduler_job.py:182} INFO - Started process (PID=4527) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:02,326] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:44:02,326] {logging_mixin.py:104} INFO - [2021-08-28 01:44:02,326] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:02,413] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:02,421] {logging_mixin.py:104} INFO - [2021-08-28 01:44:02,421] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:44:02,430] {logging_mixin.py:104} INFO - [2021-08-28 01:44:02,430] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:44:02.430641+00:00
[2021-08-28 01:44:02,437] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 01:44:32,554] {scheduler_job.py:182} INFO - Started process (PID=4530) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:32,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:44:32,555] {logging_mixin.py:104} INFO - [2021-08-28 01:44:32,555] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:32,649] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:44:32,656] {logging_mixin.py:104} INFO - [2021-08-28 01:44:32,656] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:44:32,666] {logging_mixin.py:104} INFO - [2021-08-28 01:44:32,666] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:44:32.666432+00:00
[2021-08-28 01:44:32,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 01:45:02,803] {scheduler_job.py:182} INFO - Started process (PID=4533) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:02,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:45:02,804] {logging_mixin.py:104} INFO - [2021-08-28 01:45:02,804] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:02,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:02,895] {logging_mixin.py:104} INFO - [2021-08-28 01:45:02,895] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:45:02,905] {logging_mixin.py:104} INFO - [2021-08-28 01:45:02,905] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:45:02.904936+00:00
[2021-08-28 01:45:02,910] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-08-28 01:45:33,030] {scheduler_job.py:182} INFO - Started process (PID=4536) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:33,031] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:45:33,031] {logging_mixin.py:104} INFO - [2021-08-28 01:45:33,031] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:33,117] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:45:33,124] {logging_mixin.py:104} INFO - [2021-08-28 01:45:33,124] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:45:33,134] {logging_mixin.py:104} INFO - [2021-08-28 01:45:33,134] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:45:33.133977+00:00
[2021-08-28 01:45:33,140] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:46:03,246] {scheduler_job.py:182} INFO - Started process (PID=4539) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:03,247] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:46:03,247] {logging_mixin.py:104} INFO - [2021-08-28 01:46:03,247] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:03,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:03,340] {logging_mixin.py:104} INFO - [2021-08-28 01:46:03,340] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:46:03,349] {logging_mixin.py:104} INFO - [2021-08-28 01:46:03,349] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:46:03.349590+00:00
[2021-08-28 01:46:03,355] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:46:33,462] {scheduler_job.py:182} INFO - Started process (PID=4542) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:33,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:46:33,463] {logging_mixin.py:104} INFO - [2021-08-28 01:46:33,463] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:33,550] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:46:33,557] {logging_mixin.py:104} INFO - [2021-08-28 01:46:33,557] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:46:33,567] {logging_mixin.py:104} INFO - [2021-08-28 01:46:33,566] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:46:33.566835+00:00
[2021-08-28 01:46:33,573] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:47:03,689] {scheduler_job.py:182} INFO - Started process (PID=4545) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:03,690] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:47:03,691] {logging_mixin.py:104} INFO - [2021-08-28 01:47:03,691] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:03,778] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:03,786] {logging_mixin.py:104} INFO - [2021-08-28 01:47:03,786] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:47:03,795] {logging_mixin.py:104} INFO - [2021-08-28 01:47:03,795] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:47:03.795758+00:00
[2021-08-28 01:47:03,802] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:47:33,920] {scheduler_job.py:182} INFO - Started process (PID=4548) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:33,921] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:47:33,921] {logging_mixin.py:104} INFO - [2021-08-28 01:47:33,921] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:34,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:47:34,015] {logging_mixin.py:104} INFO - [2021-08-28 01:47:34,014] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:47:34,024] {logging_mixin.py:104} INFO - [2021-08-28 01:47:34,024] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:47:34.024378+00:00
[2021-08-28 01:47:34,030] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:48:04,143] {scheduler_job.py:182} INFO - Started process (PID=4551) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:04,144] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:48:04,144] {logging_mixin.py:104} INFO - [2021-08-28 01:48:04,144] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:04,230] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:04,237] {logging_mixin.py:104} INFO - [2021-08-28 01:48:04,237] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:48:04,247] {logging_mixin.py:104} INFO - [2021-08-28 01:48:04,247] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:48:04.247318+00:00
[2021-08-28 01:48:04,253] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:48:34,374] {scheduler_job.py:182} INFO - Started process (PID=4554) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:34,375] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:48:34,375] {logging_mixin.py:104} INFO - [2021-08-28 01:48:34,375] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:34,460] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:48:34,468] {logging_mixin.py:104} INFO - [2021-08-28 01:48:34,467] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:48:34,477] {logging_mixin.py:104} INFO - [2021-08-28 01:48:34,477] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:48:34.477410+00:00
[2021-08-28 01:48:34,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:49:04,600] {scheduler_job.py:182} INFO - Started process (PID=4557) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:04,601] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:49:04,601] {logging_mixin.py:104} INFO - [2021-08-28 01:49:04,601] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:04,687] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:04,694] {logging_mixin.py:104} INFO - [2021-08-28 01:49:04,694] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:49:04,703] {logging_mixin.py:104} INFO - [2021-08-28 01:49:04,703] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:49:04.703066+00:00
[2021-08-28 01:49:04,708] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:49:34,839] {scheduler_job.py:182} INFO - Started process (PID=4560) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:34,839] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:49:34,840] {logging_mixin.py:104} INFO - [2021-08-28 01:49:34,840] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:34,949] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:49:34,957] {logging_mixin.py:104} INFO - [2021-08-28 01:49:34,957] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:49:34,970] {logging_mixin.py:104} INFO - [2021-08-28 01:49:34,970] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:49:34.970223+00:00
[2021-08-28 01:49:34,977] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-08-28 01:50:05,088] {scheduler_job.py:182} INFO - Started process (PID=4563) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:05,089] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:50:05,089] {logging_mixin.py:104} INFO - [2021-08-28 01:50:05,089] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:05,174] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:05,181] {logging_mixin.py:104} INFO - [2021-08-28 01:50:05,181] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:50:05,191] {logging_mixin.py:104} INFO - [2021-08-28 01:50:05,191] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:50:05.191020+00:00
[2021-08-28 01:50:05,197] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 01:50:35,305] {scheduler_job.py:182} INFO - Started process (PID=4566) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:35,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:50:35,306] {logging_mixin.py:104} INFO - [2021-08-28 01:50:35,306] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:35,392] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:50:35,401] {logging_mixin.py:104} INFO - [2021-08-28 01:50:35,400] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:50:35,412] {logging_mixin.py:104} INFO - [2021-08-28 01:50:35,412] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:50:35.412189+00:00
[2021-08-28 01:50:35,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:51:05,525] {scheduler_job.py:182} INFO - Started process (PID=4569) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:05,526] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:51:05,526] {logging_mixin.py:104} INFO - [2021-08-28 01:51:05,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:05,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:05,624] {logging_mixin.py:104} INFO - [2021-08-28 01:51:05,623] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:51:05,638] {logging_mixin.py:104} INFO - [2021-08-28 01:51:05,637] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:51:05.637833+00:00
[2021-08-28 01:51:05,643] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 01:51:35,756] {scheduler_job.py:182} INFO - Started process (PID=4572) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:35,757] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:51:35,757] {logging_mixin.py:104} INFO - [2021-08-28 01:51:35,757] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:35,854] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:51:35,865] {logging_mixin.py:104} INFO - [2021-08-28 01:51:35,865] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:51:35,878] {logging_mixin.py:104} INFO - [2021-08-28 01:51:35,878] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:51:35.878353+00:00
[2021-08-28 01:51:35,886] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-28 01:52:06,022] {scheduler_job.py:182} INFO - Started process (PID=4575) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:06,023] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:52:06,023] {logging_mixin.py:104} INFO - [2021-08-28 01:52:06,023] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:06,113] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:06,121] {logging_mixin.py:104} INFO - [2021-08-28 01:52:06,120] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:52:06,131] {logging_mixin.py:104} INFO - [2021-08-28 01:52:06,131] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:52:06.131028+00:00
[2021-08-28 01:52:06,138] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:52:36,223] {scheduler_job.py:182} INFO - Started process (PID=4578) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:36,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:52:36,224] {logging_mixin.py:104} INFO - [2021-08-28 01:52:36,224] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:36,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:52:36,319] {logging_mixin.py:104} INFO - [2021-08-28 01:52:36,319] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:52:36,330] {logging_mixin.py:104} INFO - [2021-08-28 01:52:36,330] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:52:36.330026+00:00
[2021-08-28 01:52:36,336] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:53:06,448] {scheduler_job.py:182} INFO - Started process (PID=4581) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:06,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:53:06,449] {logging_mixin.py:104} INFO - [2021-08-28 01:53:06,449] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:06,542] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:06,549] {logging_mixin.py:104} INFO - [2021-08-28 01:53:06,549] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:53:06,560] {logging_mixin.py:104} INFO - [2021-08-28 01:53:06,560] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:53:06.560380+00:00
[2021-08-28 01:53:06,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 01:53:36,670] {scheduler_job.py:182} INFO - Started process (PID=4584) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:36,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:53:36,671] {logging_mixin.py:104} INFO - [2021-08-28 01:53:36,671] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:36,775] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:53:36,785] {logging_mixin.py:104} INFO - [2021-08-28 01:53:36,785] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:53:36,799] {logging_mixin.py:104} INFO - [2021-08-28 01:53:36,799] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:53:36.799058+00:00
[2021-08-28 01:53:36,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-08-28 01:54:06,906] {scheduler_job.py:182} INFO - Started process (PID=4587) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:06,907] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:54:06,907] {logging_mixin.py:104} INFO - [2021-08-28 01:54:06,907] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:06,999] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:07,008] {logging_mixin.py:104} INFO - [2021-08-28 01:54:07,007] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:54:07,019] {logging_mixin.py:104} INFO - [2021-08-28 01:54:07,019] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:54:07.019634+00:00
[2021-08-28 01:54:07,028] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-28 01:54:37,154] {scheduler_job.py:182} INFO - Started process (PID=4590) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:37,154] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:54:37,155] {logging_mixin.py:104} INFO - [2021-08-28 01:54:37,155] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:37,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:54:37,268] {logging_mixin.py:104} INFO - [2021-08-28 01:54:37,268] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:54:37,280] {logging_mixin.py:104} INFO - [2021-08-28 01:54:37,280] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:54:37.280058+00:00
[2021-08-28 01:54:37,288] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-08-28 01:55:07,392] {scheduler_job.py:182} INFO - Started process (PID=4593) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:07,392] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:55:07,393] {logging_mixin.py:104} INFO - [2021-08-28 01:55:07,393] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:07,484] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:07,493] {logging_mixin.py:104} INFO - [2021-08-28 01:55:07,493] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:55:07,505] {logging_mixin.py:104} INFO - [2021-08-28 01:55:07,505] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:55:07.505461+00:00
[2021-08-28 01:55:07,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-28 01:55:37,610] {scheduler_job.py:182} INFO - Started process (PID=4596) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:37,611] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:55:37,611] {logging_mixin.py:104} INFO - [2021-08-28 01:55:37,611] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:37,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:55:37,709] {logging_mixin.py:104} INFO - [2021-08-28 01:55:37,709] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:55:37,720] {logging_mixin.py:104} INFO - [2021-08-28 01:55:37,719] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:55:37.719862+00:00
[2021-08-28 01:55:37,726] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:56:07,846] {scheduler_job.py:182} INFO - Started process (PID=4599) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:07,847] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:56:07,847] {logging_mixin.py:104} INFO - [2021-08-28 01:56:07,847] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:07,982] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:07,993] {logging_mixin.py:104} INFO - [2021-08-28 01:56:07,993] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:56:08,006] {logging_mixin.py:104} INFO - [2021-08-28 01:56:08,006] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:56:08.006605+00:00
[2021-08-28 01:56:08,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-08-28 01:56:38,118] {scheduler_job.py:182} INFO - Started process (PID=4602) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:38,119] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:56:38,119] {logging_mixin.py:104} INFO - [2021-08-28 01:56:38,119] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:38,208] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:56:38,217] {logging_mixin.py:104} INFO - [2021-08-28 01:56:38,217] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:56:38,227] {logging_mixin.py:104} INFO - [2021-08-28 01:56:38,227] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:56:38.227751+00:00
[2021-08-28 01:56:38,235] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 01:57:08,343] {scheduler_job.py:182} INFO - Started process (PID=4605) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:08,344] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:57:08,345] {logging_mixin.py:104} INFO - [2021-08-28 01:57:08,345] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:08,431] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:08,438] {logging_mixin.py:104} INFO - [2021-08-28 01:57:08,438] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:57:08,447] {logging_mixin.py:104} INFO - [2021-08-28 01:57:08,447] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:57:08.447801+00:00
[2021-08-28 01:57:08,454] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 01:57:38,577] {scheduler_job.py:182} INFO - Started process (PID=4608) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:38,578] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:57:38,578] {logging_mixin.py:104} INFO - [2021-08-28 01:57:38,578] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:38,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:57:38,672] {logging_mixin.py:104} INFO - [2021-08-28 01:57:38,672] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:57:38,682] {logging_mixin.py:104} INFO - [2021-08-28 01:57:38,682] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:57:38.682402+00:00
[2021-08-28 01:57:38,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 01:58:08,832] {scheduler_job.py:182} INFO - Started process (PID=4611) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:08,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:58:08,833] {logging_mixin.py:104} INFO - [2021-08-28 01:58:08,833] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:08,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:08,929] {logging_mixin.py:104} INFO - [2021-08-28 01:58:08,929] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:58:08,939] {logging_mixin.py:104} INFO - [2021-08-28 01:58:08,939] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:58:08.939375+00:00
[2021-08-28 01:58:08,945] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 01:58:39,043] {scheduler_job.py:182} INFO - Started process (PID=4614) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:39,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:58:39,044] {logging_mixin.py:104} INFO - [2021-08-28 01:58:39,044] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:39,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:58:39,136] {logging_mixin.py:104} INFO - [2021-08-28 01:58:39,136] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:58:39,146] {logging_mixin.py:104} INFO - [2021-08-28 01:58:39,146] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:58:39.146139+00:00
[2021-08-28 01:58:39,152] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 01:59:09,283] {scheduler_job.py:182} INFO - Started process (PID=4617) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:09,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:59:09,284] {logging_mixin.py:104} INFO - [2021-08-28 01:59:09,284] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:09,373] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:09,382] {logging_mixin.py:104} INFO - [2021-08-28 01:59:09,382] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:59:09,392] {logging_mixin.py:104} INFO - [2021-08-28 01:59:09,391] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:59:09.391873+00:00
[2021-08-28 01:59:09,397] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 01:59:39,522] {scheduler_job.py:182} INFO - Started process (PID=4620) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:39,523] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 01:59:39,523] {logging_mixin.py:104} INFO - [2021-08-28 01:59:39,523] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:39,607] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 01:59:39,615] {logging_mixin.py:104} INFO - [2021-08-28 01:59:39,614] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 01:59:39,624] {logging_mixin.py:104} INFO - [2021-08-28 01:59:39,624] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 01:59:39.624551+00:00
[2021-08-28 01:59:39,631] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:00:09,743] {scheduler_job.py:182} INFO - Started process (PID=4623) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:09,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:00:09,744] {logging_mixin.py:104} INFO - [2021-08-28 02:00:09,744] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:09,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:09,843] {logging_mixin.py:104} INFO - [2021-08-28 02:00:09,843] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:00:09,855] {logging_mixin.py:104} INFO - [2021-08-28 02:00:09,855] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:00:09.855060+00:00
[2021-08-28 02:00:09,862] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 02:00:39,969] {scheduler_job.py:182} INFO - Started process (PID=4626) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:39,970] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:00:39,970] {logging_mixin.py:104} INFO - [2021-08-28 02:00:39,970] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:40,054] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:00:40,062] {logging_mixin.py:104} INFO - [2021-08-28 02:00:40,062] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:00:40,071] {logging_mixin.py:104} INFO - [2021-08-28 02:00:40,071] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:00:40.071386+00:00
[2021-08-28 02:00:40,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:01:10,189] {scheduler_job.py:182} INFO - Started process (PID=4629) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:10,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:01:10,191] {logging_mixin.py:104} INFO - [2021-08-28 02:01:10,190] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:10,275] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:10,285] {logging_mixin.py:104} INFO - [2021-08-28 02:01:10,285] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:01:10,297] {logging_mixin.py:104} INFO - [2021-08-28 02:01:10,297] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:01:10.297134+00:00
[2021-08-28 02:01:10,303] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 02:01:40,416] {scheduler_job.py:182} INFO - Started process (PID=4632) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:40,417] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:01:40,418] {logging_mixin.py:104} INFO - [2021-08-28 02:01:40,417] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:40,504] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:01:40,511] {logging_mixin.py:104} INFO - [2021-08-28 02:01:40,511] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:01:40,521] {logging_mixin.py:104} INFO - [2021-08-28 02:01:40,521] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:01:40.521158+00:00
[2021-08-28 02:01:40,528] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:02:10,652] {scheduler_job.py:182} INFO - Started process (PID=4635) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:10,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:02:10,654] {logging_mixin.py:104} INFO - [2021-08-28 02:02:10,653] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:10,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:10,747] {logging_mixin.py:104} INFO - [2021-08-28 02:02:10,747] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:02:10,757] {logging_mixin.py:104} INFO - [2021-08-28 02:02:10,756] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:02:10.756842+00:00
[2021-08-28 02:02:10,763] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:02:40,886] {scheduler_job.py:182} INFO - Started process (PID=4638) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:40,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:02:40,887] {logging_mixin.py:104} INFO - [2021-08-28 02:02:40,887] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:40,975] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:02:40,983] {logging_mixin.py:104} INFO - [2021-08-28 02:02:40,982] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:02:40,993] {logging_mixin.py:104} INFO - [2021-08-28 02:02:40,993] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:02:40.993695+00:00
[2021-08-28 02:02:41,000] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:03:11,109] {scheduler_job.py:182} INFO - Started process (PID=4641) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:11,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:03:11,111] {logging_mixin.py:104} INFO - [2021-08-28 02:03:11,111] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:11,195] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:11,202] {logging_mixin.py:104} INFO - [2021-08-28 02:03:11,202] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:03:11,213] {logging_mixin.py:104} INFO - [2021-08-28 02:03:11,213] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:03:11.213036+00:00
[2021-08-28 02:03:11,224] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 02:03:41,334] {scheduler_job.py:182} INFO - Started process (PID=4644) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:41,335] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:03:41,335] {logging_mixin.py:104} INFO - [2021-08-28 02:03:41,335] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:41,420] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:03:41,427] {logging_mixin.py:104} INFO - [2021-08-28 02:03:41,427] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:03:41,437] {logging_mixin.py:104} INFO - [2021-08-28 02:03:41,437] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:03:41.437177+00:00
[2021-08-28 02:03:41,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:04:11,585] {scheduler_job.py:182} INFO - Started process (PID=4647) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:11,586] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:04:11,587] {logging_mixin.py:104} INFO - [2021-08-28 02:04:11,587] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:11,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:11,686] {logging_mixin.py:104} INFO - [2021-08-28 02:04:11,686] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:04:11,696] {logging_mixin.py:104} INFO - [2021-08-28 02:04:11,696] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:04:11.696263+00:00
[2021-08-28 02:04:11,702] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 02:04:41,821] {scheduler_job.py:182} INFO - Started process (PID=4650) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:41,822] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:04:41,822] {logging_mixin.py:104} INFO - [2021-08-28 02:04:41,822] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:41,906] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:04:41,914] {logging_mixin.py:104} INFO - [2021-08-28 02:04:41,913] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:04:41,924] {logging_mixin.py:104} INFO - [2021-08-28 02:04:41,924] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:04:41.924179+00:00
[2021-08-28 02:04:41,931] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:05:12,047] {scheduler_job.py:182} INFO - Started process (PID=4653) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:12,047] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:05:12,048] {logging_mixin.py:104} INFO - [2021-08-28 02:05:12,048] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:12,136] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:12,143] {logging_mixin.py:104} INFO - [2021-08-28 02:05:12,143] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:05:12,154] {logging_mixin.py:104} INFO - [2021-08-28 02:05:12,154] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:05:12.154249+00:00
[2021-08-28 02:05:12,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 02:05:42,263] {scheduler_job.py:182} INFO - Started process (PID=4656) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:42,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:05:42,264] {logging_mixin.py:104} INFO - [2021-08-28 02:05:42,264] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:42,351] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:05:42,359] {logging_mixin.py:104} INFO - [2021-08-28 02:05:42,359] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:05:42,369] {logging_mixin.py:104} INFO - [2021-08-28 02:05:42,369] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:05:42.368968+00:00
[2021-08-28 02:05:42,375] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:06:12,488] {scheduler_job.py:182} INFO - Started process (PID=4659) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:12,489] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:06:12,489] {logging_mixin.py:104} INFO - [2021-08-28 02:06:12,489] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:12,574] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:12,582] {logging_mixin.py:104} INFO - [2021-08-28 02:06:12,582] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:06:12,592] {logging_mixin.py:104} INFO - [2021-08-28 02:06:12,592] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:06:12.592043+00:00
[2021-08-28 02:06:12,598] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:06:42,708] {scheduler_job.py:182} INFO - Started process (PID=4662) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:42,709] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:06:42,709] {logging_mixin.py:104} INFO - [2021-08-28 02:06:42,709] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:42,796] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:06:42,804] {logging_mixin.py:104} INFO - [2021-08-28 02:06:42,804] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:06:42,814] {logging_mixin.py:104} INFO - [2021-08-28 02:06:42,814] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:06:42.814530+00:00
[2021-08-28 02:06:42,821] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:07:12,930] {scheduler_job.py:182} INFO - Started process (PID=4665) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:12,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:07:12,932] {logging_mixin.py:104} INFO - [2021-08-28 02:07:12,932] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:13,016] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:13,024] {logging_mixin.py:104} INFO - [2021-08-28 02:07:13,024] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:07:13,034] {logging_mixin.py:104} INFO - [2021-08-28 02:07:13,034] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:07:13.034117+00:00
[2021-08-28 02:07:13,041] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:07:43,140] {scheduler_job.py:182} INFO - Started process (PID=4668) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:43,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:07:43,141] {logging_mixin.py:104} INFO - [2021-08-28 02:07:43,141] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:43,227] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:07:43,235] {logging_mixin.py:104} INFO - [2021-08-28 02:07:43,235] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:07:43,245] {logging_mixin.py:104} INFO - [2021-08-28 02:07:43,244] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:07:43.244817+00:00
[2021-08-28 02:07:43,252] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:08:13,356] {scheduler_job.py:182} INFO - Started process (PID=4671) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:13,357] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:08:13,357] {logging_mixin.py:104} INFO - [2021-08-28 02:08:13,357] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:13,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:13,453] {logging_mixin.py:104} INFO - [2021-08-28 02:08:13,453] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:08:13,463] {logging_mixin.py:104} INFO - [2021-08-28 02:08:13,463] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:08:13.463117+00:00
[2021-08-28 02:08:13,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:08:43,587] {scheduler_job.py:182} INFO - Started process (PID=4674) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:43,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:08:43,588] {logging_mixin.py:104} INFO - [2021-08-28 02:08:43,588] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:43,673] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:08:43,681] {logging_mixin.py:104} INFO - [2021-08-28 02:08:43,681] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:08:43,690] {logging_mixin.py:104} INFO - [2021-08-28 02:08:43,690] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:08:43.690596+00:00
[2021-08-28 02:08:43,696] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:09:13,807] {scheduler_job.py:182} INFO - Started process (PID=4677) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:13,807] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:09:13,808] {logging_mixin.py:104} INFO - [2021-08-28 02:09:13,808] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:13,895] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:13,904] {logging_mixin.py:104} INFO - [2021-08-28 02:09:13,904] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:09:13,916] {logging_mixin.py:104} INFO - [2021-08-28 02:09:13,916] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:09:13.915990+00:00
[2021-08-28 02:09:13,923] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 02:09:44,053] {scheduler_job.py:182} INFO - Started process (PID=4680) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:44,054] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:09:44,054] {logging_mixin.py:104} INFO - [2021-08-28 02:09:44,054] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:44,140] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:09:44,147] {logging_mixin.py:104} INFO - [2021-08-28 02:09:44,147] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:09:44,158] {logging_mixin.py:104} INFO - [2021-08-28 02:09:44,158] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:09:44.158620+00:00
[2021-08-28 02:09:44,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:10:14,277] {scheduler_job.py:182} INFO - Started process (PID=4683) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:14,277] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:10:14,278] {logging_mixin.py:104} INFO - [2021-08-28 02:10:14,278] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:14,367] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:14,374] {logging_mixin.py:104} INFO - [2021-08-28 02:10:14,374] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:10:14,383] {logging_mixin.py:104} INFO - [2021-08-28 02:10:14,383] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:10:14.383237+00:00
[2021-08-28 02:10:14,389] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:10:44,504] {scheduler_job.py:182} INFO - Started process (PID=4686) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:44,505] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:10:44,505] {logging_mixin.py:104} INFO - [2021-08-28 02:10:44,505] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:44,608] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:10:44,619] {logging_mixin.py:104} INFO - [2021-08-28 02:10:44,619] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:10:44,629] {logging_mixin.py:104} INFO - [2021-08-28 02:10:44,629] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:10:44.629237+00:00
[2021-08-28 02:10:44,635] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-08-28 02:11:14,753] {scheduler_job.py:182} INFO - Started process (PID=4689) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:14,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:11:14,754] {logging_mixin.py:104} INFO - [2021-08-28 02:11:14,754] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:14,840] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:14,848] {logging_mixin.py:104} INFO - [2021-08-28 02:11:14,848] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:11:14,858] {logging_mixin.py:104} INFO - [2021-08-28 02:11:14,857] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:11:14.857800+00:00
[2021-08-28 02:11:14,864] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:11:44,978] {scheduler_job.py:182} INFO - Started process (PID=4692) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:44,978] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:11:44,979] {logging_mixin.py:104} INFO - [2021-08-28 02:11:44,979] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:45,066] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:11:45,076] {logging_mixin.py:104} INFO - [2021-08-28 02:11:45,076] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:11:45,086] {logging_mixin.py:104} INFO - [2021-08-28 02:11:45,086] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:11:45.086234+00:00
[2021-08-28 02:11:45,092] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:12:15,205] {scheduler_job.py:182} INFO - Started process (PID=4695) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:15,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:12:15,206] {logging_mixin.py:104} INFO - [2021-08-28 02:12:15,206] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:15,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:15,304] {logging_mixin.py:104} INFO - [2021-08-28 02:12:15,304] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:12:15,315] {logging_mixin.py:104} INFO - [2021-08-28 02:12:15,315] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:12:15.315255+00:00
[2021-08-28 02:12:15,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 02:12:45,422] {scheduler_job.py:182} INFO - Started process (PID=4698) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:45,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:12:45,423] {logging_mixin.py:104} INFO - [2021-08-28 02:12:45,423] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:45,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:12:45,517] {logging_mixin.py:104} INFO - [2021-08-28 02:12:45,516] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:12:45,526] {logging_mixin.py:104} INFO - [2021-08-28 02:12:45,526] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:12:45.526772+00:00
[2021-08-28 02:12:45,533] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:13:15,653] {scheduler_job.py:182} INFO - Started process (PID=4701) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:15,653] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:13:15,654] {logging_mixin.py:104} INFO - [2021-08-28 02:13:15,654] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:15,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:15,749] {logging_mixin.py:104} INFO - [2021-08-28 02:13:15,749] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:13:15,759] {logging_mixin.py:104} INFO - [2021-08-28 02:13:15,759] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:13:15.759012+00:00
[2021-08-28 02:13:15,767] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 02:13:45,878] {scheduler_job.py:182} INFO - Started process (PID=4704) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:45,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:13:45,879] {logging_mixin.py:104} INFO - [2021-08-28 02:13:45,879] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:45,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:13:45,972] {logging_mixin.py:104} INFO - [2021-08-28 02:13:45,972] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:13:45,982] {logging_mixin.py:104} INFO - [2021-08-28 02:13:45,981] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:13:45.981866+00:00
[2021-08-28 02:13:45,988] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:14:16,116] {scheduler_job.py:182} INFO - Started process (PID=4707) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:16,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:14:16,116] {logging_mixin.py:104} INFO - [2021-08-28 02:14:16,116] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:16,202] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:16,209] {logging_mixin.py:104} INFO - [2021-08-28 02:14:16,209] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:14:16,219] {logging_mixin.py:104} INFO - [2021-08-28 02:14:16,219] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:14:16.218954+00:00
[2021-08-28 02:14:16,225] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:14:46,350] {scheduler_job.py:182} INFO - Started process (PID=4710) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:46,351] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:14:46,351] {logging_mixin.py:104} INFO - [2021-08-28 02:14:46,351] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:46,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:14:46,446] {logging_mixin.py:104} INFO - [2021-08-28 02:14:46,446] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:14:46,456] {logging_mixin.py:104} INFO - [2021-08-28 02:14:46,456] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:14:46.456381+00:00
[2021-08-28 02:14:46,463] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:15:16,587] {scheduler_job.py:182} INFO - Started process (PID=4713) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:16,587] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:15:16,588] {logging_mixin.py:104} INFO - [2021-08-28 02:15:16,588] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:16,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:16,682] {logging_mixin.py:104} INFO - [2021-08-28 02:15:16,682] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:15:16,691] {logging_mixin.py:104} INFO - [2021-08-28 02:15:16,691] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:15:16.691735+00:00
[2021-08-28 02:15:16,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:15:46,811] {scheduler_job.py:182} INFO - Started process (PID=4716) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:46,811] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:15:46,812] {logging_mixin.py:104} INFO - [2021-08-28 02:15:46,812] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:46,896] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:15:46,904] {logging_mixin.py:104} INFO - [2021-08-28 02:15:46,904] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:15:46,913] {logging_mixin.py:104} INFO - [2021-08-28 02:15:46,913] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:15:46.913571+00:00
[2021-08-28 02:15:46,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:16:17,040] {scheduler_job.py:182} INFO - Started process (PID=4719) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:17,040] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:16:17,041] {logging_mixin.py:104} INFO - [2021-08-28 02:16:17,041] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:17,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:17,133] {logging_mixin.py:104} INFO - [2021-08-28 02:16:17,133] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:16:17,143] {logging_mixin.py:104} INFO - [2021-08-28 02:16:17,143] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:16:17.143288+00:00
[2021-08-28 02:16:17,149] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:16:47,260] {scheduler_job.py:182} INFO - Started process (PID=4722) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:47,261] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:16:47,261] {logging_mixin.py:104} INFO - [2021-08-28 02:16:47,261] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:47,346] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:16:47,353] {logging_mixin.py:104} INFO - [2021-08-28 02:16:47,353] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:16:47,363] {logging_mixin.py:104} INFO - [2021-08-28 02:16:47,363] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:16:47.362952+00:00
[2021-08-28 02:16:47,369] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:17:17,471] {scheduler_job.py:182} INFO - Started process (PID=4725) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:17,471] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:17:17,471] {logging_mixin.py:104} INFO - [2021-08-28 02:17:17,471] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:17,560] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:17,570] {logging_mixin.py:104} INFO - [2021-08-28 02:17:17,570] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:17:17,580] {logging_mixin.py:104} INFO - [2021-08-28 02:17:17,580] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:17:17.580125+00:00
[2021-08-28 02:17:17,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 02:17:47,713] {scheduler_job.py:182} INFO - Started process (PID=4728) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:47,714] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:17:47,714] {logging_mixin.py:104} INFO - [2021-08-28 02:17:47,714] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:47,801] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:17:47,809] {logging_mixin.py:104} INFO - [2021-08-28 02:17:47,809] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:17:47,818] {logging_mixin.py:104} INFO - [2021-08-28 02:17:47,818] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:17:47.818753+00:00
[2021-08-28 02:17:47,825] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:18:17,986] {scheduler_job.py:182} INFO - Started process (PID=4731) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:17,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:18:17,988] {logging_mixin.py:104} INFO - [2021-08-28 02:18:17,987] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:18,078] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:18,086] {logging_mixin.py:104} INFO - [2021-08-28 02:18:18,086] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:18:18,095] {logging_mixin.py:104} INFO - [2021-08-28 02:18:18,095] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:18:18.095642+00:00
[2021-08-28 02:18:18,102] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 02:18:48,186] {scheduler_job.py:182} INFO - Started process (PID=4734) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:48,187] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:18:48,187] {logging_mixin.py:104} INFO - [2021-08-28 02:18:48,187] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:48,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:18:48,304] {logging_mixin.py:104} INFO - [2021-08-28 02:18:48,304] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:18:48,316] {logging_mixin.py:104} INFO - [2021-08-28 02:18:48,316] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:18:48.316103+00:00
[2021-08-28 02:18:48,325] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-08-28 02:19:18,432] {scheduler_job.py:182} INFO - Started process (PID=4737) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:18,433] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:19:18,433] {logging_mixin.py:104} INFO - [2021-08-28 02:19:18,433] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:18,561] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:18,572] {logging_mixin.py:104} INFO - [2021-08-28 02:19:18,571] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:19:18,584] {logging_mixin.py:104} INFO - [2021-08-28 02:19:18,584] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:19:18.584003+00:00
[2021-08-28 02:19:18,591] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-08-28 02:19:48,720] {scheduler_job.py:182} INFO - Started process (PID=4740) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:48,721] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:19:48,721] {logging_mixin.py:104} INFO - [2021-08-28 02:19:48,721] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:48,835] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:19:48,846] {logging_mixin.py:104} INFO - [2021-08-28 02:19:48,845] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:19:48,861] {logging_mixin.py:104} INFO - [2021-08-28 02:19:48,861] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:19:48.861457+00:00
[2021-08-28 02:19:48,869] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-08-28 02:20:18,986] {scheduler_job.py:182} INFO - Started process (PID=4743) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:18,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:20:18,988] {logging_mixin.py:104} INFO - [2021-08-28 02:20:18,988] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:19,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:19,100] {logging_mixin.py:104} INFO - [2021-08-28 02:20:19,100] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:20:19,111] {logging_mixin.py:104} INFO - [2021-08-28 02:20:19,110] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:20:19.110811+00:00
[2021-08-28 02:20:19,117] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-08-28 02:20:49,190] {scheduler_job.py:182} INFO - Started process (PID=4746) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:49,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:20:49,191] {logging_mixin.py:104} INFO - [2021-08-28 02:20:49,191] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:49,276] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:20:49,283] {logging_mixin.py:104} INFO - [2021-08-28 02:20:49,283] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:20:49,293] {logging_mixin.py:104} INFO - [2021-08-28 02:20:49,293] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:20:49.292915+00:00
[2021-08-28 02:20:49,299] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:21:19,412] {scheduler_job.py:182} INFO - Started process (PID=4749) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:19,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:21:19,414] {logging_mixin.py:104} INFO - [2021-08-28 02:21:19,413] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:19,500] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:19,508] {logging_mixin.py:104} INFO - [2021-08-28 02:21:19,508] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:21:19,518] {logging_mixin.py:104} INFO - [2021-08-28 02:21:19,517] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:21:19.517862+00:00
[2021-08-28 02:21:19,524] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:21:49,638] {scheduler_job.py:182} INFO - Started process (PID=4752) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:49,638] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:21:49,639] {logging_mixin.py:104} INFO - [2021-08-28 02:21:49,639] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:49,725] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:21:49,732] {logging_mixin.py:104} INFO - [2021-08-28 02:21:49,732] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:21:49,741] {logging_mixin.py:104} INFO - [2021-08-28 02:21:49,741] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:21:49.741154+00:00
[2021-08-28 02:21:49,747] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:22:19,857] {scheduler_job.py:182} INFO - Started process (PID=4755) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:19,858] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:22:19,858] {logging_mixin.py:104} INFO - [2021-08-28 02:22:19,858] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:19,944] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:19,951] {logging_mixin.py:104} INFO - [2021-08-28 02:22:19,951] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:22:19,963] {logging_mixin.py:104} INFO - [2021-08-28 02:22:19,963] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:22:19.962962+00:00
[2021-08-28 02:22:19,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:22:50,072] {scheduler_job.py:182} INFO - Started process (PID=4758) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:50,073] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:22:50,073] {logging_mixin.py:104} INFO - [2021-08-28 02:22:50,073] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:50,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:22:50,168] {logging_mixin.py:104} INFO - [2021-08-28 02:22:50,168] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:22:50,178] {logging_mixin.py:104} INFO - [2021-08-28 02:22:50,178] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:22:50.178531+00:00
[2021-08-28 02:22:50,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:23:20,291] {scheduler_job.py:182} INFO - Started process (PID=4761) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:20,291] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:23:20,292] {logging_mixin.py:104} INFO - [2021-08-28 02:23:20,292] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:20,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:20,384] {logging_mixin.py:104} INFO - [2021-08-28 02:23:20,384] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:23:20,394] {logging_mixin.py:104} INFO - [2021-08-28 02:23:20,394] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:23:20.393907+00:00
[2021-08-28 02:23:20,400] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:23:50,508] {scheduler_job.py:182} INFO - Started process (PID=4764) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:50,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:23:50,508] {logging_mixin.py:104} INFO - [2021-08-28 02:23:50,508] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:50,595] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:23:50,602] {logging_mixin.py:104} INFO - [2021-08-28 02:23:50,602] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:23:50,612] {logging_mixin.py:104} INFO - [2021-08-28 02:23:50,612] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:23:50.612185+00:00
[2021-08-28 02:23:50,619] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:24:20,744] {scheduler_job.py:182} INFO - Started process (PID=4767) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:20,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:24:20,745] {logging_mixin.py:104} INFO - [2021-08-28 02:24:20,745] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:20,830] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:20,838] {logging_mixin.py:104} INFO - [2021-08-28 02:24:20,837] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:24:20,847] {logging_mixin.py:104} INFO - [2021-08-28 02:24:20,847] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:24:20.847442+00:00
[2021-08-28 02:24:20,853] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:24:50,976] {scheduler_job.py:182} INFO - Started process (PID=4770) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:50,977] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:24:50,977] {logging_mixin.py:104} INFO - [2021-08-28 02:24:50,977] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:51,062] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:24:51,069] {logging_mixin.py:104} INFO - [2021-08-28 02:24:51,069] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:24:51,079] {logging_mixin.py:104} INFO - [2021-08-28 02:24:51,079] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:24:51.079416+00:00
[2021-08-28 02:24:51,086] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:25:21,212] {scheduler_job.py:182} INFO - Started process (PID=4773) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:21,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:25:21,213] {logging_mixin.py:104} INFO - [2021-08-28 02:25:21,213] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:21,300] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:21,308] {logging_mixin.py:104} INFO - [2021-08-28 02:25:21,308] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:25:21,317] {logging_mixin.py:104} INFO - [2021-08-28 02:25:21,317] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:25:21.317690+00:00
[2021-08-28 02:25:21,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:25:51,439] {scheduler_job.py:182} INFO - Started process (PID=4776) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:51,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:25:51,440] {logging_mixin.py:104} INFO - [2021-08-28 02:25:51,440] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:51,525] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:25:51,532] {logging_mixin.py:104} INFO - [2021-08-28 02:25:51,532] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:25:51,541] {logging_mixin.py:104} INFO - [2021-08-28 02:25:51,541] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:25:51.541747+00:00
[2021-08-28 02:25:51,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:26:21,653] {scheduler_job.py:182} INFO - Started process (PID=4779) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:21,654] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:26:21,654] {logging_mixin.py:104} INFO - [2021-08-28 02:26:21,654] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:21,740] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:21,749] {logging_mixin.py:104} INFO - [2021-08-28 02:26:21,749] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:26:21,762] {logging_mixin.py:104} INFO - [2021-08-28 02:26:21,762] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:26:21.762709+00:00
[2021-08-28 02:26:21,770] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 02:26:51,879] {scheduler_job.py:182} INFO - Started process (PID=4782) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:51,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:26:51,880] {logging_mixin.py:104} INFO - [2021-08-28 02:26:51,880] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:51,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:26:51,973] {logging_mixin.py:104} INFO - [2021-08-28 02:26:51,973] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:26:51,982] {logging_mixin.py:104} INFO - [2021-08-28 02:26:51,982] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:26:51.982796+00:00
[2021-08-28 02:26:51,989] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:27:22,098] {scheduler_job.py:182} INFO - Started process (PID=4785) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:22,099] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:27:22,099] {logging_mixin.py:104} INFO - [2021-08-28 02:27:22,099] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:22,190] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:22,197] {logging_mixin.py:104} INFO - [2021-08-28 02:27:22,197] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:27:22,207] {logging_mixin.py:104} INFO - [2021-08-28 02:27:22,207] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:27:22.207398+00:00
[2021-08-28 02:27:22,213] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:27:52,328] {scheduler_job.py:182} INFO - Started process (PID=4788) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:52,328] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:27:52,329] {logging_mixin.py:104} INFO - [2021-08-28 02:27:52,328] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:52,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:27:52,422] {logging_mixin.py:104} INFO - [2021-08-28 02:27:52,422] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:27:52,433] {logging_mixin.py:104} INFO - [2021-08-28 02:27:52,433] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:27:52.433018+00:00
[2021-08-28 02:27:52,440] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:28:22,562] {scheduler_job.py:182} INFO - Started process (PID=4791) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:22,562] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:28:22,563] {logging_mixin.py:104} INFO - [2021-08-28 02:28:22,563] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:22,650] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:22,658] {logging_mixin.py:104} INFO - [2021-08-28 02:28:22,658] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:28:22,667] {logging_mixin.py:104} INFO - [2021-08-28 02:28:22,667] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:28:22.667544+00:00
[2021-08-28 02:28:22,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:28:52,778] {scheduler_job.py:182} INFO - Started process (PID=4794) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:52,779] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:28:52,779] {logging_mixin.py:104} INFO - [2021-08-28 02:28:52,779] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:52,865] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:28:52,872] {logging_mixin.py:104} INFO - [2021-08-28 02:28:52,872] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:28:52,881] {logging_mixin.py:104} INFO - [2021-08-28 02:28:52,881] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:28:52.881803+00:00
[2021-08-28 02:28:52,887] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:29:23,005] {scheduler_job.py:182} INFO - Started process (PID=4797) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:23,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:29:23,006] {logging_mixin.py:104} INFO - [2021-08-28 02:29:23,006] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:23,095] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:23,102] {logging_mixin.py:104} INFO - [2021-08-28 02:29:23,102] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:29:23,112] {logging_mixin.py:104} INFO - [2021-08-28 02:29:23,112] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:29:23.112355+00:00
[2021-08-28 02:29:23,119] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:29:53,234] {scheduler_job.py:182} INFO - Started process (PID=4800) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:53,234] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:29:53,235] {logging_mixin.py:104} INFO - [2021-08-28 02:29:53,235] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:53,319] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:29:53,326] {logging_mixin.py:104} INFO - [2021-08-28 02:29:53,326] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:29:53,336] {logging_mixin.py:104} INFO - [2021-08-28 02:29:53,336] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:29:53.336171+00:00
[2021-08-28 02:29:53,342] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:30:23,457] {scheduler_job.py:182} INFO - Started process (PID=4803) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:23,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:30:23,459] {logging_mixin.py:104} INFO - [2021-08-28 02:30:23,458] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:23,550] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:23,562] {logging_mixin.py:104} INFO - [2021-08-28 02:30:23,562] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:30:23,579] {logging_mixin.py:104} INFO - [2021-08-28 02:30:23,579] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:30:23.579272+00:00
[2021-08-28 02:30:23,589] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-08-28 02:30:53,722] {scheduler_job.py:182} INFO - Started process (PID=4806) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:53,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:30:53,723] {logging_mixin.py:104} INFO - [2021-08-28 02:30:53,723] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:53,807] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:30:53,814] {logging_mixin.py:104} INFO - [2021-08-28 02:30:53,814] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:30:53,823] {logging_mixin.py:104} INFO - [2021-08-28 02:30:53,823] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:30:53.823735+00:00
[2021-08-28 02:30:53,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:31:23,943] {scheduler_job.py:182} INFO - Started process (PID=4809) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:23,944] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:31:23,944] {logging_mixin.py:104} INFO - [2021-08-28 02:31:23,944] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:24,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:24,038] {logging_mixin.py:104} INFO - [2021-08-28 02:31:24,038] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:31:24,047] {logging_mixin.py:104} INFO - [2021-08-28 02:31:24,047] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:31:24.047707+00:00
[2021-08-28 02:31:24,055] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:31:54,165] {scheduler_job.py:182} INFO - Started process (PID=4812) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:54,166] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:31:54,166] {logging_mixin.py:104} INFO - [2021-08-28 02:31:54,166] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:54,252] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:31:54,259] {logging_mixin.py:104} INFO - [2021-08-28 02:31:54,259] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:31:54,268] {logging_mixin.py:104} INFO - [2021-08-28 02:31:54,268] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:31:54.268615+00:00
[2021-08-28 02:31:54,276] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:32:24,393] {scheduler_job.py:182} INFO - Started process (PID=4815) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:24,393] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:32:24,394] {logging_mixin.py:104} INFO - [2021-08-28 02:32:24,394] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:24,485] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:24,492] {logging_mixin.py:104} INFO - [2021-08-28 02:32:24,492] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:32:24,503] {logging_mixin.py:104} INFO - [2021-08-28 02:32:24,503] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:32:24.503184+00:00
[2021-08-28 02:32:24,509] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 02:32:54,609] {scheduler_job.py:182} INFO - Started process (PID=4818) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:54,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:32:54,610] {logging_mixin.py:104} INFO - [2021-08-28 02:32:54,610] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:54,697] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:32:54,705] {logging_mixin.py:104} INFO - [2021-08-28 02:32:54,705] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:32:54,716] {logging_mixin.py:104} INFO - [2021-08-28 02:32:54,715] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:32:54.715826+00:00
[2021-08-28 02:32:54,722] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:33:24,826] {scheduler_job.py:182} INFO - Started process (PID=4821) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:24,827] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:33:24,827] {logging_mixin.py:104} INFO - [2021-08-28 02:33:24,827] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:24,919] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:24,930] {logging_mixin.py:104} INFO - [2021-08-28 02:33:24,930] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:33:24,943] {logging_mixin.py:104} INFO - [2021-08-28 02:33:24,943] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:33:24.943592+00:00
[2021-08-28 02:33:24,952] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-08-28 02:33:55,076] {scheduler_job.py:182} INFO - Started process (PID=4824) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:55,076] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:33:55,077] {logging_mixin.py:104} INFO - [2021-08-28 02:33:55,077] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:55,172] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:33:55,183] {logging_mixin.py:104} INFO - [2021-08-28 02:33:55,183] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:33:55,196] {logging_mixin.py:104} INFO - [2021-08-28 02:33:55,196] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:33:55.196686+00:00
[2021-08-28 02:33:55,205] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-08-28 02:34:25,306] {scheduler_job.py:182} INFO - Started process (PID=4827) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:25,306] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:34:25,307] {logging_mixin.py:104} INFO - [2021-08-28 02:34:25,307] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:25,399] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:25,408] {logging_mixin.py:104} INFO - [2021-08-28 02:34:25,408] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:34:25,421] {logging_mixin.py:104} INFO - [2021-08-28 02:34:25,421] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:34:25.421336+00:00
[2021-08-28 02:34:25,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-28 02:34:55,553] {scheduler_job.py:182} INFO - Started process (PID=4830) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:55,554] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:34:55,554] {logging_mixin.py:104} INFO - [2021-08-28 02:34:55,554] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:55,644] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:34:55,652] {logging_mixin.py:104} INFO - [2021-08-28 02:34:55,652] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:34:55,665] {logging_mixin.py:104} INFO - [2021-08-28 02:34:55,665] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:34:55.665259+00:00
[2021-08-28 02:34:55,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 02:35:25,776] {scheduler_job.py:182} INFO - Started process (PID=4833) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:25,777] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:35:25,777] {logging_mixin.py:104} INFO - [2021-08-28 02:35:25,777] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:25,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:25,878] {logging_mixin.py:104} INFO - [2021-08-28 02:35:25,878] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:35:25,891] {logging_mixin.py:104} INFO - [2021-08-28 02:35:25,891] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:35:25.891166+00:00
[2021-08-28 02:35:25,902] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-28 02:35:56,003] {scheduler_job.py:182} INFO - Started process (PID=4836) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:56,003] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:35:56,004] {logging_mixin.py:104} INFO - [2021-08-28 02:35:56,004] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:56,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:35:56,104] {logging_mixin.py:104} INFO - [2021-08-28 02:35:56,104] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:35:56,114] {logging_mixin.py:104} INFO - [2021-08-28 02:35:56,114] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:35:56.114693+00:00
[2021-08-28 02:35:56,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 02:36:26,263] {scheduler_job.py:182} INFO - Started process (PID=4839) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:26,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:36:26,265] {logging_mixin.py:104} INFO - [2021-08-28 02:36:26,264] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:26,381] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:26,392] {logging_mixin.py:104} INFO - [2021-08-28 02:36:26,392] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:36:26,404] {logging_mixin.py:104} INFO - [2021-08-28 02:36:26,404] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:36:26.404560+00:00
[2021-08-28 02:36:26,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-08-28 02:36:56,507] {scheduler_job.py:182} INFO - Started process (PID=4842) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:56,508] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:36:56,508] {logging_mixin.py:104} INFO - [2021-08-28 02:36:56,508] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:56,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:36:56,610] {logging_mixin.py:104} INFO - [2021-08-28 02:36:56,610] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:36:56,620] {logging_mixin.py:104} INFO - [2021-08-28 02:36:56,620] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:36:56.620268+00:00
[2021-08-28 02:36:56,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-28 02:37:26,740] {scheduler_job.py:182} INFO - Started process (PID=4845) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:26,741] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:37:26,741] {logging_mixin.py:104} INFO - [2021-08-28 02:37:26,741] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:26,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:26,836] {logging_mixin.py:104} INFO - [2021-08-28 02:37:26,836] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:37:26,846] {logging_mixin.py:104} INFO - [2021-08-28 02:37:26,846] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:37:26.846069+00:00
[2021-08-28 02:37:26,852] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:37:56,968] {scheduler_job.py:182} INFO - Started process (PID=4848) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:56,969] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:37:56,969] {logging_mixin.py:104} INFO - [2021-08-28 02:37:56,969] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:57,054] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:37:57,062] {logging_mixin.py:104} INFO - [2021-08-28 02:37:57,062] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:37:57,071] {logging_mixin.py:104} INFO - [2021-08-28 02:37:57,071] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:37:57.071259+00:00
[2021-08-28 02:37:57,077] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:38:27,196] {scheduler_job.py:182} INFO - Started process (PID=4851) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:27,197] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:38:27,197] {logging_mixin.py:104} INFO - [2021-08-28 02:38:27,197] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:27,282] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:27,289] {logging_mixin.py:104} INFO - [2021-08-28 02:38:27,289] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:38:27,299] {logging_mixin.py:104} INFO - [2021-08-28 02:38:27,298] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:38:27.298828+00:00
[2021-08-28 02:38:27,306] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:38:57,422] {scheduler_job.py:182} INFO - Started process (PID=4854) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:57,423] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:38:57,423] {logging_mixin.py:104} INFO - [2021-08-28 02:38:57,423] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:57,508] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:38:57,515] {logging_mixin.py:104} INFO - [2021-08-28 02:38:57,515] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:38:57,525] {logging_mixin.py:104} INFO - [2021-08-28 02:38:57,525] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:38:57.524998+00:00
[2021-08-28 02:38:57,532] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:39:27,649] {scheduler_job.py:182} INFO - Started process (PID=4857) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:27,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:39:27,650] {logging_mixin.py:104} INFO - [2021-08-28 02:39:27,650] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:27,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:27,744] {logging_mixin.py:104} INFO - [2021-08-28 02:39:27,744] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:39:27,756] {logging_mixin.py:104} INFO - [2021-08-28 02:39:27,756] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:39:27.756205+00:00
[2021-08-28 02:39:27,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:39:57,891] {scheduler_job.py:182} INFO - Started process (PID=4860) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:57,891] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:39:57,892] {logging_mixin.py:104} INFO - [2021-08-28 02:39:57,892] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:57,977] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:39:57,985] {logging_mixin.py:104} INFO - [2021-08-28 02:39:57,984] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:39:57,994] {logging_mixin.py:104} INFO - [2021-08-28 02:39:57,994] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:39:57.994468+00:00
[2021-08-28 02:39:58,000] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:40:28,110] {scheduler_job.py:182} INFO - Started process (PID=4863) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:28,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:40:28,111] {logging_mixin.py:104} INFO - [2021-08-28 02:40:28,111] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:28,198] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:28,207] {logging_mixin.py:104} INFO - [2021-08-28 02:40:28,207] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:40:28,218] {logging_mixin.py:104} INFO - [2021-08-28 02:40:28,218] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:40:28.218538+00:00
[2021-08-28 02:40:28,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:40:58,332] {scheduler_job.py:182} INFO - Started process (PID=4866) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:58,332] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:40:58,333] {logging_mixin.py:104} INFO - [2021-08-28 02:40:58,332] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:58,419] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:40:58,427] {logging_mixin.py:104} INFO - [2021-08-28 02:40:58,426] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:40:58,436] {logging_mixin.py:104} INFO - [2021-08-28 02:40:58,436] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:40:58.436298+00:00
[2021-08-28 02:40:58,443] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:41:28,566] {scheduler_job.py:182} INFO - Started process (PID=4869) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:28,567] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:41:28,567] {logging_mixin.py:104} INFO - [2021-08-28 02:41:28,567] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:28,656] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:28,666] {logging_mixin.py:104} INFO - [2021-08-28 02:41:28,666] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:41:28,677] {logging_mixin.py:104} INFO - [2021-08-28 02:41:28,677] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:41:28.677061+00:00
[2021-08-28 02:41:28,684] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 02:41:58,795] {scheduler_job.py:182} INFO - Started process (PID=4872) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:58,796] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:41:58,797] {logging_mixin.py:104} INFO - [2021-08-28 02:41:58,797] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:58,882] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:41:58,889] {logging_mixin.py:104} INFO - [2021-08-28 02:41:58,889] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:41:58,899] {logging_mixin.py:104} INFO - [2021-08-28 02:41:58,899] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:41:58.899376+00:00
[2021-08-28 02:41:58,906] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:42:29,014] {scheduler_job.py:182} INFO - Started process (PID=4875) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:29,015] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:42:29,015] {logging_mixin.py:104} INFO - [2021-08-28 02:42:29,015] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:29,100] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:29,107] {logging_mixin.py:104} INFO - [2021-08-28 02:42:29,107] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:42:29,116] {logging_mixin.py:104} INFO - [2021-08-28 02:42:29,116] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:42:29.116690+00:00
[2021-08-28 02:42:29,123] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:42:59,237] {scheduler_job.py:182} INFO - Started process (PID=4878) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:59,237] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:42:59,238] {logging_mixin.py:104} INFO - [2021-08-28 02:42:59,238] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:59,323] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:42:59,330] {logging_mixin.py:104} INFO - [2021-08-28 02:42:59,330] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:42:59,339] {logging_mixin.py:104} INFO - [2021-08-28 02:42:59,339] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:42:59.339640+00:00
[2021-08-28 02:42:59,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:43:29,463] {scheduler_job.py:182} INFO - Started process (PID=4881) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:29,463] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:43:29,464] {logging_mixin.py:104} INFO - [2021-08-28 02:43:29,464] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:29,549] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:29,557] {logging_mixin.py:104} INFO - [2021-08-28 02:43:29,557] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:43:29,568] {logging_mixin.py:104} INFO - [2021-08-28 02:43:29,568] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:43:29.568456+00:00
[2021-08-28 02:43:29,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:43:59,684] {scheduler_job.py:182} INFO - Started process (PID=4884) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:59,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:43:59,685] {logging_mixin.py:104} INFO - [2021-08-28 02:43:59,685] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:59,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:43:59,778] {logging_mixin.py:104} INFO - [2021-08-28 02:43:59,778] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:43:59,787] {logging_mixin.py:104} INFO - [2021-08-28 02:43:59,787] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:43:59.787438+00:00
[2021-08-28 02:43:59,793] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:44:29,902] {scheduler_job.py:182} INFO - Started process (PID=4887) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:44:29,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:44:29,903] {logging_mixin.py:104} INFO - [2021-08-28 02:44:29,903] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:44:29,989] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:44:29,996] {logging_mixin.py:104} INFO - [2021-08-28 02:44:29,996] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:44:30,006] {logging_mixin.py:104} INFO - [2021-08-28 02:44:30,006] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:44:30.006231+00:00
[2021-08-28 02:44:30,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:45:00,128] {scheduler_job.py:182} INFO - Started process (PID=4890) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:00,129] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:45:00,129] {logging_mixin.py:104} INFO - [2021-08-28 02:45:00,129] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:00,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:00,224] {logging_mixin.py:104} INFO - [2021-08-28 02:45:00,224] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:45:00,234] {logging_mixin.py:104} INFO - [2021-08-28 02:45:00,234] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:45:00.234287+00:00
[2021-08-28 02:45:00,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:45:30,364] {scheduler_job.py:182} INFO - Started process (PID=4893) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:30,365] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:45:30,366] {logging_mixin.py:104} INFO - [2021-08-28 02:45:30,366] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:30,452] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:45:30,459] {logging_mixin.py:104} INFO - [2021-08-28 02:45:30,459] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:45:30,469] {logging_mixin.py:104} INFO - [2021-08-28 02:45:30,468] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:45:30.468815+00:00
[2021-08-28 02:45:30,475] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:46:00,587] {scheduler_job.py:182} INFO - Started process (PID=4896) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:00,588] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:46:00,588] {logging_mixin.py:104} INFO - [2021-08-28 02:46:00,588] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:00,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:00,687] {logging_mixin.py:104} INFO - [2021-08-28 02:46:00,687] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:46:00,698] {logging_mixin.py:104} INFO - [2021-08-28 02:46:00,698] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:46:00.698334+00:00
[2021-08-28 02:46:00,705] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 02:46:30,816] {scheduler_job.py:182} INFO - Started process (PID=4899) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:30,816] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:46:30,817] {logging_mixin.py:104} INFO - [2021-08-28 02:46:30,817] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:30,903] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:46:30,912] {logging_mixin.py:104} INFO - [2021-08-28 02:46:30,912] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:46:30,922] {logging_mixin.py:104} INFO - [2021-08-28 02:46:30,922] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:46:30.922296+00:00
[2021-08-28 02:46:30,928] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 02:47:01,026] {scheduler_job.py:182} INFO - Started process (PID=4902) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:01,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:47:01,027] {logging_mixin.py:104} INFO - [2021-08-28 02:47:01,027] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:01,112] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:01,120] {logging_mixin.py:104} INFO - [2021-08-28 02:47:01,120] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:47:01,129] {logging_mixin.py:104} INFO - [2021-08-28 02:47:01,129] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:47:01.129624+00:00
[2021-08-28 02:47:01,136] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:47:31,238] {scheduler_job.py:182} INFO - Started process (PID=4905) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:31,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:47:31,239] {logging_mixin.py:104} INFO - [2021-08-28 02:47:31,239] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:31,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:47:31,331] {logging_mixin.py:104} INFO - [2021-08-28 02:47:31,331] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:47:31,340] {logging_mixin.py:104} INFO - [2021-08-28 02:47:31,340] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:47:31.340603+00:00
[2021-08-28 02:47:31,346] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:48:01,448] {scheduler_job.py:182} INFO - Started process (PID=4908) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:01,449] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:48:01,449] {logging_mixin.py:104} INFO - [2021-08-28 02:48:01,449] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:01,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:01,542] {logging_mixin.py:104} INFO - [2021-08-28 02:48:01,542] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:48:01,552] {logging_mixin.py:104} INFO - [2021-08-28 02:48:01,551] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:48:01.551812+00:00
[2021-08-28 02:48:01,558] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:48:31,670] {scheduler_job.py:182} INFO - Started process (PID=4911) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:31,670] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:48:31,671] {logging_mixin.py:104} INFO - [2021-08-28 02:48:31,671] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:31,758] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:48:31,766] {logging_mixin.py:104} INFO - [2021-08-28 02:48:31,766] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:48:31,778] {logging_mixin.py:104} INFO - [2021-08-28 02:48:31,778] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:48:31.778453+00:00
[2021-08-28 02:48:31,785] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:49:01,893] {scheduler_job.py:182} INFO - Started process (PID=4914) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:01,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:49:01,894] {logging_mixin.py:104} INFO - [2021-08-28 02:49:01,894] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:01,979] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:01,987] {logging_mixin.py:104} INFO - [2021-08-28 02:49:01,987] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:49:01,996] {logging_mixin.py:104} INFO - [2021-08-28 02:49:01,996] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:49:01.996677+00:00
[2021-08-28 02:49:02,003] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:49:32,109] {scheduler_job.py:182} INFO - Started process (PID=4917) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:32,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:49:32,110] {logging_mixin.py:104} INFO - [2021-08-28 02:49:32,110] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:32,196] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:49:32,204] {logging_mixin.py:104} INFO - [2021-08-28 02:49:32,204] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:49:32,213] {logging_mixin.py:104} INFO - [2021-08-28 02:49:32,213] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:49:32.213567+00:00
[2021-08-28 02:49:32,220] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:50:02,347] {scheduler_job.py:182} INFO - Started process (PID=4920) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:02,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:50:02,348] {logging_mixin.py:104} INFO - [2021-08-28 02:50:02,348] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:02,434] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:02,441] {logging_mixin.py:104} INFO - [2021-08-28 02:50:02,441] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:50:02,451] {logging_mixin.py:104} INFO - [2021-08-28 02:50:02,450] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:50:02.450835+00:00
[2021-08-28 02:50:02,457] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:50:32,558] {scheduler_job.py:182} INFO - Started process (PID=4923) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:32,559] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:50:32,559] {logging_mixin.py:104} INFO - [2021-08-28 02:50:32,559] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:32,647] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:50:32,656] {logging_mixin.py:104} INFO - [2021-08-28 02:50:32,656] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:50:32,668] {logging_mixin.py:104} INFO - [2021-08-28 02:50:32,667] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:50:32.667786+00:00
[2021-08-28 02:50:32,674] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:51:02,785] {scheduler_job.py:182} INFO - Started process (PID=4926) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:02,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:51:02,786] {logging_mixin.py:104} INFO - [2021-08-28 02:51:02,786] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:02,872] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:02,879] {logging_mixin.py:104} INFO - [2021-08-28 02:51:02,879] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:51:02,888] {logging_mixin.py:104} INFO - [2021-08-28 02:51:02,888] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:51:02.888124+00:00
[2021-08-28 02:51:02,894] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 02:51:33,010] {scheduler_job.py:182} INFO - Started process (PID=4929) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:33,011] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:51:33,012] {logging_mixin.py:104} INFO - [2021-08-28 02:51:33,011] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:33,097] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:51:33,105] {logging_mixin.py:104} INFO - [2021-08-28 02:51:33,105] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:51:33,114] {logging_mixin.py:104} INFO - [2021-08-28 02:51:33,114] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:51:33.114808+00:00
[2021-08-28 02:51:33,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:52:03,238] {scheduler_job.py:182} INFO - Started process (PID=4932) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:03,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:52:03,239] {logging_mixin.py:104} INFO - [2021-08-28 02:52:03,239] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:03,324] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:03,332] {logging_mixin.py:104} INFO - [2021-08-28 02:52:03,332] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:52:03,341] {logging_mixin.py:104} INFO - [2021-08-28 02:52:03,341] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:52:03.341373+00:00
[2021-08-28 02:52:03,348] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:52:33,458] {scheduler_job.py:182} INFO - Started process (PID=4935) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:33,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:52:33,459] {logging_mixin.py:104} INFO - [2021-08-28 02:52:33,459] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:33,543] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:52:33,550] {logging_mixin.py:104} INFO - [2021-08-28 02:52:33,550] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:52:33,559] {logging_mixin.py:104} INFO - [2021-08-28 02:52:33,559] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:52:33.559617+00:00
[2021-08-28 02:52:33,565] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-08-28 02:53:03,680] {scheduler_job.py:182} INFO - Started process (PID=4938) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:03,680] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:53:03,681] {logging_mixin.py:104} INFO - [2021-08-28 02:53:03,681] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:03,766] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:03,773] {logging_mixin.py:104} INFO - [2021-08-28 02:53:03,773] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:53:03,783] {logging_mixin.py:104} INFO - [2021-08-28 02:53:03,783] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:53:03.782969+00:00
[2021-08-28 02:53:03,789] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:53:33,903] {scheduler_job.py:182} INFO - Started process (PID=4941) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:33,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:53:33,904] {logging_mixin.py:104} INFO - [2021-08-28 02:53:33,904] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:33,992] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:53:34,000] {logging_mixin.py:104} INFO - [2021-08-28 02:53:34,000] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:53:34,011] {logging_mixin.py:104} INFO - [2021-08-28 02:53:34,011] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:53:34.011240+00:00
[2021-08-28 02:53:34,017] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.117 seconds
[2021-08-28 02:54:04,130] {scheduler_job.py:182} INFO - Started process (PID=4944) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:04,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:54:04,131] {logging_mixin.py:104} INFO - [2021-08-28 02:54:04,131] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:04,217] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:04,225] {logging_mixin.py:104} INFO - [2021-08-28 02:54:04,224] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:54:04,234] {logging_mixin.py:104} INFO - [2021-08-28 02:54:04,234] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:54:04.234565+00:00
[2021-08-28 02:54:04,243] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 02:54:34,352] {scheduler_job.py:182} INFO - Started process (PID=4947) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:34,353] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:54:34,353] {logging_mixin.py:104} INFO - [2021-08-28 02:54:34,353] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:34,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:54:34,449] {logging_mixin.py:104} INFO - [2021-08-28 02:54:34,449] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:54:34,462] {logging_mixin.py:104} INFO - [2021-08-28 02:54:34,462] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:54:34.462096+00:00
[2021-08-28 02:54:34,469] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 02:55:04,609] {scheduler_job.py:182} INFO - Started process (PID=4950) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:04,610] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:55:04,610] {logging_mixin.py:104} INFO - [2021-08-28 02:55:04,610] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:04,695] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:04,702] {logging_mixin.py:104} INFO - [2021-08-28 02:55:04,702] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:55:04,712] {logging_mixin.py:104} INFO - [2021-08-28 02:55:04,712] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:55:04.711937+00:00
[2021-08-28 02:55:04,718] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:55:34,835] {scheduler_job.py:182} INFO - Started process (PID=4953) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:34,836] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:55:34,836] {logging_mixin.py:104} INFO - [2021-08-28 02:55:34,836] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:34,921] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:55:34,928] {logging_mixin.py:104} INFO - [2021-08-28 02:55:34,928] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:55:34,938] {logging_mixin.py:104} INFO - [2021-08-28 02:55:34,938] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:55:34.938434+00:00
[2021-08-28 02:55:34,944] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:56:05,071] {scheduler_job.py:182} INFO - Started process (PID=4956) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:05,072] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:56:05,072] {logging_mixin.py:104} INFO - [2021-08-28 02:56:05,072] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:05,161] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:05,171] {logging_mixin.py:104} INFO - [2021-08-28 02:56:05,171] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:56:05,181] {logging_mixin.py:104} INFO - [2021-08-28 02:56:05,181] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:56:05.181304+00:00
[2021-08-28 02:56:05,187] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-28 02:56:35,287] {scheduler_job.py:182} INFO - Started process (PID=4959) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:35,287] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:56:35,288] {logging_mixin.py:104} INFO - [2021-08-28 02:56:35,288] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:35,372] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:56:35,379] {logging_mixin.py:104} INFO - [2021-08-28 02:56:35,379] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:56:35,389] {logging_mixin.py:104} INFO - [2021-08-28 02:56:35,389] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:56:35.389369+00:00
[2021-08-28 02:56:35,395] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:57:05,511] {scheduler_job.py:182} INFO - Started process (PID=4962) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:05,512] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:57:05,513] {logging_mixin.py:104} INFO - [2021-08-28 02:57:05,513] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:05,599] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:05,606] {logging_mixin.py:104} INFO - [2021-08-28 02:57:05,606] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:57:05,615] {logging_mixin.py:104} INFO - [2021-08-28 02:57:05,615] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:57:05.615793+00:00
[2021-08-28 02:57:05,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:57:35,741] {scheduler_job.py:182} INFO - Started process (PID=4965) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:35,742] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:57:35,742] {logging_mixin.py:104} INFO - [2021-08-28 02:57:35,742] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:35,828] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:57:35,836] {logging_mixin.py:104} INFO - [2021-08-28 02:57:35,835] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:57:35,845] {logging_mixin.py:104} INFO - [2021-08-28 02:57:35,845] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:57:35.845647+00:00
[2021-08-28 02:57:35,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 02:58:05,955] {scheduler_job.py:182} INFO - Started process (PID=4968) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:05,955] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:58:05,956] {logging_mixin.py:104} INFO - [2021-08-28 02:58:05,956] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:06,041] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:06,049] {logging_mixin.py:104} INFO - [2021-08-28 02:58:06,049] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:58:06,058] {logging_mixin.py:104} INFO - [2021-08-28 02:58:06,058] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:58:06.058716+00:00
[2021-08-28 02:58:06,065] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 02:58:36,177] {scheduler_job.py:182} INFO - Started process (PID=4971) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:36,178] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:58:36,178] {logging_mixin.py:104} INFO - [2021-08-28 02:58:36,178] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:36,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:58:36,269] {logging_mixin.py:104} INFO - [2021-08-28 02:58:36,269] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:58:36,279] {logging_mixin.py:104} INFO - [2021-08-28 02:58:36,279] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:58:36.279410+00:00
[2021-08-28 02:58:36,286] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 02:59:06,397] {scheduler_job.py:182} INFO - Started process (PID=4974) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:06,398] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:59:06,398] {logging_mixin.py:104} INFO - [2021-08-28 02:59:06,398] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:06,483] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:06,491] {logging_mixin.py:104} INFO - [2021-08-28 02:59:06,491] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:59:06,505] {logging_mixin.py:104} INFO - [2021-08-28 02:59:06,504] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:59:06.504744+00:00
[2021-08-28 02:59:06,511] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 02:59:36,629] {scheduler_job.py:182} INFO - Started process (PID=4977) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:36,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 02:59:36,630] {logging_mixin.py:104} INFO - [2021-08-28 02:59:36,630] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:36,715] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 02:59:36,722] {logging_mixin.py:104} INFO - [2021-08-28 02:59:36,722] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 02:59:36,732] {logging_mixin.py:104} INFO - [2021-08-28 02:59:36,732] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 02:59:36.731976+00:00
[2021-08-28 02:59:36,738] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.111 seconds
[2021-08-28 03:00:06,865] {scheduler_job.py:182} INFO - Started process (PID=4980) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:06,866] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:00:06,866] {logging_mixin.py:104} INFO - [2021-08-28 03:00:06,866] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:06,960] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:06,968] {logging_mixin.py:104} INFO - [2021-08-28 03:00:06,968] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:00:06,978] {logging_mixin.py:104} INFO - [2021-08-28 03:00:06,977] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:00:06.977862+00:00
[2021-08-28 03:00:06,984] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 03:00:37,089] {scheduler_job.py:182} INFO - Started process (PID=4983) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:37,090] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:00:37,090] {logging_mixin.py:104} INFO - [2021-08-28 03:00:37,090] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:37,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:00:37,184] {logging_mixin.py:104} INFO - [2021-08-28 03:00:37,183] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:00:37,193] {logging_mixin.py:104} INFO - [2021-08-28 03:00:37,193] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:00:37.193661+00:00
[2021-08-28 03:00:37,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 03:01:07,315] {scheduler_job.py:182} INFO - Started process (PID=4986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:07,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:01:07,316] {logging_mixin.py:104} INFO - [2021-08-28 03:01:07,316] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:07,403] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:07,412] {logging_mixin.py:104} INFO - [2021-08-28 03:01:07,412] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:01:07,422] {logging_mixin.py:104} INFO - [2021-08-28 03:01:07,422] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:01:07.422785+00:00
[2021-08-28 03:01:07,429] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 03:01:37,564] {scheduler_job.py:182} INFO - Started process (PID=4989) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:37,565] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:01:37,565] {logging_mixin.py:104} INFO - [2021-08-28 03:01:37,565] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:37,663] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:01:37,670] {logging_mixin.py:104} INFO - [2021-08-28 03:01:37,670] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:01:37,680] {logging_mixin.py:104} INFO - [2021-08-28 03:01:37,680] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:01:37.680396+00:00
[2021-08-28 03:01:37,687] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.125 seconds
[2021-08-28 03:02:07,761] {scheduler_job.py:182} INFO - Started process (PID=4992) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:07,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:02:07,762] {logging_mixin.py:104} INFO - [2021-08-28 03:02:07,762] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:07,849] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:07,858] {logging_mixin.py:104} INFO - [2021-08-28 03:02:07,858] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:02:07,870] {logging_mixin.py:104} INFO - [2021-08-28 03:02:07,870] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:02:07.870333+00:00
[2021-08-28 03:02:07,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-28 03:02:37,985] {scheduler_job.py:182} INFO - Started process (PID=4995) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:37,986] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:02:37,986] {logging_mixin.py:104} INFO - [2021-08-28 03:02:37,986] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:38,075] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:02:38,082] {logging_mixin.py:104} INFO - [2021-08-28 03:02:38,082] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:02:38,092] {logging_mixin.py:104} INFO - [2021-08-28 03:02:38,092] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:02:38.092584+00:00
[2021-08-28 03:02:38,099] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.116 seconds
[2021-08-28 03:03:08,208] {scheduler_job.py:182} INFO - Started process (PID=4998) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:08,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:03:08,209] {logging_mixin.py:104} INFO - [2021-08-28 03:03:08,209] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:08,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:08,302] {logging_mixin.py:104} INFO - [2021-08-28 03:03:08,302] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:03:08,312] {logging_mixin.py:104} INFO - [2021-08-28 03:03:08,312] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:03:08.312467+00:00
[2021-08-28 03:03:08,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 03:03:38,423] {scheduler_job.py:182} INFO - Started process (PID=5001) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:38,424] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:03:38,424] {logging_mixin.py:104} INFO - [2021-08-28 03:03:38,424] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:38,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:03:38,518] {logging_mixin.py:104} INFO - [2021-08-28 03:03:38,518] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:03:38,529] {logging_mixin.py:104} INFO - [2021-08-28 03:03:38,529] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:03:38.529469+00:00
[2021-08-28 03:03:38,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.115 seconds
[2021-08-28 03:04:08,661] {scheduler_job.py:182} INFO - Started process (PID=5004) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:08,662] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:04:08,662] {logging_mixin.py:104} INFO - [2021-08-28 03:04:08,662] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:08,749] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:08,758] {logging_mixin.py:104} INFO - [2021-08-28 03:04:08,758] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:04:08,771] {logging_mixin.py:104} INFO - [2021-08-28 03:04:08,771] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:04:08.771175+00:00
[2021-08-28 03:04:08,779] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-28 03:04:38,907] {scheduler_job.py:182} INFO - Started process (PID=5007) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:38,908] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:04:38,908] {logging_mixin.py:104} INFO - [2021-08-28 03:04:38,908] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:38,996] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:04:39,004] {logging_mixin.py:104} INFO - [2021-08-28 03:04:39,004] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:04:39,016] {logging_mixin.py:104} INFO - [2021-08-28 03:04:39,016] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:04:39.016646+00:00
[2021-08-28 03:04:39,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-28 03:05:09,136] {scheduler_job.py:182} INFO - Started process (PID=5010) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:09,137] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:05:09,137] {logging_mixin.py:104} INFO - [2021-08-28 03:05:09,137] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:09,223] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:09,230] {logging_mixin.py:104} INFO - [2021-08-28 03:05:09,230] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:05:09,240] {logging_mixin.py:104} INFO - [2021-08-28 03:05:09,240] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:05:09.240756+00:00
[2021-08-28 03:05:09,247] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 03:05:39,358] {scheduler_job.py:182} INFO - Started process (PID=5013) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:39,359] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:05:39,359] {logging_mixin.py:104} INFO - [2021-08-28 03:05:39,359] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:39,444] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:05:39,452] {logging_mixin.py:104} INFO - [2021-08-28 03:05:39,452] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:05:39,461] {logging_mixin.py:104} INFO - [2021-08-28 03:05:39,461] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:05:39.461027+00:00
[2021-08-28 03:05:39,466] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-28 03:06:09,580] {scheduler_job.py:182} INFO - Started process (PID=5016) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:09,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:06:09,581] {logging_mixin.py:104} INFO - [2021-08-28 03:06:09,581] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:09,667] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:09,675] {logging_mixin.py:104} INFO - [2021-08-28 03:06:09,675] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:06:09,685] {logging_mixin.py:104} INFO - [2021-08-28 03:06:09,684] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:06:09.684847+00:00
[2021-08-28 03:06:09,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 03:06:39,802] {scheduler_job.py:182} INFO - Started process (PID=5019) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:39,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:06:39,803] {logging_mixin.py:104} INFO - [2021-08-28 03:06:39,803] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:39,890] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:06:39,898] {logging_mixin.py:104} INFO - [2021-08-28 03:06:39,898] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:06:39,907] {logging_mixin.py:104} INFO - [2021-08-28 03:06:39,907] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:06:39.907720+00:00
[2021-08-28 03:06:39,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 03:07:10,043] {scheduler_job.py:182} INFO - Started process (PID=5022) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:10,044] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:07:10,045] {logging_mixin.py:104} INFO - [2021-08-28 03:07:10,045] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:10,130] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:10,138] {logging_mixin.py:104} INFO - [2021-08-28 03:07:10,138] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:07:10,148] {logging_mixin.py:104} INFO - [2021-08-28 03:07:10,148] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:07:10.148437+00:00
[2021-08-28 03:07:10,155] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.113 seconds
[2021-08-28 03:07:40,257] {scheduler_job.py:182} INFO - Started process (PID=5025) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:40,258] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:07:40,258] {logging_mixin.py:104} INFO - [2021-08-28 03:07:40,258] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:40,358] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:07:40,369] {logging_mixin.py:104} INFO - [2021-08-28 03:07:40,368] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:07:40,380] {logging_mixin.py:104} INFO - [2021-08-28 03:07:40,380] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:07:40.380470+00:00
[2021-08-28 03:07:40,386] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.131 seconds
[2021-08-28 03:08:10,493] {scheduler_job.py:182} INFO - Started process (PID=5028) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:10,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:08:10,494] {logging_mixin.py:104} INFO - [2021-08-28 03:08:10,494] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:10,579] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:10,587] {logging_mixin.py:104} INFO - [2021-08-28 03:08:10,587] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:08:10,598] {logging_mixin.py:104} INFO - [2021-08-28 03:08:10,598] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:08:10.598430+00:00
[2021-08-28 03:08:10,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
[2021-08-28 03:08:40,716] {scheduler_job.py:182} INFO - Started process (PID=5031) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:40,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:08:40,717] {logging_mixin.py:104} INFO - [2021-08-28 03:08:40,717] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:40,802] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:08:40,810] {logging_mixin.py:104} INFO - [2021-08-28 03:08:40,810] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:08:40,819] {logging_mixin.py:104} INFO - [2021-08-28 03:08:40,819] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:08:40.819600+00:00
[2021-08-28 03:08:40,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.112 seconds
[2021-08-28 03:09:10,935] {scheduler_job.py:182} INFO - Started process (PID=5034) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:09:10,935] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-28 03:09:10,936] {logging_mixin.py:104} INFO - [2021-08-28 03:09:10,936] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:09:11,022] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-28 03:09:11,030] {logging_mixin.py:104} INFO - [2021-08-28 03:09:11,030] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-28 03:09:11,040] {logging_mixin.py:104} INFO - [2021-08-28 03:09:11,040] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-27 03:09:11.039939+00:00
[2021-08-28 03:09:11,047] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.114 seconds
