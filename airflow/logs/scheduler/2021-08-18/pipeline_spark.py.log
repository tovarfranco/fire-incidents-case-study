[2021-08-18 15:31:29,179] {scheduler_job.py:182} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:31:29,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:31:29,181] {logging_mixin.py:104} INFO - [2021-08-18 15:31:29,181] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:31:29,767] {logging_mixin.py:104} INFO - [2021-08-18 15:31:29,766] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:31:29,768] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:31:29,787] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.611 seconds
[2021-08-18 15:31:59,903] {scheduler_job.py:182} INFO - Started process (PID=34) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:31:59,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:31:59,905] {logging_mixin.py:104} INFO - [2021-08-18 15:31:59,905] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:32:00,013] {logging_mixin.py:104} INFO - [2021-08-18 15:32:00,011] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:32:00,013] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:32:00,019] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-18 15:32:30,072] {scheduler_job.py:182} INFO - Started process (PID=36) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:32:30,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:32:30,075] {logging_mixin.py:104} INFO - [2021-08-18 15:32:30,074] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:32:30,188] {logging_mixin.py:104} INFO - [2021-08-18 15:32:30,187] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:32:30,189] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:32:30,197] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-18 15:33:00,300] {scheduler_job.py:182} INFO - Started process (PID=38) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:00,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:33:00,303] {logging_mixin.py:104} INFO - [2021-08-18 15:33:00,302] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:00,400] {logging_mixin.py:104} INFO - [2021-08-18 15:33:00,399] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:33:00,401] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:00,406] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.110 seconds
[2021-08-18 15:33:30,466] {scheduler_job.py:182} INFO - Started process (PID=40) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:30,467] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:33:30,468] {logging_mixin.py:104} INFO - [2021-08-18 15:33:30,467] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:30,554] {logging_mixin.py:104} INFO - [2021-08-18 15:33:30,553] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:33:30,555] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:33:30,560] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.097 seconds
[2021-08-18 15:34:00,649] {scheduler_job.py:182} INFO - Started process (PID=42) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:00,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:34:00,651] {logging_mixin.py:104} INFO - [2021-08-18 15:34:00,651] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:00,750] {logging_mixin.py:104} INFO - [2021-08-18 15:34:00,749] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:34:00,750] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:00,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-08-18 15:34:30,809] {scheduler_job.py:182} INFO - Started process (PID=44) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:30,810] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:34:30,812] {logging_mixin.py:104} INFO - [2021-08-18 15:34:30,811] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:30,934] {logging_mixin.py:104} INFO - [2021-08-18 15:34:30,933] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:34:30,934] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:34:30,940] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-08-18 15:35:01,000] {scheduler_job.py:182} INFO - Started process (PID=46) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:01,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:35:01,002] {logging_mixin.py:104} INFO - [2021-08-18 15:35:01,002] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:01,097] {logging_mixin.py:104} INFO - [2021-08-18 15:35:01,096] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:35:01,097] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:01,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.107 seconds
[2021-08-18 15:35:31,170] {scheduler_job.py:182} INFO - Started process (PID=48) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:31,172] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:35:31,173] {logging_mixin.py:104} INFO - [2021-08-18 15:35:31,173] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:31,269] {logging_mixin.py:104} INFO - [2021-08-18 15:35:31,269] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:35:31,270] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:35:31,275] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.109 seconds
[2021-08-18 15:36:01,335] {scheduler_job.py:182} INFO - Started process (PID=50) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:01,337] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:36:01,338] {logging_mixin.py:104} INFO - [2021-08-18 15:36:01,338] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:01,445] {logging_mixin.py:104} INFO - [2021-08-18 15:36:01,445] {dagbag.py:308} ERROR - Failed to import: /opt/airflow/dags/pipeline_spark.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dagbag.py", line 305, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/pipeline_spark.py", line 47, in <module>
    conn = BaseHook.get_connection('aws_default')
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/hooks/base.py", line 67, in get_connection
    conn = Connection.get_connection_from_secrets(conn_id)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/connection.py", line 354, in get_connection_from_secrets
    raise AirflowNotFoundException(f"The conn_id `{conn_id}` isn't defined")
airflow.exceptions.AirflowNotFoundException: The conn_id `aws_default` isn't defined
[2021-08-18 15:36:01,446] {scheduler_job.py:641} WARNING - No viable dags retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:01,451] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-18 15:36:31,471] {scheduler_job.py:182} INFO - Started process (PID=52) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:31,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:36:31,474] {logging_mixin.py:104} INFO - [2021-08-18 15:36:31,474] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:31,682] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:31,703] {logging_mixin.py:104} INFO - [2021-08-18 15:36:31,702] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:36:31,718] {logging_mixin.py:104} INFO - [2021-08-18 15:36:31,717] {dag.py:1843} INFO - Creating ORM DAG for Pipeline_Spark_Orchestrator
[2021-08-18 15:36:31,730] {logging_mixin.py:104} INFO - [2021-08-18 15:36:31,729] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:36:31.729458+00:00
[2021-08-18 15:36:31,772] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.305 seconds
[2021-08-18 15:36:47,900] {scheduler_job.py:182} INFO - Started process (PID=32) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:47,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:36:47,902] {logging_mixin.py:104} INFO - [2021-08-18 15:36:47,902] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:48,141] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:36:48,153] {logging_mixin.py:104} INFO - [2021-08-18 15:36:48,153] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:36:48,173] {logging_mixin.py:104} INFO - [2021-08-18 15:36:48,172] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:36:48.172793+00:00
[2021-08-18 15:36:48,184] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.288 seconds
[2021-08-18 15:37:18,287] {scheduler_job.py:182} INFO - Started process (PID=34) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:18,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:37:18,290] {logging_mixin.py:104} INFO - [2021-08-18 15:37:18,290] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:18,440] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:18,452] {logging_mixin.py:104} INFO - [2021-08-18 15:37:18,452] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:37:18,464] {logging_mixin.py:104} INFO - [2021-08-18 15:37:18,464] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:37:18.464112+00:00
[2021-08-18 15:37:18,472] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-08-18 15:37:48,534] {scheduler_job.py:182} INFO - Started process (PID=36) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:48,535] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:37:48,536] {logging_mixin.py:104} INFO - [2021-08-18 15:37:48,536] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:48,632] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:37:48,640] {logging_mixin.py:104} INFO - [2021-08-18 15:37:48,640] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:37:48,650] {logging_mixin.py:104} INFO - [2021-08-18 15:37:48,650] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:37:48.650656+00:00
[2021-08-18 15:37:48,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 15:38:18,720] {scheduler_job.py:182} INFO - Started process (PID=38) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:18,722] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:38:18,722] {logging_mixin.py:104} INFO - [2021-08-18 15:38:18,722] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:18,812] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:18,820] {logging_mixin.py:104} INFO - [2021-08-18 15:38:18,820] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:38:18,831] {logging_mixin.py:104} INFO - [2021-08-18 15:38:18,831] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:38:18.831177+00:00
[2021-08-18 15:38:18,838] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-18 15:38:48,900] {scheduler_job.py:182} INFO - Started process (PID=40) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:48,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:38:48,902] {logging_mixin.py:104} INFO - [2021-08-18 15:38:48,902] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:49,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:38:49,020] {logging_mixin.py:104} INFO - [2021-08-18 15:38:49,020] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:38:49,036] {logging_mixin.py:104} INFO - [2021-08-18 15:38:49,036] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:38:49.036337+00:00
[2021-08-18 15:38:49,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-08-18 15:39:19,107] {scheduler_job.py:182} INFO - Started process (PID=42) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:19,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:39:19,109] {logging_mixin.py:104} INFO - [2021-08-18 15:39:19,109] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:19,198] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:19,206] {logging_mixin.py:104} INFO - [2021-08-18 15:39:19,206] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:39:19,217] {logging_mixin.py:104} INFO - [2021-08-18 15:39:19,217] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:39:19.217763+00:00
[2021-08-18 15:39:19,226] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-18 15:39:49,326] {scheduler_job.py:182} INFO - Started process (PID=44) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:49,327] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:39:49,328] {logging_mixin.py:104} INFO - [2021-08-18 15:39:49,327] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:49,415] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:39:49,423] {logging_mixin.py:104} INFO - [2021-08-18 15:39:49,423] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:39:49,435] {logging_mixin.py:104} INFO - [2021-08-18 15:39:49,435] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:39:49.435309+00:00
[2021-08-18 15:39:49,442] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-18 15:40:19,507] {scheduler_job.py:182} INFO - Started process (PID=46) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:19,509] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:40:19,510] {logging_mixin.py:104} INFO - [2021-08-18 15:40:19,509] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:19,609] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:19,620] {logging_mixin.py:104} INFO - [2021-08-18 15:40:19,620] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:40:19,633] {logging_mixin.py:104} INFO - [2021-08-18 15:40:19,633] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:40:19.632958+00:00
[2021-08-18 15:40:19,642] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-08-18 15:40:49,744] {scheduler_job.py:182} INFO - Started process (PID=48) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:49,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:40:49,745] {logging_mixin.py:104} INFO - [2021-08-18 15:40:49,745] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:49,835] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:40:49,843] {logging_mixin.py:104} INFO - [2021-08-18 15:40:49,843] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:40:49,858] {logging_mixin.py:104} INFO - [2021-08-18 15:40:49,858] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:40:49.858002+00:00
[2021-08-18 15:40:49,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 15:41:19,922] {scheduler_job.py:182} INFO - Started process (PID=50) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:19,923] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:41:19,923] {logging_mixin.py:104} INFO - [2021-08-18 15:41:19,923] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:20,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:20,041] {logging_mixin.py:104} INFO - [2021-08-18 15:41:20,041] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:41:20,054] {logging_mixin.py:104} INFO - [2021-08-18 15:41:20,053] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:41:20.053693+00:00
[2021-08-18 15:41:20,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 15:41:50,205] {scheduler_job.py:182} INFO - Started process (PID=53) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:50,206] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:41:50,207] {logging_mixin.py:104} INFO - [2021-08-18 15:41:50,207] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:50,293] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:41:50,302] {logging_mixin.py:104} INFO - [2021-08-18 15:41:50,302] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:41:50,313] {logging_mixin.py:104} INFO - [2021-08-18 15:41:50,313] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:41:50.313041+00:00
[2021-08-18 15:41:50,321] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.118 seconds
[2021-08-18 15:42:20,442] {scheduler_job.py:182} INFO - Started process (PID=56) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:20,443] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:42:20,443] {logging_mixin.py:104} INFO - [2021-08-18 15:42:20,443] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:20,532] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:20,541] {logging_mixin.py:104} INFO - [2021-08-18 15:42:20,541] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:42:20,553] {logging_mixin.py:104} INFO - [2021-08-18 15:42:20,553] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:42:20.553094+00:00
[2021-08-18 15:42:20,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-18 15:42:50,681] {scheduler_job.py:182} INFO - Started process (PID=59) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:50,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:42:50,683] {logging_mixin.py:104} INFO - [2021-08-18 15:42:50,683] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:50,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:42:50,780] {logging_mixin.py:104} INFO - [2021-08-18 15:42:50,780] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:42:50,791] {logging_mixin.py:104} INFO - [2021-08-18 15:42:50,791] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:42:50.791297+00:00
[2021-08-18 15:42:50,799] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-18 15:43:20,902] {scheduler_job.py:182} INFO - Started process (PID=62) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:20,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:43:20,903] {logging_mixin.py:104} INFO - [2021-08-18 15:43:20,903] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:21,006] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:21,016] {logging_mixin.py:104} INFO - [2021-08-18 15:43:21,016] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:43:21,028] {logging_mixin.py:104} INFO - [2021-08-18 15:43:21,028] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:43:21.028314+00:00
[2021-08-18 15:43:21,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 15:43:51,067] {scheduler_job.py:182} INFO - Started process (PID=65) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:51,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:43:51,070] {logging_mixin.py:104} INFO - [2021-08-18 15:43:51,069] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:51,168] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:43:51,176] {logging_mixin.py:104} INFO - [2021-08-18 15:43:51,176] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:43:51,187] {logging_mixin.py:104} INFO - [2021-08-18 15:43:51,187] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:43:51.187559+00:00
[2021-08-18 15:43:51,195] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-18 15:44:22,172] {scheduler_job.py:182} INFO - Started process (PID=68) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:22,173] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:44:22,173] {logging_mixin.py:104} INFO - [2021-08-18 15:44:22,173] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:22,267] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:22,275] {logging_mixin.py:104} INFO - [2021-08-18 15:44:22,275] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:44:22,286] {logging_mixin.py:104} INFO - [2021-08-18 15:44:22,286] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:44:22.286647+00:00
[2021-08-18 15:44:22,294] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-18 15:44:52,333] {scheduler_job.py:182} INFO - Started process (PID=71) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:52,336] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:44:52,337] {logging_mixin.py:104} INFO - [2021-08-18 15:44:52,337] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:52,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:44:52,447] {logging_mixin.py:104} INFO - [2021-08-18 15:44:52,447] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:44:52,460] {logging_mixin.py:104} INFO - [2021-08-18 15:44:52,460] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:44:52.459942+00:00
[2021-08-18 15:44:52,467] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 15:45:23,438] {scheduler_job.py:182} INFO - Started process (PID=74) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:23,439] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:45:23,440] {logging_mixin.py:104} INFO - [2021-08-18 15:45:23,440] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:23,537] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:23,548] {logging_mixin.py:104} INFO - [2021-08-18 15:45:23,548] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:45:23,559] {logging_mixin.py:104} INFO - [2021-08-18 15:45:23,559] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:45:23.559397+00:00
[2021-08-18 15:45:23,568] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-08-18 15:45:54,549] {scheduler_job.py:182} INFO - Started process (PID=77) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:54,551] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:45:54,552] {logging_mixin.py:104} INFO - [2021-08-18 15:45:54,551] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:54,656] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:45:54,668] {logging_mixin.py:104} INFO - [2021-08-18 15:45:54,668] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:45:54,680] {logging_mixin.py:104} INFO - [2021-08-18 15:45:54,680] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:45:54.680662+00:00
[2021-08-18 15:45:54,689] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-08-18 15:46:25,672] {scheduler_job.py:182} INFO - Started process (PID=80) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:25,673] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:46:25,674] {logging_mixin.py:104} INFO - [2021-08-18 15:46:25,674] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:25,815] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:25,826] {logging_mixin.py:104} INFO - [2021-08-18 15:46:25,826] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:46:25,839] {logging_mixin.py:104} INFO - [2021-08-18 15:46:25,839] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:46:25.839196+00:00
[2021-08-18 15:46:25,848] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.180 seconds
[2021-08-18 15:46:55,960] {scheduler_job.py:182} INFO - Started process (PID=83) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:55,965] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:46:55,965] {logging_mixin.py:104} INFO - [2021-08-18 15:46:55,965] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:56,079] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:46:56,088] {logging_mixin.py:104} INFO - [2021-08-18 15:46:56,088] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:46:56,104] {logging_mixin.py:104} INFO - [2021-08-18 15:46:56,104] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:46:56.104422+00:00
[2021-08-18 15:46:56,113] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.157 seconds
[2021-08-18 15:47:26,222] {scheduler_job.py:182} INFO - Started process (PID=86) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:26,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:47:26,224] {logging_mixin.py:104} INFO - [2021-08-18 15:47:26,224] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:26,327] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:26,337] {logging_mixin.py:104} INFO - [2021-08-18 15:47:26,336] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:47:26,353] {logging_mixin.py:104} INFO - [2021-08-18 15:47:26,353] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:47:26.353332+00:00
[2021-08-18 15:47:26,365] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 15:47:56,472] {scheduler_job.py:182} INFO - Started process (PID=89) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:56,473] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:47:56,474] {logging_mixin.py:104} INFO - [2021-08-18 15:47:56,474] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:56,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:47:56,613] {logging_mixin.py:104} INFO - [2021-08-18 15:47:56,613] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:47:56,628] {logging_mixin.py:104} INFO - [2021-08-18 15:47:56,628] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:47:56.628212+00:00
[2021-08-18 15:47:56,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.170 seconds
[2021-08-18 15:48:26,730] {scheduler_job.py:182} INFO - Started process (PID=92) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:26,731] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:48:26,732] {logging_mixin.py:104} INFO - [2021-08-18 15:48:26,732] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:26,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:26,857] {logging_mixin.py:104} INFO - [2021-08-18 15:48:26,857] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:48:26,871] {logging_mixin.py:104} INFO - [2021-08-18 15:48:26,871] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:48:26.871204+00:00
[2021-08-18 15:48:26,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.152 seconds
[2021-08-18 15:48:56,972] {scheduler_job.py:182} INFO - Started process (PID=95) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:56,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:48:56,973] {logging_mixin.py:104} INFO - [2021-08-18 15:48:56,973] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:57,067] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:48:57,079] {logging_mixin.py:104} INFO - [2021-08-18 15:48:57,079] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:48:57,093] {logging_mixin.py:104} INFO - [2021-08-18 15:48:57,092] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:48:57.092751+00:00
[2021-08-18 15:48:57,103] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-08-18 15:49:27,222] {scheduler_job.py:182} INFO - Started process (PID=98) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:27,223] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:49:27,224] {logging_mixin.py:104} INFO - [2021-08-18 15:49:27,224] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:27,330] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:27,339] {logging_mixin.py:104} INFO - [2021-08-18 15:49:27,339] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:49:27,353] {logging_mixin.py:104} INFO - [2021-08-18 15:49:27,353] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:49:27.352871+00:00
[2021-08-18 15:49:27,361] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-08-18 15:49:57,468] {scheduler_job.py:182} INFO - Started process (PID=101) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:57,469] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:49:57,470] {logging_mixin.py:104} INFO - [2021-08-18 15:49:57,470] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:57,595] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:49:57,604] {logging_mixin.py:104} INFO - [2021-08-18 15:49:57,604] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:49:57,617] {logging_mixin.py:104} INFO - [2021-08-18 15:49:57,617] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:49:57.617531+00:00
[2021-08-18 15:49:57,626] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-08-18 15:50:27,736] {scheduler_job.py:182} INFO - Started process (PID=104) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:27,737] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:50:27,738] {logging_mixin.py:104} INFO - [2021-08-18 15:50:27,738] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:27,834] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:27,845] {logging_mixin.py:104} INFO - [2021-08-18 15:50:27,845] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:50:27,859] {logging_mixin.py:104} INFO - [2021-08-18 15:50:27,859] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:50:27.859296+00:00
[2021-08-18 15:50:27,867] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-08-18 15:50:57,965] {scheduler_job.py:182} INFO - Started process (PID=107) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:57,966] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:50:57,967] {logging_mixin.py:104} INFO - [2021-08-18 15:50:57,967] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:58,074] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:50:58,084] {logging_mixin.py:104} INFO - [2021-08-18 15:50:58,084] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:50:58,099] {logging_mixin.py:104} INFO - [2021-08-18 15:50:58,099] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:50:58.099078+00:00
[2021-08-18 15:50:58,107] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 15:51:29,077] {scheduler_job.py:182} INFO - Started process (PID=110) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:51:29,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:51:29,079] {logging_mixin.py:104} INFO - [2021-08-18 15:51:29,079] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:51:29,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:51:29,208] {logging_mixin.py:104} INFO - [2021-08-18 15:51:29,208] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:51:29,225] {logging_mixin.py:104} INFO - [2021-08-18 15:51:29,225] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:51:29.225083+00:00
[2021-08-18 15:51:29,236] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-08-18 15:52:00,194] {scheduler_job.py:182} INFO - Started process (PID=113) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:00,196] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:52:00,196] {logging_mixin.py:104} INFO - [2021-08-18 15:52:00,196] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:00,297] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:00,306] {logging_mixin.py:104} INFO - [2021-08-18 15:52:00,306] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:52:00,319] {logging_mixin.py:104} INFO - [2021-08-18 15:52:00,319] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:52:00.319012+00:00
[2021-08-18 15:52:00,327] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 15:52:31,315] {scheduler_job.py:182} INFO - Started process (PID=116) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:31,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:52:31,317] {logging_mixin.py:104} INFO - [2021-08-18 15:52:31,317] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:31,424] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:52:31,433] {logging_mixin.py:104} INFO - [2021-08-18 15:52:31,433] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:52:31,447] {logging_mixin.py:104} INFO - [2021-08-18 15:52:31,447] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:52:31.447026+00:00
[2021-08-18 15:52:31,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-08-18 15:53:01,562] {scheduler_job.py:182} INFO - Started process (PID=119) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:01,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:53:01,564] {logging_mixin.py:104} INFO - [2021-08-18 15:53:01,564] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:01,668] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:01,678] {logging_mixin.py:104} INFO - [2021-08-18 15:53:01,677] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:53:01,691] {logging_mixin.py:104} INFO - [2021-08-18 15:53:01,690] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:53:01.690850+00:00
[2021-08-18 15:53:01,699] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-08-18 15:53:31,804] {scheduler_job.py:182} INFO - Started process (PID=122) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:31,806] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:53:31,807] {logging_mixin.py:104} INFO - [2021-08-18 15:53:31,807] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:31,941] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:53:31,951] {logging_mixin.py:104} INFO - [2021-08-18 15:53:31,951] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:53:31,963] {logging_mixin.py:104} INFO - [2021-08-18 15:53:31,963] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:53:31.963199+00:00
[2021-08-18 15:53:31,972] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.171 seconds
[2021-08-18 15:54:02,063] {scheduler_job.py:182} INFO - Started process (PID=125) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:02,064] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:54:02,064] {logging_mixin.py:104} INFO - [2021-08-18 15:54:02,064] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:02,160] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:02,169] {logging_mixin.py:104} INFO - [2021-08-18 15:54:02,169] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:54:02,180] {logging_mixin.py:104} INFO - [2021-08-18 15:54:02,180] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:54:02.180765+00:00
[2021-08-18 15:54:02,189] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-08-18 15:54:33,172] {scheduler_job.py:182} INFO - Started process (PID=128) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:33,174] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:54:33,175] {logging_mixin.py:104} INFO - [2021-08-18 15:54:33,174] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:33,276] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:54:33,288] {logging_mixin.py:104} INFO - [2021-08-18 15:54:33,288] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:54:33,302] {logging_mixin.py:104} INFO - [2021-08-18 15:54:33,302] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:54:33.302258+00:00
[2021-08-18 15:54:33,310] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.141 seconds
[2021-08-18 15:55:03,412] {scheduler_job.py:182} INFO - Started process (PID=131) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:03,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:55:03,414] {logging_mixin.py:104} INFO - [2021-08-18 15:55:03,414] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:03,531] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:03,545] {logging_mixin.py:104} INFO - [2021-08-18 15:55:03,545] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:55:03,559] {logging_mixin.py:104} INFO - [2021-08-18 15:55:03,559] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:55:03.559301+00:00
[2021-08-18 15:55:03,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-08-18 15:55:34,528] {scheduler_job.py:182} INFO - Started process (PID=134) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:34,529] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:55:34,529] {logging_mixin.py:104} INFO - [2021-08-18 15:55:34,529] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:34,630] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:55:34,640] {logging_mixin.py:104} INFO - [2021-08-18 15:55:34,640] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:55:34,651] {logging_mixin.py:104} INFO - [2021-08-18 15:55:34,651] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:55:34.651527+00:00
[2021-08-18 15:55:34,659] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-08-18 15:56:05,638] {scheduler_job.py:182} INFO - Started process (PID=137) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:05,639] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:56:05,640] {logging_mixin.py:104} INFO - [2021-08-18 15:56:05,640] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:05,752] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:05,763] {logging_mixin.py:104} INFO - [2021-08-18 15:56:05,763] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:56:05,775] {logging_mixin.py:104} INFO - [2021-08-18 15:56:05,775] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:56:05.775486+00:00
[2021-08-18 15:56:05,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-08-18 15:56:35,893] {scheduler_job.py:182} INFO - Started process (PID=140) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:35,894] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:56:35,895] {logging_mixin.py:104} INFO - [2021-08-18 15:56:35,895] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:35,987] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:56:35,996] {logging_mixin.py:104} INFO - [2021-08-18 15:56:35,996] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:56:36,007] {logging_mixin.py:104} INFO - [2021-08-18 15:56:36,007] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:56:36.007372+00:00
[2021-08-18 15:56:36,015] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-18 15:57:07,000] {scheduler_job.py:182} INFO - Started process (PID=143) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:07,001] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:57:07,002] {logging_mixin.py:104} INFO - [2021-08-18 15:57:07,002] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:07,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:07,110] {logging_mixin.py:104} INFO - [2021-08-18 15:57:07,110] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:57:07,122] {logging_mixin.py:104} INFO - [2021-08-18 15:57:07,122] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:57:07.122367+00:00
[2021-08-18 15:57:07,130] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-18 15:57:38,114] {scheduler_job.py:182} INFO - Started process (PID=146) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:38,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:57:38,116] {logging_mixin.py:104} INFO - [2021-08-18 15:57:38,116] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:38,209] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:57:38,218] {logging_mixin.py:104} INFO - [2021-08-18 15:57:38,217] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:57:38,230] {logging_mixin.py:104} INFO - [2021-08-18 15:57:38,230] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:57:38.230499+00:00
[2021-08-18 15:57:38,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-08-18 15:58:09,214] {scheduler_job.py:182} INFO - Started process (PID=149) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:09,215] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:58:09,216] {logging_mixin.py:104} INFO - [2021-08-18 15:58:09,216] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:09,319] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:09,329] {logging_mixin.py:104} INFO - [2021-08-18 15:58:09,329] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:58:09,341] {logging_mixin.py:104} INFO - [2021-08-18 15:58:09,341] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:58:09.341650+00:00
[2021-08-18 15:58:09,349] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.138 seconds
[2021-08-18 15:58:39,455] {scheduler_job.py:182} INFO - Started process (PID=152) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:39,456] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:58:39,457] {logging_mixin.py:104} INFO - [2021-08-18 15:58:39,457] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:39,592] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:58:39,603] {logging_mixin.py:104} INFO - [2021-08-18 15:58:39,603] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:58:39,618] {logging_mixin.py:104} INFO - [2021-08-18 15:58:39,618] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:58:39.618525+00:00
[2021-08-18 15:58:39,627] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.175 seconds
[2021-08-18 15:59:10,549] {scheduler_job.py:182} INFO - Started process (PID=155) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:10,551] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:59:10,551] {logging_mixin.py:104} INFO - [2021-08-18 15:59:10,551] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:10,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:10,676] {logging_mixin.py:104} INFO - [2021-08-18 15:59:10,676] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:59:10,691] {logging_mixin.py:104} INFO - [2021-08-18 15:59:10,691] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:59:10.691006+00:00
[2021-08-18 15:59:10,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-08-18 15:59:40,819] {scheduler_job.py:182} INFO - Started process (PID=158) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:40,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 15:59:40,821] {logging_mixin.py:104} INFO - [2021-08-18 15:59:40,821] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:40,929] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 15:59:40,939] {logging_mixin.py:104} INFO - [2021-08-18 15:59:40,939] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 15:59:40,953] {logging_mixin.py:104} INFO - [2021-08-18 15:59:40,953] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 15:59:40.952932+00:00
[2021-08-18 15:59:40,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-08-18 16:00:11,073] {scheduler_job.py:182} INFO - Started process (PID=161) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:11,074] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:00:11,074] {logging_mixin.py:104} INFO - [2021-08-18 16:00:11,074] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:11,181] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:11,193] {logging_mixin.py:104} INFO - [2021-08-18 16:00:11,193] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:00:11,210] {logging_mixin.py:104} INFO - [2021-08-18 16:00:11,209] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:00:11.209763+00:00
[2021-08-18 16:00:11,219] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-08-18 16:00:41,323] {scheduler_job.py:182} INFO - Started process (PID=164) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:41,324] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:00:41,325] {logging_mixin.py:104} INFO - [2021-08-18 16:00:41,325] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:41,442] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:00:41,455] {logging_mixin.py:104} INFO - [2021-08-18 16:00:41,455] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:00:41,475] {logging_mixin.py:104} INFO - [2021-08-18 16:00:41,475] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:00:41.474964+00:00
[2021-08-18 16:00:41,484] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 16:01:11,602] {scheduler_job.py:182} INFO - Started process (PID=167) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:11,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:01:11,604] {logging_mixin.py:104} INFO - [2021-08-18 16:01:11,603] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:11,716] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:11,726] {logging_mixin.py:104} INFO - [2021-08-18 16:01:11,726] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:01:11,743] {logging_mixin.py:104} INFO - [2021-08-18 16:01:11,743] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:01:11.743350+00:00
[2021-08-18 16:01:11,751] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-08-18 16:01:41,861] {scheduler_job.py:182} INFO - Started process (PID=170) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:41,862] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:01:41,863] {logging_mixin.py:104} INFO - [2021-08-18 16:01:41,863] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:41,970] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:01:41,980] {logging_mixin.py:104} INFO - [2021-08-18 16:01:41,980] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:01:41,996] {logging_mixin.py:104} INFO - [2021-08-18 16:01:41,996] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:01:41.996389+00:00
[2021-08-18 16:01:42,005] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.147 seconds
[2021-08-18 16:02:12,131] {scheduler_job.py:182} INFO - Started process (PID=173) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:12,132] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:02:12,133] {logging_mixin.py:104} INFO - [2021-08-18 16:02:12,133] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:12,253] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:12,263] {logging_mixin.py:104} INFO - [2021-08-18 16:02:12,263] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:02:12,280] {logging_mixin.py:104} INFO - [2021-08-18 16:02:12,280] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:02:12.279963+00:00
[2021-08-18 16:02:12,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.163 seconds
[2021-08-18 16:02:42,410] {scheduler_job.py:182} INFO - Started process (PID=176) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:42,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:02:42,412] {logging_mixin.py:104} INFO - [2021-08-18 16:02:42,412] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:42,529] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:02:42,539] {logging_mixin.py:104} INFO - [2021-08-18 16:02:42,539] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:02:42,557] {logging_mixin.py:104} INFO - [2021-08-18 16:02:42,557] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:02:42.557431+00:00
[2021-08-18 16:02:42,569] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-08-18 16:03:12,697] {scheduler_job.py:182} INFO - Started process (PID=179) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:12,698] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:03:12,699] {logging_mixin.py:104} INFO - [2021-08-18 16:03:12,699] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:12,801] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:12,810] {logging_mixin.py:104} INFO - [2021-08-18 16:03:12,810] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:03:12,823] {logging_mixin.py:104} INFO - [2021-08-18 16:03:12,822] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:03:12.822793+00:00
[2021-08-18 16:03:12,832] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 16:03:42,956] {scheduler_job.py:182} INFO - Started process (PID=182) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:42,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:03:42,958] {logging_mixin.py:104} INFO - [2021-08-18 16:03:42,958] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:43,072] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:03:43,085] {logging_mixin.py:104} INFO - [2021-08-18 16:03:43,085] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:03:43,098] {logging_mixin.py:104} INFO - [2021-08-18 16:03:43,098] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:03:43.098528+00:00
[2021-08-18 16:03:43,108] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.155 seconds
[2021-08-18 16:04:14,068] {scheduler_job.py:182} INFO - Started process (PID=185) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:14,070] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:04:14,070] {logging_mixin.py:104} INFO - [2021-08-18 16:04:14,070] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:14,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:14,178] {logging_mixin.py:104} INFO - [2021-08-18 16:04:14,178] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:04:14,191] {logging_mixin.py:104} INFO - [2021-08-18 16:04:14,191] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:04:14.191678+00:00
[2021-08-18 16:04:14,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.135 seconds
[2021-08-18 16:04:45,176] {scheduler_job.py:182} INFO - Started process (PID=188) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:45,177] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:04:45,177] {logging_mixin.py:104} INFO - [2021-08-18 16:04:45,177] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:45,279] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:04:45,289] {logging_mixin.py:104} INFO - [2021-08-18 16:04:45,289] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:04:45,303] {logging_mixin.py:104} INFO - [2021-08-18 16:04:45,303] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:04:45.303499+00:00
[2021-08-18 16:04:45,317] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 16:05:16,288] {scheduler_job.py:182} INFO - Started process (PID=191) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:16,289] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:05:16,290] {logging_mixin.py:104} INFO - [2021-08-18 16:05:16,290] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:16,397] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:16,409] {logging_mixin.py:104} INFO - [2021-08-18 16:05:16,409] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:05:16,422] {logging_mixin.py:104} INFO - [2021-08-18 16:05:16,422] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:05:16.422736+00:00
[2021-08-18 16:05:16,431] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-08-18 16:05:47,444] {scheduler_job.py:182} INFO - Started process (PID=194) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:47,445] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:05:47,446] {logging_mixin.py:104} INFO - [2021-08-18 16:05:47,446] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:47,540] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:05:47,554] {logging_mixin.py:104} INFO - [2021-08-18 16:05:47,554] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:05:47,567] {logging_mixin.py:104} INFO - [2021-08-18 16:05:47,567] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:05:47.567272+00:00
[2021-08-18 16:05:47,576] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 16:06:17,693] {scheduler_job.py:182} INFO - Started process (PID=197) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:17,694] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:06:17,695] {logging_mixin.py:104} INFO - [2021-08-18 16:06:17,694] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:17,796] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:17,808] {logging_mixin.py:104} INFO - [2021-08-18 16:06:17,808] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:06:17,824] {logging_mixin.py:104} INFO - [2021-08-18 16:06:17,824] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:06:17.824120+00:00
[2021-08-18 16:06:17,833] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 16:06:48,794] {scheduler_job.py:182} INFO - Started process (PID=200) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:48,795] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:06:48,796] {logging_mixin.py:104} INFO - [2021-08-18 16:06:48,796] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:48,921] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:06:48,933] {logging_mixin.py:104} INFO - [2021-08-18 16:06:48,933] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:06:48,946] {logging_mixin.py:104} INFO - [2021-08-18 16:06:48,945] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:06:48.945784+00:00
[2021-08-18 16:06:48,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 16:07:19,104] {scheduler_job.py:182} INFO - Started process (PID=203) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:19,106] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:07:19,107] {logging_mixin.py:104} INFO - [2021-08-18 16:07:19,107] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:19,212] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:19,220] {logging_mixin.py:104} INFO - [2021-08-18 16:07:19,220] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:07:19,232] {logging_mixin.py:104} INFO - [2021-08-18 16:07:19,231] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:07:19.231882+00:00
[2021-08-18 16:07:19,240] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.140 seconds
[2021-08-18 16:07:49,353] {scheduler_job.py:182} INFO - Started process (PID=206) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:49,354] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:07:49,355] {logging_mixin.py:104} INFO - [2021-08-18 16:07:49,355] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:49,467] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:07:49,479] {logging_mixin.py:104} INFO - [2021-08-18 16:07:49,479] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:07:49,494] {logging_mixin.py:104} INFO - [2021-08-18 16:07:49,493] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:07:49.493810+00:00
[2021-08-18 16:07:49,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.153 seconds
[2021-08-18 16:08:19,611] {scheduler_job.py:182} INFO - Started process (PID=209) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:19,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:08:19,618] {logging_mixin.py:104} INFO - [2021-08-18 16:08:19,617] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:19,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:19,771] {logging_mixin.py:104} INFO - [2021-08-18 16:08:19,771] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:08:19,783] {logging_mixin.py:104} INFO - [2021-08-18 16:08:19,783] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:08:19.783000+00:00
[2021-08-18 16:08:19,790] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.185 seconds
[2021-08-18 16:08:49,904] {scheduler_job.py:182} INFO - Started process (PID=212) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:49,905] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:08:49,905] {logging_mixin.py:104} INFO - [2021-08-18 16:08:49,905] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:50,030] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:08:50,045] {logging_mixin.py:104} INFO - [2021-08-18 16:08:50,045] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:08:50,061] {logging_mixin.py:104} INFO - [2021-08-18 16:08:50,061] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:08:50.061112+00:00
[2021-08-18 16:08:50,074] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.175 seconds
[2021-08-18 16:09:20,182] {scheduler_job.py:182} INFO - Started process (PID=215) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:20,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:09:20,183] {logging_mixin.py:104} INFO - [2021-08-18 16:09:20,183] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:20,296] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:20,306] {logging_mixin.py:104} INFO - [2021-08-18 16:09:20,306] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:09:20,319] {logging_mixin.py:104} INFO - [2021-08-18 16:09:20,319] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:09:20.319563+00:00
[2021-08-18 16:09:20,328] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-08-18 16:09:50,428] {scheduler_job.py:182} INFO - Started process (PID=218) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:50,429] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:09:50,430] {logging_mixin.py:104} INFO - [2021-08-18 16:09:50,430] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:50,530] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:09:50,541] {logging_mixin.py:104} INFO - [2021-08-18 16:09:50,541] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:09:50,559] {logging_mixin.py:104} INFO - [2021-08-18 16:09:50,559] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:09:50.559562+00:00
[2021-08-18 16:09:50,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.151 seconds
[2021-08-18 16:10:21,540] {scheduler_job.py:182} INFO - Started process (PID=221) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:21,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:10:21,542] {logging_mixin.py:104} INFO - [2021-08-18 16:10:21,541] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:21,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:21,653] {logging_mixin.py:104} INFO - [2021-08-18 16:10:21,653] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:10:21,666] {logging_mixin.py:104} INFO - [2021-08-18 16:10:21,666] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:10:21.666443+00:00
[2021-08-18 16:10:21,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-08-18 16:10:51,773] {scheduler_job.py:182} INFO - Started process (PID=224) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:51,775] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:10:51,776] {logging_mixin.py:104} INFO - [2021-08-18 16:10:51,775] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:51,881] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:10:51,893] {logging_mixin.py:104} INFO - [2021-08-18 16:10:51,893] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:10:51,906] {logging_mixin.py:104} INFO - [2021-08-18 16:10:51,905] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:10:51.905819+00:00
[2021-08-18 16:10:51,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 16:11:22,874] {scheduler_job.py:182} INFO - Started process (PID=227) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:22,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:11:22,876] {logging_mixin.py:104} INFO - [2021-08-18 16:11:22,876] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:22,968] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:22,977] {logging_mixin.py:104} INFO - [2021-08-18 16:11:22,977] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:11:22,989] {logging_mixin.py:104} INFO - [2021-08-18 16:11:22,989] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:11:22.989221+00:00
[2021-08-18 16:11:23,001] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-08-18 16:11:53,986] {scheduler_job.py:182} INFO - Started process (PID=230) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:53,987] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:11:53,988] {logging_mixin.py:104} INFO - [2021-08-18 16:11:53,988] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:54,077] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:11:54,086] {logging_mixin.py:104} INFO - [2021-08-18 16:11:54,086] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:11:54,098] {logging_mixin.py:104} INFO - [2021-08-18 16:11:54,098] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:11:54.098511+00:00
[2021-08-18 16:11:54,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.122 seconds
[2021-08-18 16:12:24,206] {scheduler_job.py:182} INFO - Started process (PID=233) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:24,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:12:24,208] {logging_mixin.py:104} INFO - [2021-08-18 16:12:24,208] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:24,312] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:24,321] {logging_mixin.py:104} INFO - [2021-08-18 16:12:24,321] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:12:24,332] {logging_mixin.py:104} INFO - [2021-08-18 16:12:24,332] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:12:24.332272+00:00
[2021-08-18 16:12:24,339] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.136 seconds
[2021-08-18 16:12:55,304] {scheduler_job.py:182} INFO - Started process (PID=236) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:55,305] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:12:55,305] {logging_mixin.py:104} INFO - [2021-08-18 16:12:55,305] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:55,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:12:55,411] {logging_mixin.py:104} INFO - [2021-08-18 16:12:55,411] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:12:55,422] {logging_mixin.py:104} INFO - [2021-08-18 16:12:55,422] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:12:55.422657+00:00
[2021-08-18 16:12:55,434] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.133 seconds
[2021-08-18 16:13:26,394] {scheduler_job.py:182} INFO - Started process (PID=239) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:26,399] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:13:26,399] {logging_mixin.py:104} INFO - [2021-08-18 16:13:26,399] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:26,495] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:26,504] {logging_mixin.py:104} INFO - [2021-08-18 16:13:26,503] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:13:26,516] {logging_mixin.py:104} INFO - [2021-08-18 16:13:26,515] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:13:26.515845+00:00
[2021-08-18 16:13:26,523] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.132 seconds
[2021-08-18 16:13:56,621] {scheduler_job.py:182} INFO - Started process (PID=242) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:56,622] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:13:56,622] {logging_mixin.py:104} INFO - [2021-08-18 16:13:56,622] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:56,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:13:56,744] {logging_mixin.py:104} INFO - [2021-08-18 16:13:56,744] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:13:56,757] {logging_mixin.py:104} INFO - [2021-08-18 16:13:56,757] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:13:56.756893+00:00
[2021-08-18 16:13:56,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-08-18 16:14:26,866] {scheduler_job.py:182} INFO - Started process (PID=245) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:26,871] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:14:26,872] {logging_mixin.py:104} INFO - [2021-08-18 16:14:26,872] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:26,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:26,993] {logging_mixin.py:104} INFO - [2021-08-18 16:14:26,993] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:14:27,005] {logging_mixin.py:104} INFO - [2021-08-18 16:14:27,005] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:14:27.005296+00:00
[2021-08-18 16:14:27,014] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-08-18 16:14:57,108] {scheduler_job.py:182} INFO - Started process (PID=248) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:57,109] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:14:57,110] {logging_mixin.py:104} INFO - [2021-08-18 16:14:57,110] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:57,218] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:14:57,228] {logging_mixin.py:104} INFO - [2021-08-18 16:14:57,228] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:14:57,242] {logging_mixin.py:104} INFO - [2021-08-18 16:14:57,242] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:14:57.242371+00:00
[2021-08-18 16:14:57,251] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 16:15:28,208] {scheduler_job.py:182} INFO - Started process (PID=251) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:28,209] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:15:28,210] {logging_mixin.py:104} INFO - [2021-08-18 16:15:28,209] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:28,301] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:28,310] {logging_mixin.py:104} INFO - [2021-08-18 16:15:28,310] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:15:28,322] {logging_mixin.py:104} INFO - [2021-08-18 16:15:28,322] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:15:28.322068+00:00
[2021-08-18 16:15:28,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-18 16:15:58,434] {scheduler_job.py:182} INFO - Started process (PID=254) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:58,435] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:15:58,436] {logging_mixin.py:104} INFO - [2021-08-18 16:15:58,436] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:58,543] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:15:58,555] {logging_mixin.py:104} INFO - [2021-08-18 16:15:58,555] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:15:58,575] {logging_mixin.py:104} INFO - [2021-08-18 16:15:58,575] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:15:58.574925+00:00
[2021-08-18 16:15:58,586] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-08-18 16:16:28,682] {scheduler_job.py:182} INFO - Started process (PID=257) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:28,683] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:16:28,684] {logging_mixin.py:104} INFO - [2021-08-18 16:16:28,684] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:28,782] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:28,792] {logging_mixin.py:104} INFO - [2021-08-18 16:16:28,791] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:16:28,806] {logging_mixin.py:104} INFO - [2021-08-18 16:16:28,806] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:16:28.806362+00:00
[2021-08-18 16:16:28,814] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 16:16:58,930] {scheduler_job.py:182} INFO - Started process (PID=260) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:58,931] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:16:58,932] {logging_mixin.py:104} INFO - [2021-08-18 16:16:58,932] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:59,035] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:16:59,047] {logging_mixin.py:104} INFO - [2021-08-18 16:16:59,047] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:16:59,061] {logging_mixin.py:104} INFO - [2021-08-18 16:16:59,060] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:16:59.060771+00:00
[2021-08-18 16:16:59,075] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-08-18 16:17:30,024] {scheduler_job.py:182} INFO - Started process (PID=263) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:17:30,025] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:17:30,026] {logging_mixin.py:104} INFO - [2021-08-18 16:17:30,026] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:17:30,133] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:17:30,143] {logging_mixin.py:104} INFO - [2021-08-18 16:17:30,142] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:17:30,157] {logging_mixin.py:104} INFO - [2021-08-18 16:17:30,157] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:17:30.157330+00:00
[2021-08-18 16:17:30,166] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.146 seconds
[2021-08-18 16:18:00,274] {scheduler_job.py:182} INFO - Started process (PID=266) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:00,276] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:18:00,276] {logging_mixin.py:104} INFO - [2021-08-18 16:18:00,276] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:00,370] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:00,379] {logging_mixin.py:104} INFO - [2021-08-18 16:18:00,379] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:18:00,390] {logging_mixin.py:104} INFO - [2021-08-18 16:18:00,390] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:18:00.390194+00:00
[2021-08-18 16:18:00,398] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-08-18 16:18:31,374] {scheduler_job.py:182} INFO - Started process (PID=269) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:31,376] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:18:31,377] {logging_mixin.py:104} INFO - [2021-08-18 16:18:31,376] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:31,469] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:18:31,478] {logging_mixin.py:104} INFO - [2021-08-18 16:18:31,477] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:18:31,489] {logging_mixin.py:104} INFO - [2021-08-18 16:18:31,489] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:18:31.489163+00:00
[2021-08-18 16:18:31,496] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 16:19:02,476] {scheduler_job.py:182} INFO - Started process (PID=272) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:02,478] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:19:02,478] {logging_mixin.py:104} INFO - [2021-08-18 16:19:02,478] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:02,579] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:02,591] {logging_mixin.py:104} INFO - [2021-08-18 16:19:02,590] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:19:02,605] {logging_mixin.py:104} INFO - [2021-08-18 16:19:02,605] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:19:02.605361+00:00
[2021-08-18 16:19:02,615] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-08-18 16:19:32,735] {scheduler_job.py:182} INFO - Started process (PID=275) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:32,736] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:19:32,737] {logging_mixin.py:104} INFO - [2021-08-18 16:19:32,737] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:32,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:19:32,855] {logging_mixin.py:104} INFO - [2021-08-18 16:19:32,855] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:19:32,869] {logging_mixin.py:104} INFO - [2021-08-18 16:19:32,869] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:19:32.869377+00:00
[2021-08-18 16:19:32,879] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.148 seconds
[2021-08-18 16:20:02,992] {scheduler_job.py:182} INFO - Started process (PID=278) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:02,994] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:20:02,994] {logging_mixin.py:104} INFO - [2021-08-18 16:20:02,994] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:03,094] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:03,103] {logging_mixin.py:104} INFO - [2021-08-18 16:20:03,103] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:20:03,116] {logging_mixin.py:104} INFO - [2021-08-18 16:20:03,116] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:20:03.116609+00:00
[2021-08-18 16:20:03,125] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 16:20:33,237] {scheduler_job.py:182} INFO - Started process (PID=281) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:33,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:20:33,239] {logging_mixin.py:104} INFO - [2021-08-18 16:20:33,239] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:33,342] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:20:33,352] {logging_mixin.py:104} INFO - [2021-08-18 16:20:33,352] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:20:33,364] {logging_mixin.py:104} INFO - [2021-08-18 16:20:33,364] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:20:33.364456+00:00
[2021-08-18 16:20:33,373] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.139 seconds
[2021-08-18 16:21:03,492] {scheduler_job.py:182} INFO - Started process (PID=284) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:03,493] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:21:03,494] {logging_mixin.py:104} INFO - [2021-08-18 16:21:03,494] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:03,629] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:03,644] {logging_mixin.py:104} INFO - [2021-08-18 16:21:03,644] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:21:03,660] {logging_mixin.py:104} INFO - [2021-08-18 16:21:03,660] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:21:03.660215+00:00
[2021-08-18 16:21:03,673] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.184 seconds
[2021-08-18 16:21:33,764] {scheduler_job.py:182} INFO - Started process (PID=287) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:33,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:21:33,765] {logging_mixin.py:104} INFO - [2021-08-18 16:21:33,765] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:33,884] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:21:33,895] {logging_mixin.py:104} INFO - [2021-08-18 16:21:33,895] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:21:33,908] {logging_mixin.py:104} INFO - [2021-08-18 16:21:33,908] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:21:33.908381+00:00
[2021-08-18 16:21:33,916] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.154 seconds
[2021-08-18 16:22:04,026] {scheduler_job.py:182} INFO - Started process (PID=290) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:04,027] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:22:04,027] {logging_mixin.py:104} INFO - [2021-08-18 16:22:04,027] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:04,128] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:04,142] {logging_mixin.py:104} INFO - [2021-08-18 16:22:04,141] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:22:04,158] {logging_mixin.py:104} INFO - [2021-08-18 16:22:04,158] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:22:04.157810+00:00
[2021-08-18 16:22:04,170] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.149 seconds
[2021-08-18 16:22:34,263] {scheduler_job.py:182} INFO - Started process (PID=293) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:34,266] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:22:34,267] {logging_mixin.py:104} INFO - [2021-08-18 16:22:34,267] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:34,385] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:22:34,399] {logging_mixin.py:104} INFO - [2021-08-18 16:22:34,399] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:22:34,415] {logging_mixin.py:104} INFO - [2021-08-18 16:22:34,415] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:22:34.415034+00:00
[2021-08-18 16:22:34,426] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.165 seconds
[2021-08-18 16:23:04,520] {scheduler_job.py:182} INFO - Started process (PID=296) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:04,522] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:23:04,523] {logging_mixin.py:104} INFO - [2021-08-18 16:23:04,523] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:04,620] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:04,630] {logging_mixin.py:104} INFO - [2021-08-18 16:23:04,629] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:23:04,642] {logging_mixin.py:104} INFO - [2021-08-18 16:23:04,642] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:23:04.642446+00:00
[2021-08-18 16:23:04,650] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.134 seconds
[2021-08-18 16:23:34,743] {scheduler_job.py:182} INFO - Started process (PID=299) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:34,745] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:23:34,745] {logging_mixin.py:104} INFO - [2021-08-18 16:23:34,745] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:34,844] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:23:34,854] {logging_mixin.py:104} INFO - [2021-08-18 16:23:34,853] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:23:34,869] {logging_mixin.py:104} INFO - [2021-08-18 16:23:34,869] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:23:34.869154+00:00
[2021-08-18 16:23:34,881] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-08-18 16:24:05,003] {scheduler_job.py:182} INFO - Started process (PID=302) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:05,005] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:24:05,005] {logging_mixin.py:104} INFO - [2021-08-18 16:24:05,005] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:05,126] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:05,138] {logging_mixin.py:104} INFO - [2021-08-18 16:24:05,138] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:24:05,153] {logging_mixin.py:104} INFO - [2021-08-18 16:24:05,153] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:24:05.153044+00:00
[2021-08-18 16:24:05,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-08-18 16:24:35,268] {scheduler_job.py:182} INFO - Started process (PID=305) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:35,269] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:24:35,270] {logging_mixin.py:104} INFO - [2021-08-18 16:24:35,270] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:35,376] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:24:35,390] {logging_mixin.py:104} INFO - [2021-08-18 16:24:35,390] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:24:35,407] {logging_mixin.py:104} INFO - [2021-08-18 16:24:35,407] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:24:35.407543+00:00
[2021-08-18 16:24:35,420] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.156 seconds
[2021-08-18 16:25:05,523] {scheduler_job.py:182} INFO - Started process (PID=308) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:05,524] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:25:05,525] {logging_mixin.py:104} INFO - [2021-08-18 16:25:05,525] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:05,637] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:05,648] {logging_mixin.py:104} INFO - [2021-08-18 16:25:05,648] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:25:05,663] {logging_mixin.py:104} INFO - [2021-08-18 16:25:05,663] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:25:05.662929+00:00
[2021-08-18 16:25:05,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.150 seconds
[2021-08-18 16:25:35,765] {scheduler_job.py:182} INFO - Started process (PID=311) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:35,766] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:25:35,767] {logging_mixin.py:104} INFO - [2021-08-18 16:25:35,767] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:35,862] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:25:35,874] {logging_mixin.py:104} INFO - [2021-08-18 16:25:35,874] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:25:35,890] {logging_mixin.py:104} INFO - [2021-08-18 16:25:35,890] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:25:35.890015+00:00
[2021-08-18 16:25:35,900] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.137 seconds
[2021-08-18 16:26:06,004] {scheduler_job.py:182} INFO - Started process (PID=314) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:06,006] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:26:06,008] {logging_mixin.py:104} INFO - [2021-08-18 16:26:06,007] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:06,123] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:06,132] {logging_mixin.py:104} INFO - [2021-08-18 16:26:06,132] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:26:06,149] {logging_mixin.py:104} INFO - [2021-08-18 16:26:06,149] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:26:06.148857+00:00
[2021-08-18 16:26:06,164] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.162 seconds
[2021-08-18 16:26:36,256] {scheduler_job.py:182} INFO - Started process (PID=317) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:36,257] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:26:36,258] {logging_mixin.py:104} INFO - [2021-08-18 16:26:36,258] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:36,386] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:26:36,400] {logging_mixin.py:104} INFO - [2021-08-18 16:26:36,399] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:26:36,414] {logging_mixin.py:104} INFO - [2021-08-18 16:26:36,414] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:26:36.414173+00:00
[2021-08-18 16:26:36,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-08-18 16:27:06,535] {scheduler_job.py:182} INFO - Started process (PID=320) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:06,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:27:06,537] {logging_mixin.py:104} INFO - [2021-08-18 16:27:06,537] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:06,675] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:06,687] {logging_mixin.py:104} INFO - [2021-08-18 16:27:06,687] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:27:06,704] {logging_mixin.py:104} INFO - [2021-08-18 16:27:06,704] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:27:06.704451+00:00
[2021-08-18 16:27:06,720] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-08-18 16:27:36,819] {scheduler_job.py:182} INFO - Started process (PID=323) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:36,820] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:27:36,821] {logging_mixin.py:104} INFO - [2021-08-18 16:27:36,821] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:36,922] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:27:36,935] {logging_mixin.py:104} INFO - [2021-08-18 16:27:36,934] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:27:36,952] {logging_mixin.py:104} INFO - [2021-08-18 16:27:36,952] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:27:36.951966+00:00
[2021-08-18 16:27:36,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.144 seconds
[2021-08-18 16:28:07,061] {scheduler_job.py:182} INFO - Started process (PID=326) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:07,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:28:07,062] {logging_mixin.py:104} INFO - [2021-08-18 16:28:07,062] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:07,200] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:07,222] {logging_mixin.py:104} INFO - [2021-08-18 16:28:07,222] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:28:07,243] {logging_mixin.py:104} INFO - [2021-08-18 16:28:07,243] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:28:07.243409+00:00
[2021-08-18 16:28:07,259] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.201 seconds
[2021-08-18 16:28:37,368] {scheduler_job.py:182} INFO - Started process (PID=329) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:37,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:28:37,374] {logging_mixin.py:104} INFO - [2021-08-18 16:28:37,374] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:37,516] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:28:37,530] {logging_mixin.py:104} INFO - [2021-08-18 16:28:37,529] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:28:37,548] {logging_mixin.py:104} INFO - [2021-08-18 16:28:37,548] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:28:37.548334+00:00
[2021-08-18 16:28:37,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.197 seconds
[2021-08-18 16:29:07,654] {scheduler_job.py:182} INFO - Started process (PID=332) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:07,655] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:29:07,656] {logging_mixin.py:104} INFO - [2021-08-18 16:29:07,656] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:07,771] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:07,787] {logging_mixin.py:104} INFO - [2021-08-18 16:29:07,786] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:29:07,804] {logging_mixin.py:104} INFO - [2021-08-18 16:29:07,804] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:29:07.804011+00:00
[2021-08-18 16:29:07,812] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-08-18 16:29:37,899] {scheduler_job.py:182} INFO - Started process (PID=335) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:37,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:29:37,901] {logging_mixin.py:104} INFO - [2021-08-18 16:29:37,901] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:38,027] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:29:38,037] {logging_mixin.py:104} INFO - [2021-08-18 16:29:38,037] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:29:38,053] {logging_mixin.py:104} INFO - [2021-08-18 16:29:38,053] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:29:38.052995+00:00
[2021-08-18 16:29:38,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-08-18 16:30:08,157] {scheduler_job.py:182} INFO - Started process (PID=338) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:08,158] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:30:08,159] {logging_mixin.py:104} INFO - [2021-08-18 16:30:08,159] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:08,285] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:08,296] {logging_mixin.py:104} INFO - [2021-08-18 16:30:08,296] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:30:08,313] {logging_mixin.py:104} INFO - [2021-08-18 16:30:08,312] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:30:08.312727+00:00
[2021-08-18 16:30:08,324] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.170 seconds
[2021-08-18 16:30:38,429] {scheduler_job.py:182} INFO - Started process (PID=341) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:38,432] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:30:38,433] {logging_mixin.py:104} INFO - [2021-08-18 16:30:38,432] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:38,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:30:38,546] {logging_mixin.py:104} INFO - [2021-08-18 16:30:38,546] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:30:38,559] {logging_mixin.py:104} INFO - [2021-08-18 16:30:38,559] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:30:38.559570+00:00
[2021-08-18 16:30:38,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.143 seconds
[2021-08-18 16:31:08,665] {scheduler_job.py:182} INFO - Started process (PID=344) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:08,665] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:31:08,666] {logging_mixin.py:104} INFO - [2021-08-18 16:31:08,666] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:08,769] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:08,781] {logging_mixin.py:104} INFO - [2021-08-18 16:31:08,781] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:31:08,797] {logging_mixin.py:104} INFO - [2021-08-18 16:31:08,797] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:31:08.797235+00:00
[2021-08-18 16:31:08,807] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.145 seconds
[2021-08-18 16:31:38,894] {scheduler_job.py:182} INFO - Started process (PID=347) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:38,895] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:31:38,896] {logging_mixin.py:104} INFO - [2021-08-18 16:31:38,896] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:38,997] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:31:39,008] {logging_mixin.py:104} INFO - [2021-08-18 16:31:39,008] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:31:39,023] {logging_mixin.py:104} INFO - [2021-08-18 16:31:39,023] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:31:39.023521+00:00
[2021-08-18 16:31:39,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.142 seconds
[2021-08-18 16:32:09,145] {scheduler_job.py:182} INFO - Started process (PID=350) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:09,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:32:09,147] {logging_mixin.py:104} INFO - [2021-08-18 16:32:09,147] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:09,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:09,247] {logging_mixin.py:104} INFO - [2021-08-18 16:32:09,247] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:32:09,262] {logging_mixin.py:104} INFO - [2021-08-18 16:32:09,261] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:32:09.261799+00:00
[2021-08-18 16:32:09,270] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.130 seconds
[2021-08-18 16:32:39,371] {scheduler_job.py:182} INFO - Started process (PID=353) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:39,372] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:32:39,373] {logging_mixin.py:104} INFO - [2021-08-18 16:32:39,373] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:39,503] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:32:39,513] {logging_mixin.py:104} INFO - [2021-08-18 16:32:39,513] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:32:39,528] {logging_mixin.py:104} INFO - [2021-08-18 16:32:39,528] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:32:39.528534+00:00
[2021-08-18 16:32:39,536] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-08-18 16:33:09,628] {scheduler_job.py:182} INFO - Started process (PID=356) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:09,629] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:33:09,630] {logging_mixin.py:104} INFO - [2021-08-18 16:33:09,630] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:09,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:09,729] {logging_mixin.py:104} INFO - [2021-08-18 16:33:09,728] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:33:09,743] {logging_mixin.py:104} INFO - [2021-08-18 16:33:09,743] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:33:09.742887+00:00
[2021-08-18 16:33:09,752] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 16:33:39,858] {scheduler_job.py:182} INFO - Started process (PID=359) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:39,860] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:33:39,861] {logging_mixin.py:104} INFO - [2021-08-18 16:33:39,861] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:39,948] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:33:39,957] {logging_mixin.py:104} INFO - [2021-08-18 16:33:39,957] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:33:39,969] {logging_mixin.py:104} INFO - [2021-08-18 16:33:39,969] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:33:39.969355+00:00
[2021-08-18 16:33:39,976] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.123 seconds
[2021-08-18 16:34:10,083] {scheduler_job.py:182} INFO - Started process (PID=362) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:10,084] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:34:10,085] {logging_mixin.py:104} INFO - [2021-08-18 16:34:10,085] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:10,176] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:10,185] {logging_mixin.py:104} INFO - [2021-08-18 16:34:10,185] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:34:10,198] {logging_mixin.py:104} INFO - [2021-08-18 16:34:10,198] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:34:10.198427+00:00
[2021-08-18 16:34:10,207] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 16:34:40,310] {scheduler_job.py:182} INFO - Started process (PID=365) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:40,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:34:40,313] {logging_mixin.py:104} INFO - [2021-08-18 16:34:40,313] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:40,402] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:34:40,411] {logging_mixin.py:104} INFO - [2021-08-18 16:34:40,411] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:34:40,423] {logging_mixin.py:104} INFO - [2021-08-18 16:34:40,423] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:34:40.423287+00:00
[2021-08-18 16:34:40,432] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.126 seconds
[2021-08-18 16:35:10,535] {scheduler_job.py:182} INFO - Started process (PID=368) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:10,536] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:35:10,537] {logging_mixin.py:104} INFO - [2021-08-18 16:35:10,537] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:10,626] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:10,635] {logging_mixin.py:104} INFO - [2021-08-18 16:35:10,635] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:35:10,647] {logging_mixin.py:104} INFO - [2021-08-18 16:35:10,647] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:35:10.647610+00:00
[2021-08-18 16:35:10,655] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-18 16:35:40,747] {scheduler_job.py:182} INFO - Started process (PID=371) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:40,748] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:35:40,748] {logging_mixin.py:104} INFO - [2021-08-18 16:35:40,748] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:40,842] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:35:40,854] {logging_mixin.py:104} INFO - [2021-08-18 16:35:40,854] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:35:40,866] {logging_mixin.py:104} INFO - [2021-08-18 16:35:40,866] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:35:40.866379+00:00
[2021-08-18 16:35:40,873] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.128 seconds
[2021-08-18 16:36:10,971] {scheduler_job.py:182} INFO - Started process (PID=374) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:10,972] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:36:10,973] {logging_mixin.py:104} INFO - [2021-08-18 16:36:10,972] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:11,065] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:11,074] {logging_mixin.py:104} INFO - [2021-08-18 16:36:11,073] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:36:11,089] {logging_mixin.py:104} INFO - [2021-08-18 16:36:11,089] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:36:11.089436+00:00
[2021-08-18 16:36:11,098] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.129 seconds
[2021-08-18 16:36:41,206] {scheduler_job.py:182} INFO - Started process (PID=377) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:41,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:36:41,207] {logging_mixin.py:104} INFO - [2021-08-18 16:36:41,207] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:41,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:36:41,303] {logging_mixin.py:104} INFO - [2021-08-18 16:36:41,303] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:36:41,315] {logging_mixin.py:104} INFO - [2021-08-18 16:36:41,315] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:36:41.315106+00:00
[2021-08-18 16:36:41,323] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.119 seconds
[2021-08-18 16:37:11,460] {scheduler_job.py:182} INFO - Started process (PID=380) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:11,462] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:37:11,463] {logging_mixin.py:104} INFO - [2021-08-18 16:37:11,462] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:11,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:11,561] {logging_mixin.py:104} INFO - [2021-08-18 16:37:11,561] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:37:11,574] {logging_mixin.py:104} INFO - [2021-08-18 16:37:11,574] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:37:11.574710+00:00
[2021-08-18 16:37:11,582] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.127 seconds
[2021-08-18 16:37:41,684] {scheduler_job.py:182} INFO - Started process (PID=383) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:41,685] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:37:41,686] {logging_mixin.py:104} INFO - [2021-08-18 16:37:41,686] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:41,776] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:37:41,784] {logging_mixin.py:104} INFO - [2021-08-18 16:37:41,784] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:37:41,796] {logging_mixin.py:104} INFO - [2021-08-18 16:37:41,796] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:37:41.796113+00:00
[2021-08-18 16:37:41,803] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.121 seconds
[2021-08-18 16:38:11,918] {scheduler_job.py:182} INFO - Started process (PID=386) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:11,919] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:38:11,920] {logging_mixin.py:104} INFO - [2021-08-18 16:38:11,920] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:12,010] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:12,018] {logging_mixin.py:104} INFO - [2021-08-18 16:38:12,018] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:38:12,030] {logging_mixin.py:104} INFO - [2021-08-18 16:38:12,030] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:38:12.030512+00:00
[2021-08-18 16:38:12,038] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.124 seconds
[2021-08-18 16:38:42,156] {scheduler_job.py:182} INFO - Started process (PID=389) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:42,157] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 16:38:42,157] {logging_mixin.py:104} INFO - [2021-08-18 16:38:42,157] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:42,246] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 16:38:42,254] {logging_mixin.py:104} INFO - [2021-08-18 16:38:42,254] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 16:38:42,266] {logging_mixin.py:104} INFO - [2021-08-18 16:38:42,266] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 16:38:42.266262+00:00
[2021-08-18 16:38:42,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.120 seconds
[2021-08-18 18:28:14,108] {scheduler_job.py:182} INFO - Started process (PID=392) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:14,109] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:28:14,110] {logging_mixin.py:104} INFO - [2021-08-18 18:28:14,110] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:14,362] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:14,375] {logging_mixin.py:104} INFO - [2021-08-18 18:28:14,375] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:28:14,396] {logging_mixin.py:104} INFO - [2021-08-18 18:28:14,396] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:28:14.396528+00:00
[2021-08-18 18:28:14,411] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.308 seconds
[2021-08-18 18:28:44,537] {scheduler_job.py:182} INFO - Started process (PID=395) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:44,538] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:28:44,539] {logging_mixin.py:104} INFO - [2021-08-18 18:28:44,539] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:44,669] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:28:44,681] {logging_mixin.py:104} INFO - [2021-08-18 18:28:44,681] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:28:44,699] {logging_mixin.py:104} INFO - [2021-08-18 18:28:44,699] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:28:44.699297+00:00
[2021-08-18 18:28:44,711] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.178 seconds
[2021-08-18 18:29:14,831] {scheduler_job.py:182} INFO - Started process (PID=398) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:14,832] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:29:14,833] {logging_mixin.py:104} INFO - [2021-08-18 18:29:14,833] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:14,954] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:14,966] {logging_mixin.py:104} INFO - [2021-08-18 18:29:14,966] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:29:14,982] {logging_mixin.py:104} INFO - [2021-08-18 18:29:14,982] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:29:14.981996+00:00
[2021-08-18 18:29:14,993] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 18:29:45,109] {scheduler_job.py:182} INFO - Started process (PID=401) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:45,110] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:29:45,111] {logging_mixin.py:104} INFO - [2021-08-18 18:29:45,111] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:45,235] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:29:45,246] {logging_mixin.py:104} INFO - [2021-08-18 18:29:45,246] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:29:45,262] {logging_mixin.py:104} INFO - [2021-08-18 18:29:45,262] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:29:45.262417+00:00
[2021-08-18 18:29:45,273] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-08-18 18:30:15,396] {scheduler_job.py:182} INFO - Started process (PID=404) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:15,397] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:30:15,398] {logging_mixin.py:104} INFO - [2021-08-18 18:30:15,398] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:15,521] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:15,532] {logging_mixin.py:104} INFO - [2021-08-18 18:30:15,532] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:30:15,547] {logging_mixin.py:104} INFO - [2021-08-18 18:30:15,546] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:30:15.546852+00:00
[2021-08-18 18:30:15,557] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 18:30:45,677] {scheduler_job.py:182} INFO - Started process (PID=407) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:45,679] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:30:45,680] {logging_mixin.py:104} INFO - [2021-08-18 18:30:45,680] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:45,861] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:30:45,874] {logging_mixin.py:104} INFO - [2021-08-18 18:30:45,873] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:30:45,891] {logging_mixin.py:104} INFO - [2021-08-18 18:30:45,891] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:30:45.891326+00:00
[2021-08-18 18:30:45,904] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 18:31:16,034] {scheduler_job.py:182} INFO - Started process (PID=410) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:16,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:31:16,036] {logging_mixin.py:104} INFO - [2021-08-18 18:31:16,036] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:16,177] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:16,189] {logging_mixin.py:104} INFO - [2021-08-18 18:31:16,189] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:31:16,205] {logging_mixin.py:104} INFO - [2021-08-18 18:31:16,205] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:31:16.205641+00:00
[2021-08-18 18:31:16,216] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.187 seconds
[2021-08-18 18:31:46,339] {scheduler_job.py:182} INFO - Started process (PID=413) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:46,340] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:31:46,341] {logging_mixin.py:104} INFO - [2021-08-18 18:31:46,341] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:46,466] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:31:46,477] {logging_mixin.py:104} INFO - [2021-08-18 18:31:46,477] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:31:46,492] {logging_mixin.py:104} INFO - [2021-08-18 18:31:46,492] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:31:46.492222+00:00
[2021-08-18 18:31:46,502] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.166 seconds
[2021-08-18 18:32:16,619] {scheduler_job.py:182} INFO - Started process (PID=416) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:16,620] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:32:16,621] {logging_mixin.py:104} INFO - [2021-08-18 18:32:16,621] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:16,746] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:16,757] {logging_mixin.py:104} INFO - [2021-08-18 18:32:16,757] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:32:16,773] {logging_mixin.py:104} INFO - [2021-08-18 18:32:16,773] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:32:16.772942+00:00
[2021-08-18 18:32:16,783] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-08-18 18:32:46,900] {scheduler_job.py:182} INFO - Started process (PID=419) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:46,901] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:32:46,902] {logging_mixin.py:104} INFO - [2021-08-18 18:32:46,902] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:47,033] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:32:47,044] {logging_mixin.py:104} INFO - [2021-08-18 18:32:47,044] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:32:47,059] {logging_mixin.py:104} INFO - [2021-08-18 18:32:47,059] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:32:47.058936+00:00
[2021-08-18 18:32:47,069] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-08-18 18:33:17,211] {scheduler_job.py:182} INFO - Started process (PID=422) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:17,213] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:33:17,214] {logging_mixin.py:104} INFO - [2021-08-18 18:33:17,214] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:17,338] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:17,350] {logging_mixin.py:104} INFO - [2021-08-18 18:33:17,350] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:33:17,365] {logging_mixin.py:104} INFO - [2021-08-18 18:33:17,365] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:33:17.365476+00:00
[2021-08-18 18:33:17,376] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.167 seconds
[2021-08-18 18:33:47,498] {scheduler_job.py:182} INFO - Started process (PID=425) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:47,500] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:33:47,500] {logging_mixin.py:104} INFO - [2021-08-18 18:33:47,500] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:47,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:33:47,634] {logging_mixin.py:104} INFO - [2021-08-18 18:33:47,634] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:33:47,650] {logging_mixin.py:104} INFO - [2021-08-18 18:33:47,650] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:33:47.650192+00:00
[2021-08-18 18:33:47,660] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 18:34:17,773] {scheduler_job.py:182} INFO - Started process (PID=428) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:17,775] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:34:17,776] {logging_mixin.py:104} INFO - [2021-08-18 18:34:17,776] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:17,947] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:17,964] {logging_mixin.py:104} INFO - [2021-08-18 18:34:17,964] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:34:17,988] {logging_mixin.py:104} INFO - [2021-08-18 18:34:17,987] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:34:17.987667+00:00
[2021-08-18 18:34:18,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.233 seconds
[2021-08-18 18:34:48,115] {scheduler_job.py:182} INFO - Started process (PID=431) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:48,116] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:34:48,116] {logging_mixin.py:104} INFO - [2021-08-18 18:34:48,116] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:48,243] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:34:48,254] {logging_mixin.py:104} INFO - [2021-08-18 18:34:48,254] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:34:48,270] {logging_mixin.py:104} INFO - [2021-08-18 18:34:48,270] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:34:48.269872+00:00
[2021-08-18 18:34:48,281] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-08-18 18:35:18,403] {scheduler_job.py:182} INFO - Started process (PID=434) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:18,405] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:35:18,406] {logging_mixin.py:104} INFO - [2021-08-18 18:35:18,406] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:18,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:18,637] {logging_mixin.py:104} INFO - [2021-08-18 18:35:18,637] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:35:18,677] {logging_mixin.py:104} INFO - [2021-08-18 18:35:18,677] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:35:18.677449+00:00
[2021-08-18 18:35:18,691] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.293 seconds
[2021-08-18 18:35:48,802] {scheduler_job.py:182} INFO - Started process (PID=437) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:48,804] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:35:48,805] {logging_mixin.py:104} INFO - [2021-08-18 18:35:48,805] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:48,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:35:48,980] {logging_mixin.py:104} INFO - [2021-08-18 18:35:48,980] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:35:49,001] {logging_mixin.py:104} INFO - [2021-08-18 18:35:49,000] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:35:49.000804+00:00
[2021-08-18 18:35:49,012] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.215 seconds
[2021-08-18 18:36:19,132] {scheduler_job.py:182} INFO - Started process (PID=440) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:19,133] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:36:19,134] {logging_mixin.py:104} INFO - [2021-08-18 18:36:19,134] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:19,261] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:19,272] {logging_mixin.py:104} INFO - [2021-08-18 18:36:19,272] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:36:19,287] {logging_mixin.py:104} INFO - [2021-08-18 18:36:19,287] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:36:19.286897+00:00
[2021-08-18 18:36:19,297] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-08-18 18:36:49,408] {scheduler_job.py:182} INFO - Started process (PID=443) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:49,409] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:36:49,410] {logging_mixin.py:104} INFO - [2021-08-18 18:36:49,410] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:49,543] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:36:49,554] {logging_mixin.py:104} INFO - [2021-08-18 18:36:49,554] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:36:49,570] {logging_mixin.py:104} INFO - [2021-08-18 18:36:49,570] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:36:49.569983+00:00
[2021-08-18 18:36:49,580] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.176 seconds
[2021-08-18 18:37:19,699] {scheduler_job.py:182} INFO - Started process (PID=446) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:19,700] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:37:19,701] {logging_mixin.py:104} INFO - [2021-08-18 18:37:19,700] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:19,822] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:19,834] {logging_mixin.py:104} INFO - [2021-08-18 18:37:19,834] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:37:19,849] {logging_mixin.py:104} INFO - [2021-08-18 18:37:19,849] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:37:19.849418+00:00
[2021-08-18 18:37:19,860] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 18:37:49,979] {scheduler_job.py:182} INFO - Started process (PID=449) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:49,981] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:37:49,982] {logging_mixin.py:104} INFO - [2021-08-18 18:37:49,981] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:50,148] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:37:50,165] {logging_mixin.py:104} INFO - [2021-08-18 18:37:50,164] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:37:50,185] {logging_mixin.py:104} INFO - [2021-08-18 18:37:50,185] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:37:50.185389+00:00
[2021-08-18 18:37:50,199] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.225 seconds
[2021-08-18 18:38:20,338] {scheduler_job.py:182} INFO - Started process (PID=452) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:20,339] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:38:20,340] {logging_mixin.py:104} INFO - [2021-08-18 18:38:20,340] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:20,463] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:20,475] {logging_mixin.py:104} INFO - [2021-08-18 18:38:20,475] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:38:20,490] {logging_mixin.py:104} INFO - [2021-08-18 18:38:20,490] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:38:20.490703+00:00
[2021-08-18 18:38:20,501] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.168 seconds
[2021-08-18 18:38:50,622] {scheduler_job.py:182} INFO - Started process (PID=455) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:50,623] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:38:50,624] {logging_mixin.py:104} INFO - [2021-08-18 18:38:50,624] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:50,742] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:38:50,753] {logging_mixin.py:104} INFO - [2021-08-18 18:38:50,753] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:38:50,767] {logging_mixin.py:104} INFO - [2021-08-18 18:38:50,767] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:38:50.767471+00:00
[2021-08-18 18:38:50,778] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.159 seconds
[2021-08-18 18:39:20,903] {scheduler_job.py:182} INFO - Started process (PID=458) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:20,906] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:39:20,907] {logging_mixin.py:104} INFO - [2021-08-18 18:39:20,906] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:21,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:21,082] {logging_mixin.py:104} INFO - [2021-08-18 18:39:21,082] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:39:21,101] {logging_mixin.py:104} INFO - [2021-08-18 18:39:21,101] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:39:21.101225+00:00
[2021-08-18 18:39:21,115] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.221 seconds
[2021-08-18 18:39:51,233] {scheduler_job.py:182} INFO - Started process (PID=461) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:51,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:39:51,236] {logging_mixin.py:104} INFO - [2021-08-18 18:39:51,236] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:51,384] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:39:51,397] {logging_mixin.py:104} INFO - [2021-08-18 18:39:51,396] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:39:51,412] {logging_mixin.py:104} INFO - [2021-08-18 18:39:51,412] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:39:51.412394+00:00
[2021-08-18 18:39:51,423] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.195 seconds
[2021-08-18 18:40:21,546] {scheduler_job.py:182} INFO - Started process (PID=464) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:21,547] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:40:21,547] {logging_mixin.py:104} INFO - [2021-08-18 18:40:21,547] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:21,664] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:21,675] {logging_mixin.py:104} INFO - [2021-08-18 18:40:21,675] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:40:21,690] {logging_mixin.py:104} INFO - [2021-08-18 18:40:21,690] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:40:21.690050+00:00
[2021-08-18 18:40:21,701] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.158 seconds
[2021-08-18 18:40:51,824] {scheduler_job.py:182} INFO - Started process (PID=467) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:51,826] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:40:51,826] {logging_mixin.py:104} INFO - [2021-08-18 18:40:51,826] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:51,961] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:40:51,973] {logging_mixin.py:104} INFO - [2021-08-18 18:40:51,973] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:40:51,988] {logging_mixin.py:104} INFO - [2021-08-18 18:40:51,988] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:40:51.987915+00:00
[2021-08-18 18:40:51,999] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.178 seconds
[2021-08-18 18:41:22,127] {scheduler_job.py:182} INFO - Started process (PID=470) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:22,128] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:41:22,129] {logging_mixin.py:104} INFO - [2021-08-18 18:41:22,129] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:22,303] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:22,319] {logging_mixin.py:104} INFO - [2021-08-18 18:41:22,319] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:41:22,339] {logging_mixin.py:104} INFO - [2021-08-18 18:41:22,339] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:41:22.338951+00:00
[2021-08-18 18:41:22,353] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.230 seconds
[2021-08-18 18:41:52,479] {scheduler_job.py:182} INFO - Started process (PID=473) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:52,480] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:41:52,480] {logging_mixin.py:104} INFO - [2021-08-18 18:41:52,480] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:52,599] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:41:52,610] {logging_mixin.py:104} INFO - [2021-08-18 18:41:52,610] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:41:52,626] {logging_mixin.py:104} INFO - [2021-08-18 18:41:52,626] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:41:52.626136+00:00
[2021-08-18 18:41:52,637] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-08-18 18:42:22,750] {scheduler_job.py:182} INFO - Started process (PID=476) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:22,751] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:42:22,752] {logging_mixin.py:104} INFO - [2021-08-18 18:42:22,752] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:22,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:22,882] {logging_mixin.py:104} INFO - [2021-08-18 18:42:22,882] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:42:22,897] {logging_mixin.py:104} INFO - [2021-08-18 18:42:22,897] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:42:22.897185+00:00
[2021-08-18 18:42:22,908] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.161 seconds
[2021-08-18 18:42:53,024] {scheduler_job.py:182} INFO - Started process (PID=479) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:53,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:42:53,026] {logging_mixin.py:104} INFO - [2021-08-18 18:42:53,026] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:53,145] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:42:53,156] {logging_mixin.py:104} INFO - [2021-08-18 18:42:53,156] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:42:53,171] {logging_mixin.py:104} INFO - [2021-08-18 18:42:53,171] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:42:53.171176+00:00
[2021-08-18 18:42:53,182] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.160 seconds
[2021-08-18 18:43:23,321] {scheduler_job.py:182} INFO - Started process (PID=482) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:23,322] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:43:23,323] {logging_mixin.py:104} INFO - [2021-08-18 18:43:23,323] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:23,446] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:23,457] {logging_mixin.py:104} INFO - [2021-08-18 18:43:23,457] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:43:23,472] {logging_mixin.py:104} INFO - [2021-08-18 18:43:23,472] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:43:23.471870+00:00
[2021-08-18 18:43:23,481] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.164 seconds
[2021-08-18 18:43:53,602] {scheduler_job.py:182} INFO - Started process (PID=485) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:53,603] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:43:53,604] {logging_mixin.py:104} INFO - [2021-08-18 18:43:53,604] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:53,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:43:53,745] {logging_mixin.py:104} INFO - [2021-08-18 18:43:53,745] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:43:53,760] {logging_mixin.py:104} INFO - [2021-08-18 18:43:53,760] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:43:53.760305+00:00
[2021-08-18 18:43:53,771] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.174 seconds
[2021-08-18 18:44:23,888] {scheduler_job.py:182} INFO - Started process (PID=488) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:23,889] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:44:23,890] {logging_mixin.py:104} INFO - [2021-08-18 18:44:23,889] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:24,007] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:24,021] {logging_mixin.py:104} INFO - [2021-08-18 18:44:24,021] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:44:24,037] {logging_mixin.py:104} INFO - [2021-08-18 18:44:24,037] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:44:24.037281+00:00
[2021-08-18 18:44:24,058] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.173 seconds
[2021-08-18 18:44:54,206] {scheduler_job.py:182} INFO - Started process (PID=491) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:54,207] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:44:54,208] {logging_mixin.py:104} INFO - [2021-08-18 18:44:54,208] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:54,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:44:54,409] {logging_mixin.py:104} INFO - [2021-08-18 18:44:54,409] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:44:54,445] {logging_mixin.py:104} INFO - [2021-08-18 18:44:54,445] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:44:54.444902+00:00
[2021-08-18 18:44:54,456] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.257 seconds
[2021-08-18 18:45:24,580] {scheduler_job.py:182} INFO - Started process (PID=494) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:24,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:45:24,582] {logging_mixin.py:104} INFO - [2021-08-18 18:45:24,582] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:24,707] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:24,719] {logging_mixin.py:104} INFO - [2021-08-18 18:45:24,719] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:45:24,734] {logging_mixin.py:104} INFO - [2021-08-18 18:45:24,734] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:45:24.734383+00:00
[2021-08-18 18:45:24,745] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.169 seconds
[2021-08-18 18:45:54,857] {scheduler_job.py:182} INFO - Started process (PID=497) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:54,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:45:54,860] {logging_mixin.py:104} INFO - [2021-08-18 18:45:54,860] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:54,994] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:45:55,006] {logging_mixin.py:104} INFO - [2021-08-18 18:45:55,005] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:45:55,023] {logging_mixin.py:104} INFO - [2021-08-18 18:45:55,023] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:45:55.023398+00:00
[2021-08-18 18:45:55,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.181 seconds
[2021-08-18 18:46:25,161] {scheduler_job.py:182} INFO - Started process (PID=500) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:25,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:46:25,164] {logging_mixin.py:104} INFO - [2021-08-18 18:46:25,164] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:25,310] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:25,325] {logging_mixin.py:104} INFO - [2021-08-18 18:46:25,325] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:46:25,344] {logging_mixin.py:104} INFO - [2021-08-18 18:46:25,344] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:46:25.344159+00:00
[2021-08-18 18:46:25,356] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.200 seconds
[2021-08-18 18:46:55,485] {scheduler_job.py:182} INFO - Started process (PID=503) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:55,486] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:46:55,487] {logging_mixin.py:104} INFO - [2021-08-18 18:46:55,487] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:55,603] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:46:55,614] {logging_mixin.py:104} INFO - [2021-08-18 18:46:55,614] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:46:55,629] {logging_mixin.py:104} INFO - [2021-08-18 18:46:55,629] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:46:55.629462+00:00
[2021-08-18 18:46:55,640] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.157 seconds
[2021-08-18 18:47:25,767] {scheduler_job.py:182} INFO - Started process (PID=506) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:25,768] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:47:25,769] {logging_mixin.py:104} INFO - [2021-08-18 18:47:25,769] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:25,917] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:25,929] {logging_mixin.py:104} INFO - [2021-08-18 18:47:25,929] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:47:25,946] {logging_mixin.py:104} INFO - [2021-08-18 18:47:25,946] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:47:25.946247+00:00
[2021-08-18 18:47:25,957] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.195 seconds
[2021-08-18 18:47:56,074] {scheduler_job.py:182} INFO - Started process (PID=509) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:56,075] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:47:56,076] {logging_mixin.py:104} INFO - [2021-08-18 18:47:56,076] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:56,218] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:47:56,231] {logging_mixin.py:104} INFO - [2021-08-18 18:47:56,231] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:47:56,249] {logging_mixin.py:104} INFO - [2021-08-18 18:47:56,248] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:47:56.248660+00:00
[2021-08-18 18:47:56,262] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.190 seconds
[2021-08-18 18:48:26,395] {scheduler_job.py:182} INFO - Started process (PID=512) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:26,396] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:48:26,397] {logging_mixin.py:104} INFO - [2021-08-18 18:48:26,397] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:26,533] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:26,545] {logging_mixin.py:104} INFO - [2021-08-18 18:48:26,545] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:48:26,561] {logging_mixin.py:104} INFO - [2021-08-18 18:48:26,561] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:48:26.561567+00:00
[2021-08-18 18:48:26,571] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.180 seconds
[2021-08-18 18:48:56,694] {scheduler_job.py:182} INFO - Started process (PID=515) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:56,696] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:48:56,697] {logging_mixin.py:104} INFO - [2021-08-18 18:48:56,697] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:56,859] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:48:56,873] {logging_mixin.py:104} INFO - [2021-08-18 18:48:56,873] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:48:56,893] {logging_mixin.py:104} INFO - [2021-08-18 18:48:56,893] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:48:56.893245+00:00
[2021-08-18 18:48:56,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.214 seconds
[2021-08-18 18:49:27,023] {scheduler_job.py:182} INFO - Started process (PID=518) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:27,024] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:49:27,025] {logging_mixin.py:104} INFO - [2021-08-18 18:49:27,024] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:27,162] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:27,173] {logging_mixin.py:104} INFO - [2021-08-18 18:49:27,173] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:49:27,189] {logging_mixin.py:104} INFO - [2021-08-18 18:49:27,189] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:49:27.189639+00:00
[2021-08-18 18:49:27,200] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.180 seconds
[2021-08-18 18:49:57,312] {scheduler_job.py:182} INFO - Started process (PID=521) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:57,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:49:57,313] {logging_mixin.py:104} INFO - [2021-08-18 18:49:57,313] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:57,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:49:57,477] {logging_mixin.py:104} INFO - [2021-08-18 18:49:57,477] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:49:57,498] {logging_mixin.py:104} INFO - [2021-08-18 18:49:57,498] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:49:57.498208+00:00
[2021-08-18 18:49:57,512] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.204 seconds
[2021-08-18 18:50:27,632] {scheduler_job.py:182} INFO - Started process (PID=524) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:27,633] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:50:27,634] {logging_mixin.py:104} INFO - [2021-08-18 18:50:27,633] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:27,763] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:27,776] {logging_mixin.py:104} INFO - [2021-08-18 18:50:27,775] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:50:27,793] {logging_mixin.py:104} INFO - [2021-08-18 18:50:27,793] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:50:27.793440+00:00
[2021-08-18 18:50:28,292] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.663 seconds
[2021-08-18 18:50:58,406] {scheduler_job.py:182} INFO - Started process (PID=527) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:58,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:50:58,409] {logging_mixin.py:104} INFO - [2021-08-18 18:50:58,409] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:58,554] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:50:58,566] {logging_mixin.py:104} INFO - [2021-08-18 18:50:58,566] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:50:58,659] {logging_mixin.py:104} INFO - [2021-08-18 18:50:58,659] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:50:58.659440+00:00
[2021-08-18 18:50:58,670] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.268 seconds
[2021-08-18 18:51:28,792] {scheduler_job.py:182} INFO - Started process (PID=530) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:28,793] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:51:28,794] {logging_mixin.py:104} INFO - [2021-08-18 18:51:28,794] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:28,931] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:28,944] {logging_mixin.py:104} INFO - [2021-08-18 18:51:28,944] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:51:29,042] {logging_mixin.py:104} INFO - [2021-08-18 18:51:29,042] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:51:29.042072+00:00
[2021-08-18 18:51:29,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.265 seconds
[2021-08-18 18:51:59,166] {scheduler_job.py:182} INFO - Started process (PID=533) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:59,167] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:51:59,168] {logging_mixin.py:104} INFO - [2021-08-18 18:51:59,168] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:59,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:51:59,318] {logging_mixin.py:104} INFO - [2021-08-18 18:51:59,318] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:51:59,407] {logging_mixin.py:104} INFO - [2021-08-18 18:51:59,407] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:51:59.407444+00:00
[2021-08-18 18:51:59,419] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.256 seconds
[2021-08-18 18:52:29,541] {scheduler_job.py:182} INFO - Started process (PID=536) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:52:29,542] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:52:29,543] {logging_mixin.py:104} INFO - [2021-08-18 18:52:29,543] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:52:29,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:52:29,729] {logging_mixin.py:104} INFO - [2021-08-18 18:52:29,729] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:52:29,828] {logging_mixin.py:104} INFO - [2021-08-18 18:52:29,828] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:52:29.828319+00:00
[2021-08-18 18:52:29,839] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.302 seconds
[2021-08-18 18:52:59,956] {scheduler_job.py:182} INFO - Started process (PID=539) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:52:59,957] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:52:59,958] {logging_mixin.py:104} INFO - [2021-08-18 18:52:59,958] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:53:00,111] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:53:00,128] {logging_mixin.py:104} INFO - [2021-08-18 18:53:00,128] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:53:00,253] {logging_mixin.py:104} INFO - [2021-08-18 18:53:00,253] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:53:00.253277+00:00
[2021-08-18 18:53:00,270] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.317 seconds
[2021-08-18 18:53:30,417] {scheduler_job.py:182} INFO - Started process (PID=542) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:53:30,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:53:30,419] {logging_mixin.py:104} INFO - [2021-08-18 18:53:30,419] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:53:30,611] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:53:30,636] {logging_mixin.py:104} INFO - [2021-08-18 18:53:30,636] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:53:30,760] {logging_mixin.py:104} INFO - [2021-08-18 18:53:30,760] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:53:30.760508+00:00
[2021-08-18 18:53:30,775] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.361 seconds
[2021-08-18 18:54:00,892] {scheduler_job.py:182} INFO - Started process (PID=545) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:00,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:54:00,894] {logging_mixin.py:104} INFO - [2021-08-18 18:54:00,894] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:01,064] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:01,080] {logging_mixin.py:104} INFO - [2021-08-18 18:54:01,080] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:54:01,179] {logging_mixin.py:104} INFO - [2021-08-18 18:54:01,179] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:54:01.179215+00:00
[2021-08-18 18:54:01,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.302 seconds
[2021-08-18 18:54:31,312] {scheduler_job.py:182} INFO - Started process (PID=548) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:31,313] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:54:31,314] {logging_mixin.py:104} INFO - [2021-08-18 18:54:31,313] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:31,455] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:54:31,467] {logging_mixin.py:104} INFO - [2021-08-18 18:54:31,467] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:54:31,562] {logging_mixin.py:104} INFO - [2021-08-18 18:54:31,562] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:54:31.561901+00:00
[2021-08-18 18:54:31,577] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.269 seconds
[2021-08-18 18:55:01,702] {scheduler_job.py:182} INFO - Started process (PID=551) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:01,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:55:01,704] {logging_mixin.py:104} INFO - [2021-08-18 18:55:01,703] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:01,833] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:01,911] {logging_mixin.py:104} INFO - [2021-08-18 18:55:01,911] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:55:01,925] {logging_mixin.py:104} INFO - [2021-08-18 18:55:01,925] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:55:01.925120+00:00
[2021-08-18 18:55:01,936] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.237 seconds
[2021-08-18 18:55:32,061] {scheduler_job.py:182} INFO - Started process (PID=554) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:32,062] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:55:32,062] {logging_mixin.py:104} INFO - [2021-08-18 18:55:32,062] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:32,181] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:55:32,268] {logging_mixin.py:104} INFO - [2021-08-18 18:55:32,268] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:55:32,285] {logging_mixin.py:104} INFO - [2021-08-18 18:55:32,285] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:55:32.284883+00:00
[2021-08-18 18:55:32,297] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.239 seconds
[2021-08-18 18:56:02,418] {scheduler_job.py:182} INFO - Started process (PID=557) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:02,419] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:56:02,420] {logging_mixin.py:104} INFO - [2021-08-18 18:56:02,419] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:02,538] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:02,616] {logging_mixin.py:104} INFO - [2021-08-18 18:56:02,616] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:56:02,629] {logging_mixin.py:104} INFO - [2021-08-18 18:56:02,629] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:56:02.629639+00:00
[2021-08-18 18:56:02,641] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-08-18 18:56:32,768] {scheduler_job.py:182} INFO - Started process (PID=560) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:32,769] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:56:32,770] {logging_mixin.py:104} INFO - [2021-08-18 18:56:32,770] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:32,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:56:32,967] {logging_mixin.py:104} INFO - [2021-08-18 18:56:32,967] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:56:32,981] {logging_mixin.py:104} INFO - [2021-08-18 18:56:32,981] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:56:32.981048+00:00
[2021-08-18 18:56:32,992] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.227 seconds
[2021-08-18 18:57:03,117] {scheduler_job.py:182} INFO - Started process (PID=563) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:03,118] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:57:03,119] {logging_mixin.py:104} INFO - [2021-08-18 18:57:03,119] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:03,239] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:03,319] {logging_mixin.py:104} INFO - [2021-08-18 18:57:03,319] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:57:03,332] {logging_mixin.py:104} INFO - [2021-08-18 18:57:03,332] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:57:03.332430+00:00
[2021-08-18 18:57:03,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 18:57:33,459] {scheduler_job.py:182} INFO - Started process (PID=566) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:33,461] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:57:33,461] {logging_mixin.py:104} INFO - [2021-08-18 18:57:33,461] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:33,646] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:57:33,660] {logging_mixin.py:104} INFO - [2021-08-18 18:57:33,660] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:57:33,681] {logging_mixin.py:104} INFO - [2021-08-18 18:57:33,681] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:57:33.681203+00:00
[2021-08-18 18:57:33,695] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.238 seconds
[2021-08-18 18:58:03,815] {scheduler_job.py:182} INFO - Started process (PID=569) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:03,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:58:03,817] {logging_mixin.py:104} INFO - [2021-08-18 18:58:03,817] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:04,001] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:04,012] {logging_mixin.py:104} INFO - [2021-08-18 18:58:04,011] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:58:04,025] {logging_mixin.py:104} INFO - [2021-08-18 18:58:04,025] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:58:04.025620+00:00
[2021-08-18 18:58:04,036] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 18:58:34,190] {scheduler_job.py:182} INFO - Started process (PID=572) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:34,191] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:58:34,192] {logging_mixin.py:104} INFO - [2021-08-18 18:58:34,192] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:34,378] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:58:34,388] {logging_mixin.py:104} INFO - [2021-08-18 18:58:34,388] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:58:34,402] {logging_mixin.py:104} INFO - [2021-08-18 18:58:34,402] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:58:34.402395+00:00
[2021-08-18 18:58:34,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.225 seconds
[2021-08-18 18:59:04,540] {scheduler_job.py:182} INFO - Started process (PID=575) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:04,541] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:59:04,542] {logging_mixin.py:104} INFO - [2021-08-18 18:59:04,542] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:04,782] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:04,797] {logging_mixin.py:104} INFO - [2021-08-18 18:59:04,796] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:59:04,815] {logging_mixin.py:104} INFO - [2021-08-18 18:59:04,815] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:59:04.815361+00:00
[2021-08-18 18:59:04,826] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.289 seconds
[2021-08-18 18:59:34,949] {scheduler_job.py:182} INFO - Started process (PID=578) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:34,950] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 18:59:34,950] {logging_mixin.py:104} INFO - [2021-08-18 18:59:34,950] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:35,180] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 18:59:35,191] {logging_mixin.py:104} INFO - [2021-08-18 18:59:35,191] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 18:59:35,205] {logging_mixin.py:104} INFO - [2021-08-18 18:59:35,205] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 18:59:35.205450+00:00
[2021-08-18 18:59:35,215] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.269 seconds
[2021-08-18 19:00:05,333] {scheduler_job.py:182} INFO - Started process (PID=581) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:05,334] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:00:05,335] {logging_mixin.py:104} INFO - [2021-08-18 19:00:05,335] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:05,529] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:05,539] {logging_mixin.py:104} INFO - [2021-08-18 19:00:05,539] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:00:05,552] {logging_mixin.py:104} INFO - [2021-08-18 19:00:05,552] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:00:05.551887+00:00
[2021-08-18 19:00:05,561] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 19:00:35,687] {scheduler_job.py:182} INFO - Started process (PID=584) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:35,688] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:00:35,688] {logging_mixin.py:104} INFO - [2021-08-18 19:00:35,688] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:35,887] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:00:35,898] {logging_mixin.py:104} INFO - [2021-08-18 19:00:35,898] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:00:35,910] {logging_mixin.py:104} INFO - [2021-08-18 19:00:35,910] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:00:35.910264+00:00
[2021-08-18 19:00:35,920] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.237 seconds
[2021-08-18 19:01:06,039] {scheduler_job.py:182} INFO - Started process (PID=587) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:06,041] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:01:06,042] {logging_mixin.py:104} INFO - [2021-08-18 19:01:06,042] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:06,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:06,318] {logging_mixin.py:104} INFO - [2021-08-18 19:01:06,318] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:01:06,336] {logging_mixin.py:104} INFO - [2021-08-18 19:01:06,336] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:01:06.336124+00:00
[2021-08-18 19:01:06,351] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.317 seconds
[2021-08-18 19:01:36,471] {scheduler_job.py:182} INFO - Started process (PID=590) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:36,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:01:36,473] {logging_mixin.py:104} INFO - [2021-08-18 19:01:36,472] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:36,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:01:36,709] {logging_mixin.py:104} INFO - [2021-08-18 19:01:36,709] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:01:36,731] {logging_mixin.py:104} INFO - [2021-08-18 19:01:36,731] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:01:36.731428+00:00
[2021-08-18 19:01:36,742] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.275 seconds
[2021-08-18 19:02:06,855] {scheduler_job.py:182} INFO - Started process (PID=593) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:06,857] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:02:06,857] {logging_mixin.py:104} INFO - [2021-08-18 19:02:06,857] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:07,078] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:07,089] {logging_mixin.py:104} INFO - [2021-08-18 19:02:07,089] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:02:07,106] {logging_mixin.py:104} INFO - [2021-08-18 19:02:07,106] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:02:07.105913+00:00
[2021-08-18 19:02:07,121] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.270 seconds
[2021-08-18 19:02:37,237] {scheduler_job.py:182} INFO - Started process (PID=596) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:37,238] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:02:37,239] {logging_mixin.py:104} INFO - [2021-08-18 19:02:37,239] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:37,459] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:02:37,472] {logging_mixin.py:104} INFO - [2021-08-18 19:02:37,472] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:02:37,486] {logging_mixin.py:104} INFO - [2021-08-18 19:02:37,486] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:02:37.486296+00:00
[2021-08-18 19:02:37,497] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 19:03:07,614] {scheduler_job.py:182} INFO - Started process (PID=599) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:07,616] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:03:07,616] {logging_mixin.py:104} INFO - [2021-08-18 19:03:07,616] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:07,833] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:07,845] {logging_mixin.py:104} INFO - [2021-08-18 19:03:07,845] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:03:07,859] {logging_mixin.py:104} INFO - [2021-08-18 19:03:07,859] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:03:07.859340+00:00
[2021-08-18 19:03:07,870] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.261 seconds
[2021-08-18 19:03:38,013] {scheduler_job.py:182} INFO - Started process (PID=602) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:38,014] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:03:38,014] {logging_mixin.py:104} INFO - [2021-08-18 19:03:38,014] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:38,225] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:03:38,236] {logging_mixin.py:104} INFO - [2021-08-18 19:03:38,236] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:03:38,253] {logging_mixin.py:104} INFO - [2021-08-18 19:03:38,252] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:03:38.252661+00:00
[2021-08-18 19:03:38,264] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.255 seconds
[2021-08-18 19:04:08,398] {scheduler_job.py:182} INFO - Started process (PID=605) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:08,400] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:04:08,400] {logging_mixin.py:104} INFO - [2021-08-18 19:04:08,400] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:08,691] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:08,703] {logging_mixin.py:104} INFO - [2021-08-18 19:04:08,703] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:04:08,720] {logging_mixin.py:104} INFO - [2021-08-18 19:04:08,719] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:04:08.719710+00:00
[2021-08-18 19:04:08,732] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.338 seconds
[2021-08-18 19:04:38,854] {scheduler_job.py:182} INFO - Started process (PID=608) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:38,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:04:38,856] {logging_mixin.py:104} INFO - [2021-08-18 19:04:38,856] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:39,158] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:04:39,172] {logging_mixin.py:104} INFO - [2021-08-18 19:04:39,172] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:04:39,192] {logging_mixin.py:104} INFO - [2021-08-18 19:04:39,192] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:04:39.191936+00:00
[2021-08-18 19:04:39,204] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.354 seconds
[2021-08-18 19:05:09,315] {scheduler_job.py:182} INFO - Started process (PID=611) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:09,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:05:09,317] {logging_mixin.py:104} INFO - [2021-08-18 19:05:09,317] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:09,568] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:09,579] {logging_mixin.py:104} INFO - [2021-08-18 19:05:09,579] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:05:09,593] {logging_mixin.py:104} INFO - [2021-08-18 19:05:09,593] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:05:09.592959+00:00
[2021-08-18 19:05:09,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.293 seconds
[2021-08-18 19:05:39,719] {scheduler_job.py:182} INFO - Started process (PID=614) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:39,720] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:05:39,721] {logging_mixin.py:104} INFO - [2021-08-18 19:05:39,721] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:39,965] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:05:39,979] {logging_mixin.py:104} INFO - [2021-08-18 19:05:39,979] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:05:39,997] {logging_mixin.py:104} INFO - [2021-08-18 19:05:39,996] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:05:39.996815+00:00
[2021-08-18 19:05:40,009] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.293 seconds
[2021-08-18 19:06:10,129] {scheduler_job.py:182} INFO - Started process (PID=617) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:10,130] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:06:10,131] {logging_mixin.py:104} INFO - [2021-08-18 19:06:10,131] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:10,377] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:10,388] {logging_mixin.py:104} INFO - [2021-08-18 19:06:10,388] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:06:10,401] {logging_mixin.py:104} INFO - [2021-08-18 19:06:10,401] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:06:10.401358+00:00
[2021-08-18 19:06:10,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.286 seconds
[2021-08-18 19:06:40,538] {scheduler_job.py:182} INFO - Started process (PID=620) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:40,540] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:06:40,541] {logging_mixin.py:104} INFO - [2021-08-18 19:06:40,541] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:40,791] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:06:40,803] {logging_mixin.py:104} INFO - [2021-08-18 19:06:40,803] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:06:40,817] {logging_mixin.py:104} INFO - [2021-08-18 19:06:40,817] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:06:40.817448+00:00
[2021-08-18 19:06:40,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.297 seconds
[2021-08-18 19:07:10,946] {scheduler_job.py:182} INFO - Started process (PID=623) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:10,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:07:10,948] {logging_mixin.py:104} INFO - [2021-08-18 19:07:10,948] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:11,226] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:11,240] {logging_mixin.py:104} INFO - [2021-08-18 19:07:11,240] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:07:11,262] {logging_mixin.py:104} INFO - [2021-08-18 19:07:11,262] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:07:11.261831+00:00
[2021-08-18 19:07:11,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.333 seconds
[2021-08-18 19:07:41,412] {scheduler_job.py:182} INFO - Started process (PID=626) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:41,413] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:07:41,414] {logging_mixin.py:104} INFO - [2021-08-18 19:07:41,414] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:41,614] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:07:41,633] {logging_mixin.py:104} INFO - [2021-08-18 19:07:41,633] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:07:41,652] {logging_mixin.py:104} INFO - [2021-08-18 19:07:41,652] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:07:41.652638+00:00
[2021-08-18 19:07:41,665] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-08-18 19:08:11,782] {scheduler_job.py:182} INFO - Started process (PID=629) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:11,783] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:08:11,783] {logging_mixin.py:104} INFO - [2021-08-18 19:08:11,783] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:11,997] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:12,008] {logging_mixin.py:104} INFO - [2021-08-18 19:08:12,008] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:08:12,023] {logging_mixin.py:104} INFO - [2021-08-18 19:08:12,023] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:08:12.023024+00:00
[2021-08-18 19:08:12,033] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.255 seconds
[2021-08-18 19:08:42,161] {scheduler_job.py:182} INFO - Started process (PID=632) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:42,162] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:08:42,163] {logging_mixin.py:104} INFO - [2021-08-18 19:08:42,162] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:42,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:08:42,364] {logging_mixin.py:104} INFO - [2021-08-18 19:08:42,364] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:08:42,377] {logging_mixin.py:104} INFO - [2021-08-18 19:08:42,377] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:08:42.377446+00:00
[2021-08-18 19:08:42,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 19:09:12,505] {scheduler_job.py:182} INFO - Started process (PID=635) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:12,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:09:12,507] {logging_mixin.py:104} INFO - [2021-08-18 19:09:12,507] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:12,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:12,712] {logging_mixin.py:104} INFO - [2021-08-18 19:09:12,712] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:09:12,725] {logging_mixin.py:104} INFO - [2021-08-18 19:09:12,724] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:09:12.724767+00:00
[2021-08-18 19:09:12,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.234 seconds
[2021-08-18 19:09:42,854] {scheduler_job.py:182} INFO - Started process (PID=638) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:42,855] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:09:42,856] {logging_mixin.py:104} INFO - [2021-08-18 19:09:42,855] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:43,049] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:09:43,058] {logging_mixin.py:104} INFO - [2021-08-18 19:09:43,058] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:09:43,072] {logging_mixin.py:104} INFO - [2021-08-18 19:09:43,072] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:09:43.071917+00:00
[2021-08-18 19:09:43,082] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 19:10:13,199] {scheduler_job.py:182} INFO - Started process (PID=641) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:13,200] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:10:13,201] {logging_mixin.py:104} INFO - [2021-08-18 19:10:13,201] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:13,391] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:13,402] {logging_mixin.py:104} INFO - [2021-08-18 19:10:13,402] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:10:13,414] {logging_mixin.py:104} INFO - [2021-08-18 19:10:13,414] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:10:13.414180+00:00
[2021-08-18 19:10:13,424] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 19:10:43,535] {scheduler_job.py:182} INFO - Started process (PID=644) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:43,537] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:10:43,538] {logging_mixin.py:104} INFO - [2021-08-18 19:10:43,538] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:43,761] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:10:43,776] {logging_mixin.py:104} INFO - [2021-08-18 19:10:43,776] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:10:43,799] {logging_mixin.py:104} INFO - [2021-08-18 19:10:43,798] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:10:43.798645+00:00
[2021-08-18 19:10:43,810] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.278 seconds
[2021-08-18 19:11:13,931] {scheduler_job.py:182} INFO - Started process (PID=647) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:13,932] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:11:13,933] {logging_mixin.py:104} INFO - [2021-08-18 19:11:13,933] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:14,147] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:14,160] {logging_mixin.py:104} INFO - [2021-08-18 19:11:14,160] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:11:14,175] {logging_mixin.py:104} INFO - [2021-08-18 19:11:14,175] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:11:14.175709+00:00
[2021-08-18 19:11:14,186] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.259 seconds
[2021-08-18 19:11:44,307] {scheduler_job.py:182} INFO - Started process (PID=650) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:44,308] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:11:44,309] {logging_mixin.py:104} INFO - [2021-08-18 19:11:44,309] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:44,501] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:11:44,510] {logging_mixin.py:104} INFO - [2021-08-18 19:11:44,510] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:11:44,524] {logging_mixin.py:104} INFO - [2021-08-18 19:11:44,524] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:11:44.524152+00:00
[2021-08-18 19:11:44,534] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 19:12:14,655] {scheduler_job.py:182} INFO - Started process (PID=653) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:14,657] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:12:14,657] {logging_mixin.py:104} INFO - [2021-08-18 19:12:14,657] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:14,867] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:14,882] {logging_mixin.py:104} INFO - [2021-08-18 19:12:14,881] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:12:14,901] {logging_mixin.py:104} INFO - [2021-08-18 19:12:14,901] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:12:14.901141+00:00
[2021-08-18 19:12:14,914] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.262 seconds
[2021-08-18 19:12:45,034] {scheduler_job.py:182} INFO - Started process (PID=656) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:45,035] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:12:45,036] {logging_mixin.py:104} INFO - [2021-08-18 19:12:45,036] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:45,234] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:12:45,245] {logging_mixin.py:104} INFO - [2021-08-18 19:12:45,245] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:12:45,259] {logging_mixin.py:104} INFO - [2021-08-18 19:12:45,258] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:12:45.258833+00:00
[2021-08-18 19:12:45,268] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.238 seconds
[2021-08-18 19:13:15,389] {scheduler_job.py:182} INFO - Started process (PID=659) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:15,390] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:13:15,391] {logging_mixin.py:104} INFO - [2021-08-18 19:13:15,391] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:15,589] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:15,599] {logging_mixin.py:104} INFO - [2021-08-18 19:13:15,599] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:13:15,612] {logging_mixin.py:104} INFO - [2021-08-18 19:13:15,612] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:13:15.612224+00:00
[2021-08-18 19:13:15,622] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.236 seconds
[2021-08-18 19:13:45,743] {scheduler_job.py:182} INFO - Started process (PID=662) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:45,744] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:13:45,745] {logging_mixin.py:104} INFO - [2021-08-18 19:13:45,744] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:45,953] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:13:45,965] {logging_mixin.py:104} INFO - [2021-08-18 19:13:45,965] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:13:45,978] {logging_mixin.py:104} INFO - [2021-08-18 19:13:45,978] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:13:45.977862+00:00
[2021-08-18 19:13:45,986] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.247 seconds
[2021-08-18 19:14:16,106] {scheduler_job.py:182} INFO - Started process (PID=665) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:16,108] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:14:16,109] {logging_mixin.py:104} INFO - [2021-08-18 19:14:16,108] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:16,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:16,342] {logging_mixin.py:104} INFO - [2021-08-18 19:14:16,342] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:14:16,355] {logging_mixin.py:104} INFO - [2021-08-18 19:14:16,355] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:14:16.354912+00:00
[2021-08-18 19:14:16,364] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 19:14:46,485] {scheduler_job.py:182} INFO - Started process (PID=668) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:46,486] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:14:46,487] {logging_mixin.py:104} INFO - [2021-08-18 19:14:46,487] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:46,671] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:14:46,680] {logging_mixin.py:104} INFO - [2021-08-18 19:14:46,680] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:14:46,694] {logging_mixin.py:104} INFO - [2021-08-18 19:14:46,693] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:14:46.693809+00:00
[2021-08-18 19:14:46,704] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 19:15:16,818] {scheduler_job.py:182} INFO - Started process (PID=671) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:16,819] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:15:16,820] {logging_mixin.py:104} INFO - [2021-08-18 19:15:16,820] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:17,005] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:17,015] {logging_mixin.py:104} INFO - [2021-08-18 19:15:17,015] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:15:17,028] {logging_mixin.py:104} INFO - [2021-08-18 19:15:17,028] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:15:17.028405+00:00
[2021-08-18 19:15:17,039] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 19:15:47,161] {scheduler_job.py:182} INFO - Started process (PID=674) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:47,163] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:15:47,163] {logging_mixin.py:104} INFO - [2021-08-18 19:15:47,163] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:47,346] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:15:47,356] {logging_mixin.py:104} INFO - [2021-08-18 19:15:47,356] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:15:47,369] {logging_mixin.py:104} INFO - [2021-08-18 19:15:47,369] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:15:47.369002+00:00
[2021-08-18 19:15:47,379] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.221 seconds
[2021-08-18 19:16:17,503] {scheduler_job.py:182} INFO - Started process (PID=677) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:17,504] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:16:17,505] {logging_mixin.py:104} INFO - [2021-08-18 19:16:17,505] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:17,749] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:17,766] {logging_mixin.py:104} INFO - [2021-08-18 19:16:17,766] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:16:17,785] {logging_mixin.py:104} INFO - [2021-08-18 19:16:17,785] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:16:17.785604+00:00
[2021-08-18 19:16:17,795] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.295 seconds
[2021-08-18 19:16:47,911] {scheduler_job.py:182} INFO - Started process (PID=680) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:47,912] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:16:47,913] {logging_mixin.py:104} INFO - [2021-08-18 19:16:47,913] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:48,101] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:16:48,113] {logging_mixin.py:104} INFO - [2021-08-18 19:16:48,113] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:16:48,126] {logging_mixin.py:104} INFO - [2021-08-18 19:16:48,126] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:16:48.126162+00:00
[2021-08-18 19:16:48,137] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.230 seconds
[2021-08-18 19:17:18,263] {scheduler_job.py:182} INFO - Started process (PID=683) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:18,265] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:17:18,265] {logging_mixin.py:104} INFO - [2021-08-18 19:17:18,265] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:18,529] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:18,542] {logging_mixin.py:104} INFO - [2021-08-18 19:17:18,542] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:17:18,561] {logging_mixin.py:104} INFO - [2021-08-18 19:17:18,561] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:17:18.560996+00:00
[2021-08-18 19:17:18,575] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.317 seconds
[2021-08-18 19:17:48,697] {scheduler_job.py:182} INFO - Started process (PID=686) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:48,699] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:17:48,699] {logging_mixin.py:104} INFO - [2021-08-18 19:17:48,699] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:48,895] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:17:48,906] {logging_mixin.py:104} INFO - [2021-08-18 19:17:48,906] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:17:48,920] {logging_mixin.py:104} INFO - [2021-08-18 19:17:48,920] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:17:48.920399+00:00
[2021-08-18 19:17:48,933] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.239 seconds
[2021-08-18 19:18:19,079] {scheduler_job.py:182} INFO - Started process (PID=689) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:19,081] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:18:19,083] {logging_mixin.py:104} INFO - [2021-08-18 19:18:19,082] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:19,364] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:19,385] {logging_mixin.py:104} INFO - [2021-08-18 19:18:19,384] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:18:19,411] {logging_mixin.py:104} INFO - [2021-08-18 19:18:19,410] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:18:19.410679+00:00
[2021-08-18 19:18:19,427] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.352 seconds
[2021-08-18 19:18:49,544] {scheduler_job.py:182} INFO - Started process (PID=692) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:49,545] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:18:49,546] {logging_mixin.py:104} INFO - [2021-08-18 19:18:49,545] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:49,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:18:49,740] {logging_mixin.py:104} INFO - [2021-08-18 19:18:49,740] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:18:49,753] {logging_mixin.py:104} INFO - [2021-08-18 19:18:49,753] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:18:49.753354+00:00
[2021-08-18 19:18:49,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.225 seconds
[2021-08-18 19:19:19,885] {scheduler_job.py:182} INFO - Started process (PID=695) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:19,887] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:19:19,888] {logging_mixin.py:104} INFO - [2021-08-18 19:19:19,888] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:20,236] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:20,251] {logging_mixin.py:104} INFO - [2021-08-18 19:19:20,251] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:19:20,267] {logging_mixin.py:104} INFO - [2021-08-18 19:19:20,267] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:19:20.267158+00:00
[2021-08-18 19:19:20,278] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.399 seconds
[2021-08-18 19:19:50,393] {scheduler_job.py:182} INFO - Started process (PID=698) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:50,394] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:19:50,395] {logging_mixin.py:104} INFO - [2021-08-18 19:19:50,395] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:50,640] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:19:50,652] {logging_mixin.py:104} INFO - [2021-08-18 19:19:50,652] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:19:50,669] {logging_mixin.py:104} INFO - [2021-08-18 19:19:50,669] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:19:50.668978+00:00
[2021-08-18 19:19:50,682] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.294 seconds
[2021-08-18 19:20:20,800] {scheduler_job.py:182} INFO - Started process (PID=701) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:20,802] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:20:20,802] {logging_mixin.py:104} INFO - [2021-08-18 19:20:20,802] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:21,028] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:21,038] {logging_mixin.py:104} INFO - [2021-08-18 19:20:21,038] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:20:21,051] {logging_mixin.py:104} INFO - [2021-08-18 19:20:21,050] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:20:21.050801+00:00
[2021-08-18 19:20:21,062] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.266 seconds
[2021-08-18 19:20:51,179] {scheduler_job.py:182} INFO - Started process (PID=704) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:51,181] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:20:51,182] {logging_mixin.py:104} INFO - [2021-08-18 19:20:51,182] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:51,381] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:20:51,392] {logging_mixin.py:104} INFO - [2021-08-18 19:20:51,391] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:20:51,404] {logging_mixin.py:104} INFO - [2021-08-18 19:20:51,404] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:20:51.404026+00:00
[2021-08-18 19:20:51,415] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.239 seconds
[2021-08-18 19:21:21,523] {scheduler_job.py:182} INFO - Started process (PID=707) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:21,525] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:21:21,526] {logging_mixin.py:104} INFO - [2021-08-18 19:21:21,526] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:21,775] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:21,791] {logging_mixin.py:104} INFO - [2021-08-18 19:21:21,791] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:21:21,813] {logging_mixin.py:104} INFO - [2021-08-18 19:21:21,813] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:21:21.813019+00:00
[2021-08-18 19:21:21,824] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.306 seconds
[2021-08-18 19:21:51,941] {scheduler_job.py:182} INFO - Started process (PID=710) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:51,943] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:21:51,944] {logging_mixin.py:104} INFO - [2021-08-18 19:21:51,943] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:52,257] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:21:52,278] {logging_mixin.py:104} INFO - [2021-08-18 19:21:52,278] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:21:52,302] {logging_mixin.py:104} INFO - [2021-08-18 19:21:52,302] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:21:52.302514+00:00
[2021-08-18 19:21:52,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.381 seconds
[2021-08-18 19:22:22,470] {scheduler_job.py:182} INFO - Started process (PID=713) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:22,472] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:22:22,472] {logging_mixin.py:104} INFO - [2021-08-18 19:22:22,472] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:22,655] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:22,664] {logging_mixin.py:104} INFO - [2021-08-18 19:22:22,664] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:22:22,677] {logging_mixin.py:104} INFO - [2021-08-18 19:22:22,677] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:22:22.677435+00:00
[2021-08-18 19:22:22,685] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.218 seconds
[2021-08-18 19:22:52,811] {scheduler_job.py:182} INFO - Started process (PID=716) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:52,812] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:22:52,812] {logging_mixin.py:104} INFO - [2021-08-18 19:22:52,812] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:53,008] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:22:53,018] {logging_mixin.py:104} INFO - [2021-08-18 19:22:53,018] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:22:53,034] {logging_mixin.py:104} INFO - [2021-08-18 19:22:53,033] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:22:53.033834+00:00
[2021-08-18 19:22:53,044] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.236 seconds
[2021-08-18 19:23:23,182] {scheduler_job.py:182} INFO - Started process (PID=719) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:23,183] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:23:23,184] {logging_mixin.py:104} INFO - [2021-08-18 19:23:23,184] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:23,400] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:23,411] {logging_mixin.py:104} INFO - [2021-08-18 19:23:23,411] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:23:23,429] {logging_mixin.py:104} INFO - [2021-08-18 19:23:23,429] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:23:23.428910+00:00
[2021-08-18 19:23:23,441] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 19:23:53,562] {scheduler_job.py:182} INFO - Started process (PID=722) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:53,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:23:53,564] {logging_mixin.py:104} INFO - [2021-08-18 19:23:53,564] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:53,857] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:23:53,875] {logging_mixin.py:104} INFO - [2021-08-18 19:23:53,875] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:23:53,895] {logging_mixin.py:104} INFO - [2021-08-18 19:23:53,895] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:23:53.895060+00:00
[2021-08-18 19:23:53,909] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.350 seconds
[2021-08-18 19:24:24,024] {scheduler_job.py:182} INFO - Started process (PID=725) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:24,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:24:24,027] {logging_mixin.py:104} INFO - [2021-08-18 19:24:24,026] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:24,248] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:24,261] {logging_mixin.py:104} INFO - [2021-08-18 19:24:24,261] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:24:24,279] {logging_mixin.py:104} INFO - [2021-08-18 19:24:24,279] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:24:24.279239+00:00
[2021-08-18 19:24:24,291] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.271 seconds
[2021-08-18 19:24:54,418] {scheduler_job.py:182} INFO - Started process (PID=728) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:54,420] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:24:54,422] {logging_mixin.py:104} INFO - [2021-08-18 19:24:54,421] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:54,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:24:54,727] {logging_mixin.py:104} INFO - [2021-08-18 19:24:54,726] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:24:54,741] {logging_mixin.py:104} INFO - [2021-08-18 19:24:54,741] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:24:54.741694+00:00
[2021-08-18 19:24:54,750] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.338 seconds
[2021-08-18 19:25:24,870] {scheduler_job.py:182} INFO - Started process (PID=731) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:24,872] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:25:24,872] {logging_mixin.py:104} INFO - [2021-08-18 19:25:24,872] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:25,109] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:25,121] {logging_mixin.py:104} INFO - [2021-08-18 19:25:25,121] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:25:25,135] {logging_mixin.py:104} INFO - [2021-08-18 19:25:25,135] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:25:25.135501+00:00
[2021-08-18 19:25:25,145] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.278 seconds
[2021-08-18 19:25:55,264] {scheduler_job.py:182} INFO - Started process (PID=734) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:55,266] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:25:55,266] {logging_mixin.py:104} INFO - [2021-08-18 19:25:55,266] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:55,448] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:25:55,459] {logging_mixin.py:104} INFO - [2021-08-18 19:25:55,459] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:25:55,472] {logging_mixin.py:104} INFO - [2021-08-18 19:25:55,472] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:25:55.472631+00:00
[2021-08-18 19:25:55,483] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.222 seconds
[2021-08-18 19:26:25,601] {scheduler_job.py:182} INFO - Started process (PID=737) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:25,602] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:26:25,603] {logging_mixin.py:104} INFO - [2021-08-18 19:26:25,603] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:25,784] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:25,793] {logging_mixin.py:104} INFO - [2021-08-18 19:26:25,793] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:26:25,805] {logging_mixin.py:104} INFO - [2021-08-18 19:26:25,805] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:26:25.805486+00:00
[2021-08-18 19:26:25,813] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.215 seconds
[2021-08-18 19:26:55,944] {scheduler_job.py:182} INFO - Started process (PID=740) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:55,947] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:26:55,948] {logging_mixin.py:104} INFO - [2021-08-18 19:26:55,948] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:56,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:26:56,296] {logging_mixin.py:104} INFO - [2021-08-18 19:26:56,296] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:26:56,321] {logging_mixin.py:104} INFO - [2021-08-18 19:26:56,321] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:26:56.320815+00:00
[2021-08-18 19:26:56,334] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.397 seconds
[2021-08-18 19:27:26,457] {scheduler_job.py:182} INFO - Started process (PID=743) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:26,459] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:27:26,460] {logging_mixin.py:104} INFO - [2021-08-18 19:27:26,460] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:26,730] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:26,741] {logging_mixin.py:104} INFO - [2021-08-18 19:27:26,741] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:27:26,755] {logging_mixin.py:104} INFO - [2021-08-18 19:27:26,755] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:27:26.755196+00:00
[2021-08-18 19:27:26,766] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.313 seconds
[2021-08-18 19:27:56,889] {scheduler_job.py:182} INFO - Started process (PID=746) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:56,890] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:27:56,891] {logging_mixin.py:104} INFO - [2021-08-18 19:27:56,891] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:57,115] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:27:57,129] {logging_mixin.py:104} INFO - [2021-08-18 19:27:57,129] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:27:57,150] {logging_mixin.py:104} INFO - [2021-08-18 19:27:57,150] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:27:57.150344+00:00
[2021-08-18 19:27:57,161] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.275 seconds
[2021-08-18 19:28:27,314] {scheduler_job.py:182} INFO - Started process (PID=749) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:27,316] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:28:27,317] {logging_mixin.py:104} INFO - [2021-08-18 19:28:27,317] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:27,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:27,658] {logging_mixin.py:104} INFO - [2021-08-18 19:28:27,657] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:28:27,683] {logging_mixin.py:104} INFO - [2021-08-18 19:28:27,683] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:28:27.683011+00:00
[2021-08-18 19:28:27,700] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.391 seconds
[2021-08-18 19:28:57,816] {scheduler_job.py:182} INFO - Started process (PID=752) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:57,817] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:28:57,818] {logging_mixin.py:104} INFO - [2021-08-18 19:28:57,817] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:58,035] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:28:58,046] {logging_mixin.py:104} INFO - [2021-08-18 19:28:58,046] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:28:58,059] {logging_mixin.py:104} INFO - [2021-08-18 19:28:58,059] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:28:58.059508+00:00
[2021-08-18 19:28:58,069] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.256 seconds
[2021-08-18 19:29:28,199] {scheduler_job.py:182} INFO - Started process (PID=755) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:28,202] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:29:28,203] {logging_mixin.py:104} INFO - [2021-08-18 19:29:28,203] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:28,513] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:28,532] {logging_mixin.py:104} INFO - [2021-08-18 19:29:28,532] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:29:28,550] {logging_mixin.py:104} INFO - [2021-08-18 19:29:28,550] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:29:28.550562+00:00
[2021-08-18 19:29:28,562] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.368 seconds
[2021-08-18 19:29:58,681] {scheduler_job.py:182} INFO - Started process (PID=758) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:58,682] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:29:58,682] {logging_mixin.py:104} INFO - [2021-08-18 19:29:58,682] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:58,883] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:29:58,895] {logging_mixin.py:104} INFO - [2021-08-18 19:29:58,895] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:29:58,910] {logging_mixin.py:104} INFO - [2021-08-18 19:29:58,910] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:29:58.910296+00:00
[2021-08-18 19:29:58,921] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.243 seconds
[2021-08-18 19:30:29,036] {scheduler_job.py:182} INFO - Started process (PID=761) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:29,037] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:30:29,038] {logging_mixin.py:104} INFO - [2021-08-18 19:30:29,038] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:29,241] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:29,254] {logging_mixin.py:104} INFO - [2021-08-18 19:30:29,253] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:30:29,267] {logging_mixin.py:104} INFO - [2021-08-18 19:30:29,266] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:30:29.266795+00:00
[2021-08-18 19:30:29,277] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.245 seconds
[2021-08-18 19:30:59,400] {scheduler_job.py:182} INFO - Started process (PID=764) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:59,402] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:30:59,402] {logging_mixin.py:104} INFO - [2021-08-18 19:30:59,402] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:59,679] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:30:59,696] {logging_mixin.py:104} INFO - [2021-08-18 19:30:59,695] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:30:59,716] {logging_mixin.py:104} INFO - [2021-08-18 19:30:59,716] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:30:59.716355+00:00
[2021-08-18 19:30:59,729] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.333 seconds
[2021-08-18 19:31:29,848] {scheduler_job.py:182} INFO - Started process (PID=767) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:31:29,850] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:31:29,851] {logging_mixin.py:104} INFO - [2021-08-18 19:31:29,851] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:31:30,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:31:30,240] {logging_mixin.py:104} INFO - [2021-08-18 19:31:30,240] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:31:30,268] {logging_mixin.py:104} INFO - [2021-08-18 19:31:30,268] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:31:30.268057+00:00
[2021-08-18 19:31:30,284] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.441 seconds
[2021-08-18 19:32:00,410] {scheduler_job.py:182} INFO - Started process (PID=770) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:00,411] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:32:00,412] {logging_mixin.py:104} INFO - [2021-08-18 19:32:00,412] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:00,610] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:00,622] {logging_mixin.py:104} INFO - [2021-08-18 19:32:00,622] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:32:00,635] {logging_mixin.py:104} INFO - [2021-08-18 19:32:00,635] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:32:00.635561+00:00
[2021-08-18 19:32:00,645] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.239 seconds
[2021-08-18 19:32:30,764] {scheduler_job.py:182} INFO - Started process (PID=773) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:30,765] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:32:30,765] {logging_mixin.py:104} INFO - [2021-08-18 19:32:30,765] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:30,959] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:32:30,971] {logging_mixin.py:104} INFO - [2021-08-18 19:32:30,970] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:32:30,985] {logging_mixin.py:104} INFO - [2021-08-18 19:32:30,985] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:32:30.985281+00:00
[2021-08-18 19:32:30,995] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.234 seconds
[2021-08-18 19:33:01,109] {scheduler_job.py:182} INFO - Started process (PID=776) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:01,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:33:01,112] {logging_mixin.py:104} INFO - [2021-08-18 19:33:01,111] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:01,305] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:01,317] {logging_mixin.py:104} INFO - [2021-08-18 19:33:01,316] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:33:01,330] {logging_mixin.py:104} INFO - [2021-08-18 19:33:01,330] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:33:01.329930+00:00
[2021-08-18 19:33:01,343] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.238 seconds
[2021-08-18 19:33:31,490] {scheduler_job.py:182} INFO - Started process (PID=779) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:31,491] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:33:31,491] {logging_mixin.py:104} INFO - [2021-08-18 19:33:31,491] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:31,702] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:33:31,712] {logging_mixin.py:104} INFO - [2021-08-18 19:33:31,711] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:33:31,727] {logging_mixin.py:104} INFO - [2021-08-18 19:33:31,726] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:33:31.726841+00:00
[2021-08-18 19:33:31,736] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.250 seconds
[2021-08-18 19:34:01,845] {scheduler_job.py:182} INFO - Started process (PID=782) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:01,846] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:34:01,847] {logging_mixin.py:104} INFO - [2021-08-18 19:34:01,847] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:02,071] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:02,082] {logging_mixin.py:104} INFO - [2021-08-18 19:34:02,082] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:34:02,096] {logging_mixin.py:104} INFO - [2021-08-18 19:34:02,096] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:34:02.096523+00:00
[2021-08-18 19:34:02,106] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.265 seconds
[2021-08-18 19:34:32,258] {scheduler_job.py:182} INFO - Started process (PID=785) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:32,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:34:32,265] {logging_mixin.py:104} INFO - [2021-08-18 19:34:32,265] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:32,509] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:34:32,521] {logging_mixin.py:104} INFO - [2021-08-18 19:34:32,521] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:34:32,535] {logging_mixin.py:104} INFO - [2021-08-18 19:34:32,535] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:34:32.535083+00:00
[2021-08-18 19:34:32,546] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.304 seconds
[2021-08-18 19:35:02,667] {scheduler_job.py:182} INFO - Started process (PID=788) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:02,669] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:35:02,669] {logging_mixin.py:104} INFO - [2021-08-18 19:35:02,669] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:02,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:02,881] {logging_mixin.py:104} INFO - [2021-08-18 19:35:02,881] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:35:02,894] {logging_mixin.py:104} INFO - [2021-08-18 19:35:02,894] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:35:02.894692+00:00
[2021-08-18 19:35:02,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.241 seconds
[2021-08-18 19:35:33,033] {scheduler_job.py:182} INFO - Started process (PID=791) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:33,034] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:35:33,035] {logging_mixin.py:104} INFO - [2021-08-18 19:35:33,035] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:33,259] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:35:33,270] {logging_mixin.py:104} INFO - [2021-08-18 19:35:33,270] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:35:33,289] {logging_mixin.py:104} INFO - [2021-08-18 19:35:33,289] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:35:33.288878+00:00
[2021-08-18 19:35:33,302] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.272 seconds
[2021-08-18 19:36:03,426] {scheduler_job.py:182} INFO - Started process (PID=794) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:03,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:36:03,428] {logging_mixin.py:104} INFO - [2021-08-18 19:36:03,428] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:03,634] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:03,646] {logging_mixin.py:104} INFO - [2021-08-18 19:36:03,646] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:36:03,660] {logging_mixin.py:104} INFO - [2021-08-18 19:36:03,660] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:36:03.660673+00:00
[2021-08-18 19:36:03,671] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.248 seconds
[2021-08-18 19:36:33,798] {scheduler_job.py:182} INFO - Started process (PID=797) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:33,799] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:36:33,800] {logging_mixin.py:104} INFO - [2021-08-18 19:36:33,799] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:34,010] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:36:34,024] {logging_mixin.py:104} INFO - [2021-08-18 19:36:34,024] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:36:34,042] {logging_mixin.py:104} INFO - [2021-08-18 19:36:34,041] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:36:34.041777+00:00
[2021-08-18 19:36:34,054] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.259 seconds
[2021-08-18 19:37:04,179] {scheduler_job.py:182} INFO - Started process (PID=800) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:04,180] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:37:04,181] {logging_mixin.py:104} INFO - [2021-08-18 19:37:04,181] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:04,394] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:04,405] {logging_mixin.py:104} INFO - [2021-08-18 19:37:04,405] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:37:04,420] {logging_mixin.py:104} INFO - [2021-08-18 19:37:04,420] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:37:04.420188+00:00
[2021-08-18 19:37:04,430] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.254 seconds
[2021-08-18 19:37:34,561] {scheduler_job.py:182} INFO - Started process (PID=803) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:34,563] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:37:34,565] {logging_mixin.py:104} INFO - [2021-08-18 19:37:34,564] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:34,811] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:37:34,822] {logging_mixin.py:104} INFO - [2021-08-18 19:37:34,822] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:37:34,837] {logging_mixin.py:104} INFO - [2021-08-18 19:37:34,837] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:37:34.837580+00:00
[2021-08-18 19:37:34,849] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.292 seconds
[2021-08-18 19:38:04,966] {scheduler_job.py:182} INFO - Started process (PID=806) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:04,968] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:38:04,968] {logging_mixin.py:104} INFO - [2021-08-18 19:38:04,968] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:05,184] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:05,198] {logging_mixin.py:104} INFO - [2021-08-18 19:38:05,197] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:38:05,217] {logging_mixin.py:104} INFO - [2021-08-18 19:38:05,217] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:38:05.217522+00:00
[2021-08-18 19:38:05,231] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.268 seconds
[2021-08-18 19:38:35,376] {scheduler_job.py:182} INFO - Started process (PID=809) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:35,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:38:35,378] {logging_mixin.py:104} INFO - [2021-08-18 19:38:35,378] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:35,591] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:38:35,603] {logging_mixin.py:104} INFO - [2021-08-18 19:38:35,602] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:38:35,617] {logging_mixin.py:104} INFO - [2021-08-18 19:38:35,617] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:38:35.617416+00:00
[2021-08-18 19:38:35,628] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.255 seconds
[2021-08-18 19:39:05,753] {scheduler_job.py:182} INFO - Started process (PID=812) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:05,754] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:39:05,755] {logging_mixin.py:104} INFO - [2021-08-18 19:39:05,754] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:05,966] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:05,977] {logging_mixin.py:104} INFO - [2021-08-18 19:39:05,977] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:39:05,992] {logging_mixin.py:104} INFO - [2021-08-18 19:39:05,992] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:39:05.992041+00:00
[2021-08-18 19:39:06,002] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.253 seconds
[2021-08-18 19:39:36,129] {scheduler_job.py:182} INFO - Started process (PID=815) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:36,131] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:39:36,131] {logging_mixin.py:104} INFO - [2021-08-18 19:39:36,131] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:36,348] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:39:36,362] {logging_mixin.py:104} INFO - [2021-08-18 19:39:36,362] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:39:36,380] {logging_mixin.py:104} INFO - [2021-08-18 19:39:36,379] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:39:36.379710+00:00
[2021-08-18 19:39:36,391] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.265 seconds
[2021-08-18 19:40:06,513] {scheduler_job.py:182} INFO - Started process (PID=818) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:06,514] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:40:06,514] {logging_mixin.py:104} INFO - [2021-08-18 19:40:06,514] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:06,721] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:06,733] {logging_mixin.py:104} INFO - [2021-08-18 19:40:06,733] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:40:06,748] {logging_mixin.py:104} INFO - [2021-08-18 19:40:06,747] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:40:06.747702+00:00
[2021-08-18 19:40:06,758] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.249 seconds
[2021-08-18 19:40:36,875] {scheduler_job.py:182} INFO - Started process (PID=821) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:36,876] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:40:36,877] {logging_mixin.py:104} INFO - [2021-08-18 19:40:36,877] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:37,092] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:40:37,105] {logging_mixin.py:104} INFO - [2021-08-18 19:40:37,105] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:40:37,121] {logging_mixin.py:104} INFO - [2021-08-18 19:40:37,121] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:40:37.121620+00:00
[2021-08-18 19:40:37,132] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.260 seconds
[2021-08-18 19:41:07,258] {scheduler_job.py:182} INFO - Started process (PID=824) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:07,259] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:41:07,260] {logging_mixin.py:104} INFO - [2021-08-18 19:41:07,260] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:07,465] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:07,479] {logging_mixin.py:104} INFO - [2021-08-18 19:41:07,479] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:41:07,500] {logging_mixin.py:104} INFO - [2021-08-18 19:41:07,500] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:41:07.500228+00:00
[2021-08-18 19:41:07,513] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-08-18 19:41:37,629] {scheduler_job.py:182} INFO - Started process (PID=827) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:37,630] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:41:37,631] {logging_mixin.py:104} INFO - [2021-08-18 19:41:37,630] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:37,842] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:41:37,854] {logging_mixin.py:104} INFO - [2021-08-18 19:41:37,854] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:41:37,868] {logging_mixin.py:104} INFO - [2021-08-18 19:41:37,868] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:41:37.868406+00:00
[2021-08-18 19:41:37,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.253 seconds
[2021-08-18 19:42:08,009] {scheduler_job.py:182} INFO - Started process (PID=830) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:08,010] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:42:08,011] {logging_mixin.py:104} INFO - [2021-08-18 19:42:08,011] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:08,271] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:08,283] {logging_mixin.py:104} INFO - [2021-08-18 19:42:08,282] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:42:08,297] {logging_mixin.py:104} INFO - [2021-08-18 19:42:08,297] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:42:08.297374+00:00
[2021-08-18 19:42:08,309] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.304 seconds
[2021-08-18 19:42:38,420] {scheduler_job.py:182} INFO - Started process (PID=833) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:38,422] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:42:38,422] {logging_mixin.py:104} INFO - [2021-08-18 19:42:38,422] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:38,605] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:42:38,615] {logging_mixin.py:104} INFO - [2021-08-18 19:42:38,615] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:42:38,628] {logging_mixin.py:104} INFO - [2021-08-18 19:42:38,628] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:42:38.628500+00:00
[2021-08-18 19:42:38,639] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.222 seconds
[2021-08-18 19:43:08,761] {scheduler_job.py:182} INFO - Started process (PID=836) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:08,762] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:43:08,762] {logging_mixin.py:104} INFO - [2021-08-18 19:43:08,762] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:08,961] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:08,973] {logging_mixin.py:104} INFO - [2021-08-18 19:43:08,973] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:43:08,987] {logging_mixin.py:104} INFO - [2021-08-18 19:43:08,986] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:43:08.986791+00:00
[2021-08-18 19:43:08,997] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.240 seconds
[2021-08-18 19:43:39,140] {scheduler_job.py:182} INFO - Started process (PID=839) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:39,141] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:43:39,142] {logging_mixin.py:104} INFO - [2021-08-18 19:43:39,142] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:39,332] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:43:39,342] {logging_mixin.py:104} INFO - [2021-08-18 19:43:39,342] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:43:39,356] {logging_mixin.py:104} INFO - [2021-08-18 19:43:39,356] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:43:39.356002+00:00
[2021-08-18 19:43:39,366] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 19:44:09,487] {scheduler_job.py:182} INFO - Started process (PID=842) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:09,488] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:44:09,488] {logging_mixin.py:104} INFO - [2021-08-18 19:44:09,488] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:09,676] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:09,685] {logging_mixin.py:104} INFO - [2021-08-18 19:44:09,685] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:44:09,699] {logging_mixin.py:104} INFO - [2021-08-18 19:44:09,699] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:44:09.699059+00:00
[2021-08-18 19:44:09,710] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.227 seconds
[2021-08-18 19:44:39,824] {scheduler_job.py:182} INFO - Started process (PID=845) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:39,825] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:44:39,825] {logging_mixin.py:104} INFO - [2021-08-18 19:44:39,825] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:40,022] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:44:40,031] {logging_mixin.py:104} INFO - [2021-08-18 19:44:40,031] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:44:40,043] {logging_mixin.py:104} INFO - [2021-08-18 19:44:40,043] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:44:40.043382+00:00
[2021-08-18 19:44:40,052] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 19:45:10,164] {scheduler_job.py:182} INFO - Started process (PID=848) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:10,165] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:45:10,166] {logging_mixin.py:104} INFO - [2021-08-18 19:45:10,166] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:10,407] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:10,421] {logging_mixin.py:104} INFO - [2021-08-18 19:45:10,421] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:45:10,444] {logging_mixin.py:104} INFO - [2021-08-18 19:45:10,444] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:45:10.444394+00:00
[2021-08-18 19:45:10,459] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.299 seconds
[2021-08-18 19:45:40,578] {scheduler_job.py:182} INFO - Started process (PID=851) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:40,581] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:45:40,583] {logging_mixin.py:104} INFO - [2021-08-18 19:45:40,582] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:40,926] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:45:40,941] {logging_mixin.py:104} INFO - [2021-08-18 19:45:40,941] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:45:40,964] {logging_mixin.py:104} INFO - [2021-08-18 19:45:40,964] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:45:40.964444+00:00
[2021-08-18 19:45:40,979] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.408 seconds
[2021-08-18 19:46:11,118] {scheduler_job.py:182} INFO - Started process (PID=854) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:11,120] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:46:11,121] {logging_mixin.py:104} INFO - [2021-08-18 19:46:11,121] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:11,638] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:11,669] {logging_mixin.py:104} INFO - [2021-08-18 19:46:11,668] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:46:11,698] {logging_mixin.py:104} INFO - [2021-08-18 19:46:11,698] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:46:11.698312+00:00
[2021-08-18 19:46:11,719] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.606 seconds
[2021-08-18 19:46:41,876] {scheduler_job.py:182} INFO - Started process (PID=857) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:41,879] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:46:41,880] {logging_mixin.py:104} INFO - [2021-08-18 19:46:41,880] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:42,320] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:46:42,346] {logging_mixin.py:104} INFO - [2021-08-18 19:46:42,346] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:46:42,383] {logging_mixin.py:104} INFO - [2021-08-18 19:46:42,382] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:46:42.382097+00:00
[2021-08-18 19:46:42,412] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.545 seconds
[2021-08-18 19:47:12,562] {scheduler_job.py:182} INFO - Started process (PID=860) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:12,564] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:47:12,566] {logging_mixin.py:104} INFO - [2021-08-18 19:47:12,565] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:12,993] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:13,016] {logging_mixin.py:104} INFO - [2021-08-18 19:47:13,016] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:47:13,043] {logging_mixin.py:104} INFO - [2021-08-18 19:47:13,043] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:47:13.043145+00:00
[2021-08-18 19:47:13,064] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.509 seconds
[2021-08-18 19:47:43,188] {scheduler_job.py:182} INFO - Started process (PID=863) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:43,190] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:47:43,190] {logging_mixin.py:104} INFO - [2021-08-18 19:47:43,190] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:43,582] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:47:43,605] {logging_mixin.py:104} INFO - [2021-08-18 19:47:43,604] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:47:43,634] {logging_mixin.py:104} INFO - [2021-08-18 19:47:43,634] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:47:43.634217+00:00
[2021-08-18 19:47:43,653] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.470 seconds
[2021-08-18 19:48:13,784] {scheduler_job.py:182} INFO - Started process (PID=866) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:13,786] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:48:13,788] {logging_mixin.py:104} INFO - [2021-08-18 19:48:13,787] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:14,194] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:14,213] {logging_mixin.py:104} INFO - [2021-08-18 19:48:14,213] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:48:14,239] {logging_mixin.py:104} INFO - [2021-08-18 19:48:14,239] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:48:14.239065+00:00
[2021-08-18 19:48:14,258] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.481 seconds
[2021-08-18 19:48:44,447] {scheduler_job.py:182} INFO - Started process (PID=869) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:44,448] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:48:44,450] {logging_mixin.py:104} INFO - [2021-08-18 19:48:44,449] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:44,827] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:48:44,853] {logging_mixin.py:104} INFO - [2021-08-18 19:48:44,853] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:48:44,892] {logging_mixin.py:104} INFO - [2021-08-18 19:48:44,891] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:48:44.891166+00:00
[2021-08-18 19:48:44,918] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.480 seconds
[2021-08-18 19:49:15,069] {scheduler_job.py:182} INFO - Started process (PID=872) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:15,071] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:49:15,072] {logging_mixin.py:104} INFO - [2021-08-18 19:49:15,072] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:15,500] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:15,535] {logging_mixin.py:104} INFO - [2021-08-18 19:49:15,535] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:49:15,574] {logging_mixin.py:104} INFO - [2021-08-18 19:49:15,573] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:49:15.573570+00:00
[2021-08-18 19:49:15,601] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.536 seconds
[2021-08-18 19:49:45,738] {scheduler_job.py:182} INFO - Started process (PID=875) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:45,740] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:49:45,741] {logging_mixin.py:104} INFO - [2021-08-18 19:49:45,741] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:46,043] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:49:46,062] {logging_mixin.py:104} INFO - [2021-08-18 19:49:46,062] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:49:46,087] {logging_mixin.py:104} INFO - [2021-08-18 19:49:46,087] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:49:46.087405+00:00
[2021-08-18 19:49:46,109] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.375 seconds
[2021-08-18 19:50:16,237] {scheduler_job.py:182} INFO - Started process (PID=878) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:16,239] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:50:16,240] {logging_mixin.py:104} INFO - [2021-08-18 19:50:16,240] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:16,553] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:16,572] {logging_mixin.py:104} INFO - [2021-08-18 19:50:16,572] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:50:16,592] {logging_mixin.py:104} INFO - [2021-08-18 19:50:16,592] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:50:16.591829+00:00
[2021-08-18 19:50:16,616] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.383 seconds
[2021-08-18 19:50:46,750] {scheduler_job.py:182} INFO - Started process (PID=881) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:46,753] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:50:46,754] {logging_mixin.py:104} INFO - [2021-08-18 19:50:46,754] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:47,108] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:50:47,129] {logging_mixin.py:104} INFO - [2021-08-18 19:50:47,129] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:50:47,150] {logging_mixin.py:104} INFO - [2021-08-18 19:50:47,150] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:50:47.150366+00:00
[2021-08-18 19:50:47,168] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.423 seconds
[2021-08-18 19:51:17,299] {scheduler_job.py:182} INFO - Started process (PID=884) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:17,301] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:51:17,302] {logging_mixin.py:104} INFO - [2021-08-18 19:51:17,302] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:17,615] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:17,632] {logging_mixin.py:104} INFO - [2021-08-18 19:51:17,632] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:51:17,652] {logging_mixin.py:104} INFO - [2021-08-18 19:51:17,651] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:51:17.651519+00:00
[2021-08-18 19:51:17,669] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.379 seconds
[2021-08-18 19:51:47,785] {scheduler_job.py:182} INFO - Started process (PID=887) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:47,787] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:51:47,788] {logging_mixin.py:104} INFO - [2021-08-18 19:51:47,788] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:48,069] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:51:48,084] {logging_mixin.py:104} INFO - [2021-08-18 19:51:48,084] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:51:48,107] {logging_mixin.py:104} INFO - [2021-08-18 19:51:48,107] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:51:48.106862+00:00
[2021-08-18 19:51:48,122] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.342 seconds
[2021-08-18 19:52:18,270] {scheduler_job.py:182} INFO - Started process (PID=890) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:18,272] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:52:18,274] {logging_mixin.py:104} INFO - [2021-08-18 19:52:18,273] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:18,693] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:18,712] {logging_mixin.py:104} INFO - [2021-08-18 19:52:18,712] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:52:18,741] {logging_mixin.py:104} INFO - [2021-08-18 19:52:18,741] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:52:18.740761+00:00
[2021-08-18 19:52:18,757] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.493 seconds
[2021-08-18 19:52:48,911] {scheduler_job.py:182} INFO - Started process (PID=893) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:48,913] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:52:48,914] {logging_mixin.py:104} INFO - [2021-08-18 19:52:48,914] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:49,310] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:52:49,331] {logging_mixin.py:104} INFO - [2021-08-18 19:52:49,331] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:52:49,361] {logging_mixin.py:104} INFO - [2021-08-18 19:52:49,361] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:52:49.360885+00:00
[2021-08-18 19:52:49,381] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.479 seconds
[2021-08-18 19:53:19,525] {scheduler_job.py:182} INFO - Started process (PID=896) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:19,527] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:53:19,528] {logging_mixin.py:104} INFO - [2021-08-18 19:53:19,528] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:19,961] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:19,987] {logging_mixin.py:104} INFO - [2021-08-18 19:53:19,986] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:53:20,030] {logging_mixin.py:104} INFO - [2021-08-18 19:53:20,030] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:53:20.029842+00:00
[2021-08-18 19:53:20,052] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.534 seconds
[2021-08-18 19:53:50,256] {scheduler_job.py:182} INFO - Started process (PID=899) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:50,264] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:53:50,267] {logging_mixin.py:104} INFO - [2021-08-18 19:53:50,266] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:50,735] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:53:50,768] {logging_mixin.py:104} INFO - [2021-08-18 19:53:50,768] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:53:50,809] {logging_mixin.py:104} INFO - [2021-08-18 19:53:50,808] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:53:50.808323+00:00
[2021-08-18 19:53:50,830] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.582 seconds
[2021-08-18 19:54:20,962] {scheduler_job.py:182} INFO - Started process (PID=902) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:20,963] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:54:20,964] {logging_mixin.py:104} INFO - [2021-08-18 19:54:20,964] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:21,414] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:21,443] {logging_mixin.py:104} INFO - [2021-08-18 19:54:21,443] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:54:21,470] {logging_mixin.py:104} INFO - [2021-08-18 19:54:21,470] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:54:21.470134+00:00
[2021-08-18 19:54:21,489] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.535 seconds
[2021-08-18 19:54:51,647] {scheduler_job.py:182} INFO - Started process (PID=905) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:51,650] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:54:51,651] {logging_mixin.py:104} INFO - [2021-08-18 19:54:51,651] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:52,159] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:54:52,185] {logging_mixin.py:104} INFO - [2021-08-18 19:54:52,184] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:54:52,219] {logging_mixin.py:104} INFO - [2021-08-18 19:54:52,219] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:54:52.219474+00:00
[2021-08-18 19:54:52,241] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.605 seconds
[2021-08-18 19:55:22,382] {scheduler_job.py:182} INFO - Started process (PID=908) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:22,383] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:55:22,385] {logging_mixin.py:104} INFO - [2021-08-18 19:55:22,385] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:22,875] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:22,901] {logging_mixin.py:104} INFO - [2021-08-18 19:55:22,901] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:55:22,940] {logging_mixin.py:104} INFO - [2021-08-18 19:55:22,940] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:55:22.940403+00:00
[2021-08-18 19:55:22,961] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.587 seconds
[2021-08-18 19:55:53,113] {scheduler_job.py:182} INFO - Started process (PID=911) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:53,117] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:55:53,118] {logging_mixin.py:104} INFO - [2021-08-18 19:55:53,117] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:53,619] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:55:53,644] {logging_mixin.py:104} INFO - [2021-08-18 19:55:53,644] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:55:53,674] {logging_mixin.py:104} INFO - [2021-08-18 19:55:53,674] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:55:53.674287+00:00
[2021-08-18 19:55:53,694] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.585 seconds
[2021-08-18 19:56:23,835] {scheduler_job.py:182} INFO - Started process (PID=914) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:23,837] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:56:23,839] {logging_mixin.py:104} INFO - [2021-08-18 19:56:23,839] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:24,586] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:24,628] {logging_mixin.py:104} INFO - [2021-08-18 19:56:24,628] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:56:24,658] {logging_mixin.py:104} INFO - [2021-08-18 19:56:24,658] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:56:24.658007+00:00
[2021-08-18 19:56:24,678] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.852 seconds
[2021-08-18 19:56:54,830] {scheduler_job.py:182} INFO - Started process (PID=917) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:54,832] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:56:54,835] {logging_mixin.py:104} INFO - [2021-08-18 19:56:54,834] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:55,283] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:56:55,301] {logging_mixin.py:104} INFO - [2021-08-18 19:56:55,301] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:56:55,336] {logging_mixin.py:104} INFO - [2021-08-18 19:56:55,336] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:56:55.335870+00:00
[2021-08-18 19:56:55,360] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.537 seconds
[2021-08-18 19:57:25,503] {scheduler_job.py:182} INFO - Started process (PID=920) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:25,506] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:57:25,507] {logging_mixin.py:104} INFO - [2021-08-18 19:57:25,507] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:25,984] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:26,024] {logging_mixin.py:104} INFO - [2021-08-18 19:57:26,023] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:57:26,072] {logging_mixin.py:104} INFO - [2021-08-18 19:57:26,071] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:57:26.071493+00:00
[2021-08-18 19:57:26,094] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.597 seconds
[2021-08-18 19:57:56,247] {scheduler_job.py:182} INFO - Started process (PID=923) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:56,250] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:57:56,251] {logging_mixin.py:104} INFO - [2021-08-18 19:57:56,251] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:56,748] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:57:56,769] {logging_mixin.py:104} INFO - [2021-08-18 19:57:56,769] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:57:56,801] {logging_mixin.py:104} INFO - [2021-08-18 19:57:56,801] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:57:56.801049+00:00
[2021-08-18 19:57:56,820] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.580 seconds
[2021-08-18 19:58:27,018] {scheduler_job.py:182} INFO - Started process (PID=926) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:27,020] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:58:27,020] {logging_mixin.py:104} INFO - [2021-08-18 19:58:27,020] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:27,477] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:27,502] {logging_mixin.py:104} INFO - [2021-08-18 19:58:27,501] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:58:27,533] {logging_mixin.py:104} INFO - [2021-08-18 19:58:27,533] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:58:27.533234+00:00
[2021-08-18 19:58:27,555] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.544 seconds
[2021-08-18 19:58:57,702] {scheduler_job.py:182} INFO - Started process (PID=929) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:57,706] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:58:57,709] {logging_mixin.py:104} INFO - [2021-08-18 19:58:57,708] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:58,226] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:58:58,256] {logging_mixin.py:104} INFO - [2021-08-18 19:58:58,256] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:58:58,294] {logging_mixin.py:104} INFO - [2021-08-18 19:58:58,294] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:58:58.294089+00:00
[2021-08-18 19:58:58,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.623 seconds
[2021-08-18 19:59:28,454] {scheduler_job.py:182} INFO - Started process (PID=932) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:28,457] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:59:28,459] {logging_mixin.py:104} INFO - [2021-08-18 19:59:28,458] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:28,986] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:29,012] {logging_mixin.py:104} INFO - [2021-08-18 19:59:29,012] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:59:29,047] {logging_mixin.py:104} INFO - [2021-08-18 19:59:29,047] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:59:29.046793+00:00
[2021-08-18 19:59:29,066] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.617 seconds
[2021-08-18 19:59:59,231] {scheduler_job.py:182} INFO - Started process (PID=935) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:59,233] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 19:59:59,233] {logging_mixin.py:104} INFO - [2021-08-18 19:59:59,233] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:59,680] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 19:59:59,713] {logging_mixin.py:104} INFO - [2021-08-18 19:59:59,713] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 19:59:59,742] {logging_mixin.py:104} INFO - [2021-08-18 19:59:59,742] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 19:59:59.742454+00:00
[2021-08-18 19:59:59,761] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.537 seconds
[2021-08-18 20:00:29,901] {scheduler_job.py:182} INFO - Started process (PID=938) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:00:29,903] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:00:29,905] {logging_mixin.py:104} INFO - [2021-08-18 20:00:29,905] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:00:30,389] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:00:30,410] {logging_mixin.py:104} INFO - [2021-08-18 20:00:30,409] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:00:30,438] {logging_mixin.py:104} INFO - [2021-08-18 20:00:30,438] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:00:30.437785+00:00
[2021-08-18 20:00:30,460] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.567 seconds
[2021-08-18 20:01:00,588] {scheduler_job.py:182} INFO - Started process (PID=941) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:00,589] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:01:00,590] {logging_mixin.py:104} INFO - [2021-08-18 20:01:00,590] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:00,781] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:00,792] {logging_mixin.py:104} INFO - [2021-08-18 20:01:00,792] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:01:00,806] {logging_mixin.py:104} INFO - [2021-08-18 20:01:00,805] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:01:00.805752+00:00
[2021-08-18 20:01:00,817] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 20:01:30,928] {scheduler_job.py:182} INFO - Started process (PID=944) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:30,929] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:01:30,931] {logging_mixin.py:104} INFO - [2021-08-18 20:01:30,930] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:31,152] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:01:31,163] {logging_mixin.py:104} INFO - [2021-08-18 20:01:31,163] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:01:31,178] {logging_mixin.py:104} INFO - [2021-08-18 20:01:31,178] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:01:31.178103+00:00
[2021-08-18 20:01:31,188] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 20:02:01,301] {scheduler_job.py:182} INFO - Started process (PID=947) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:01,302] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:02:01,303] {logging_mixin.py:104} INFO - [2021-08-18 20:02:01,302] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:01,535] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:01,550] {logging_mixin.py:104} INFO - [2021-08-18 20:02:01,549] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:02:01,571] {logging_mixin.py:104} INFO - [2021-08-18 20:02:01,571] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:02:01.571324+00:00
[2021-08-18 20:02:01,585] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.287 seconds
[2021-08-18 20:02:31,701] {scheduler_job.py:182} INFO - Started process (PID=950) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:31,703] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:02:31,704] {logging_mixin.py:104} INFO - [2021-08-18 20:02:31,703] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:31,914] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:02:31,925] {logging_mixin.py:104} INFO - [2021-08-18 20:02:31,925] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:02:31,939] {logging_mixin.py:104} INFO - [2021-08-18 20:02:31,939] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:02:31.938868+00:00
[2021-08-18 20:02:31,949] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.251 seconds
[2021-08-18 20:03:02,068] {scheduler_job.py:182} INFO - Started process (PID=953) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:02,069] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:03:02,070] {logging_mixin.py:104} INFO - [2021-08-18 20:03:02,070] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:02,277] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:02,289] {logging_mixin.py:104} INFO - [2021-08-18 20:03:02,289] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:03:02,306] {logging_mixin.py:104} INFO - [2021-08-18 20:03:02,306] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:03:02.306057+00:00
[2021-08-18 20:03:02,318] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.253 seconds
[2021-08-18 20:03:32,456] {scheduler_job.py:182} INFO - Started process (PID=956) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:32,457] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:03:32,458] {logging_mixin.py:104} INFO - [2021-08-18 20:03:32,458] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:32,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:03:32,676] {logging_mixin.py:104} INFO - [2021-08-18 20:03:32,676] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:03:32,689] {logging_mixin.py:104} INFO - [2021-08-18 20:03:32,689] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:03:32.689253+00:00
[2021-08-18 20:03:32,698] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.245 seconds
[2021-08-18 20:04:02,832] {scheduler_job.py:182} INFO - Started process (PID=959) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:02,833] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:04:02,834] {logging_mixin.py:104} INFO - [2021-08-18 20:04:02,834] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:03,052] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:03,067] {logging_mixin.py:104} INFO - [2021-08-18 20:04:03,067] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:04:03,087] {logging_mixin.py:104} INFO - [2021-08-18 20:04:03,086] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:04:03.086608+00:00
[2021-08-18 20:04:03,097] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.268 seconds
[2021-08-18 20:04:33,220] {scheduler_job.py:182} INFO - Started process (PID=962) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:33,221] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:04:33,221] {logging_mixin.py:104} INFO - [2021-08-18 20:04:33,221] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:33,439] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:04:33,451] {logging_mixin.py:104} INFO - [2021-08-18 20:04:33,451] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:04:33,466] {logging_mixin.py:104} INFO - [2021-08-18 20:04:33,466] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:04:33.466158+00:00
[2021-08-18 20:04:33,476] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.260 seconds
[2021-08-18 20:05:03,594] {scheduler_job.py:182} INFO - Started process (PID=965) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:03,596] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:05:03,596] {logging_mixin.py:104} INFO - [2021-08-18 20:05:03,596] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:03,817] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:03,829] {logging_mixin.py:104} INFO - [2021-08-18 20:05:03,828] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:05:03,843] {logging_mixin.py:104} INFO - [2021-08-18 20:05:03,843] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:05:03.843617+00:00
[2021-08-18 20:05:03,854] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 20:05:33,970] {scheduler_job.py:182} INFO - Started process (PID=968) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:33,971] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:05:33,972] {logging_mixin.py:104} INFO - [2021-08-18 20:05:33,972] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:34,187] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:05:34,199] {logging_mixin.py:104} INFO - [2021-08-18 20:05:34,198] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:05:34,213] {logging_mixin.py:104} INFO - [2021-08-18 20:05:34,213] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:05:34.213331+00:00
[2021-08-18 20:05:34,224] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.257 seconds
[2021-08-18 20:06:04,337] {scheduler_job.py:182} INFO - Started process (PID=971) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:04,338] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:06:04,339] {logging_mixin.py:104} INFO - [2021-08-18 20:06:04,339] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:04,559] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:04,571] {logging_mixin.py:104} INFO - [2021-08-18 20:06:04,571] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:06:04,586] {logging_mixin.py:104} INFO - [2021-08-18 20:06:04,586] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:06:04.586478+00:00
[2021-08-18 20:06:04,596] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.263 seconds
[2021-08-18 20:06:34,716] {scheduler_job.py:182} INFO - Started process (PID=974) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:34,717] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:06:34,718] {logging_mixin.py:104} INFO - [2021-08-18 20:06:34,718] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:34,932] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:06:34,943] {logging_mixin.py:104} INFO - [2021-08-18 20:06:34,943] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:06:34,959] {logging_mixin.py:104} INFO - [2021-08-18 20:06:34,959] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:06:34.959099+00:00
[2021-08-18 20:06:34,970] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.257 seconds
[2021-08-18 20:07:05,082] {scheduler_job.py:182} INFO - Started process (PID=977) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:05,083] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:07:05,084] {logging_mixin.py:104} INFO - [2021-08-18 20:07:05,084] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:05,299] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:05,312] {logging_mixin.py:104} INFO - [2021-08-18 20:07:05,312] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:07:05,326] {logging_mixin.py:104} INFO - [2021-08-18 20:07:05,326] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:07:05.326504+00:00
[2021-08-18 20:07:05,337] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-08-18 20:07:35,451] {scheduler_job.py:182} INFO - Started process (PID=980) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:35,453] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:07:35,453] {logging_mixin.py:104} INFO - [2021-08-18 20:07:35,453] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:35,665] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:07:35,677] {logging_mixin.py:104} INFO - [2021-08-18 20:07:35,677] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:07:35,692] {logging_mixin.py:104} INFO - [2021-08-18 20:07:35,692] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:07:35.691983+00:00
[2021-08-18 20:07:35,703] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.254 seconds
[2021-08-18 20:08:05,824] {scheduler_job.py:182} INFO - Started process (PID=983) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:05,825] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:08:05,826] {logging_mixin.py:104} INFO - [2021-08-18 20:08:05,825] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:06,038] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:06,052] {logging_mixin.py:104} INFO - [2021-08-18 20:08:06,052] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:08:06,067] {logging_mixin.py:104} INFO - [2021-08-18 20:08:06,067] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:08:06.067496+00:00
[2021-08-18 20:08:06,079] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.258 seconds
[2021-08-18 20:08:36,233] {scheduler_job.py:182} INFO - Started process (PID=986) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:36,235] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:08:36,236] {logging_mixin.py:104} INFO - [2021-08-18 20:08:36,236] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:36,461] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:08:36,472] {logging_mixin.py:104} INFO - [2021-08-18 20:08:36,472] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:08:36,487] {logging_mixin.py:104} INFO - [2021-08-18 20:08:36,486] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:08:36.486837+00:00
[2021-08-18 20:08:36,496] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.267 seconds
[2021-08-18 20:09:06,611] {scheduler_job.py:182} INFO - Started process (PID=989) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:06,612] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:09:06,612] {logging_mixin.py:104} INFO - [2021-08-18 20:09:06,612] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:06,826] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:06,844] {logging_mixin.py:104} INFO - [2021-08-18 20:09:06,844] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:09:06,864] {logging_mixin.py:104} INFO - [2021-08-18 20:09:06,864] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:09:06.864567+00:00
[2021-08-18 20:09:06,878] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.271 seconds
[2021-08-18 20:09:37,010] {scheduler_job.py:182} INFO - Started process (PID=992) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:37,011] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:09:37,012] {logging_mixin.py:104} INFO - [2021-08-18 20:09:37,012] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:37,204] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:09:37,216] {logging_mixin.py:104} INFO - [2021-08-18 20:09:37,216] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:09:37,231] {logging_mixin.py:104} INFO - [2021-08-18 20:09:37,231] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:09:37.231284+00:00
[2021-08-18 20:09:37,242] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.236 seconds
[2021-08-18 20:10:07,366] {scheduler_job.py:182} INFO - Started process (PID=995) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:07,367] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:10:07,368] {logging_mixin.py:104} INFO - [2021-08-18 20:10:07,367] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:07,570] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:07,580] {logging_mixin.py:104} INFO - [2021-08-18 20:10:07,580] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:10:07,593] {logging_mixin.py:104} INFO - [2021-08-18 20:10:07,593] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:10:07.593525+00:00
[2021-08-18 20:10:07,603] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.241 seconds
[2021-08-18 20:10:37,728] {scheduler_job.py:182} INFO - Started process (PID=998) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:37,729] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:10:37,729] {logging_mixin.py:104} INFO - [2021-08-18 20:10:37,729] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:37,915] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:10:37,926] {logging_mixin.py:104} INFO - [2021-08-18 20:10:37,926] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:10:37,942] {logging_mixin.py:104} INFO - [2021-08-18 20:10:37,941] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:10:37.941835+00:00
[2021-08-18 20:10:37,954] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 20:11:08,077] {scheduler_job.py:182} INFO - Started process (PID=1001) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:08,078] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:11:08,079] {logging_mixin.py:104} INFO - [2021-08-18 20:11:08,079] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:08,264] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:08,274] {logging_mixin.py:104} INFO - [2021-08-18 20:11:08,274] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:11:08,287] {logging_mixin.py:104} INFO - [2021-08-18 20:11:08,287] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:11:08.287604+00:00
[2021-08-18 20:11:08,298] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.224 seconds
[2021-08-18 20:11:38,426] {scheduler_job.py:182} INFO - Started process (PID=1004) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:38,427] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:11:38,427] {logging_mixin.py:104} INFO - [2021-08-18 20:11:38,427] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:38,622] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:11:38,633] {logging_mixin.py:104} INFO - [2021-08-18 20:11:38,633] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:11:38,647] {logging_mixin.py:104} INFO - [2021-08-18 20:11:38,647] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:11:38.646892+00:00
[2021-08-18 20:11:38,657] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.234 seconds
[2021-08-18 20:12:08,777] {scheduler_job.py:182} INFO - Started process (PID=1007) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:08,778] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:12:08,779] {logging_mixin.py:104} INFO - [2021-08-18 20:12:08,778] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:08,964] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:08,974] {logging_mixin.py:104} INFO - [2021-08-18 20:12:08,974] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:12:08,988] {logging_mixin.py:104} INFO - [2021-08-18 20:12:08,988] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:12:08.988321+00:00
[2021-08-18 20:12:08,998] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.225 seconds
[2021-08-18 20:12:39,120] {scheduler_job.py:182} INFO - Started process (PID=1010) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:39,121] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:12:39,122] {logging_mixin.py:104} INFO - [2021-08-18 20:12:39,122] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:39,306] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:12:39,317] {logging_mixin.py:104} INFO - [2021-08-18 20:12:39,317] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:12:39,330] {logging_mixin.py:104} INFO - [2021-08-18 20:12:39,330] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:12:39.330190+00:00
[2021-08-18 20:12:39,340] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 20:13:09,456] {scheduler_job.py:182} INFO - Started process (PID=1013) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:09,458] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:13:09,458] {logging_mixin.py:104} INFO - [2021-08-18 20:13:09,458] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:09,643] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:09,653] {logging_mixin.py:104} INFO - [2021-08-18 20:13:09,653] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:13:09,666] {logging_mixin.py:104} INFO - [2021-08-18 20:13:09,666] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:13:09.666745+00:00
[2021-08-18 20:13:09,677] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.224 seconds
[2021-08-18 20:13:39,827] {scheduler_job.py:182} INFO - Started process (PID=1016) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:39,828] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:13:39,828] {logging_mixin.py:104} INFO - [2021-08-18 20:13:39,828] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:40,015] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:13:40,026] {logging_mixin.py:104} INFO - [2021-08-18 20:13:40,026] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:13:40,039] {logging_mixin.py:104} INFO - [2021-08-18 20:13:40,039] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:13:40.039203+00:00
[2021-08-18 20:13:40,049] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-08-18 20:14:10,168] {scheduler_job.py:182} INFO - Started process (PID=1019) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:10,169] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:14:10,170] {logging_mixin.py:104} INFO - [2021-08-18 20:14:10,170] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:10,354] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:10,365] {logging_mixin.py:104} INFO - [2021-08-18 20:14:10,365] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:14:10,378] {logging_mixin.py:104} INFO - [2021-08-18 20:14:10,378] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:14:10.377904+00:00
[2021-08-18 20:14:10,388] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 20:14:40,517] {scheduler_job.py:182} INFO - Started process (PID=1022) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:40,519] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:14:40,519] {logging_mixin.py:104} INFO - [2021-08-18 20:14:40,519] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:40,701] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:14:40,712] {logging_mixin.py:104} INFO - [2021-08-18 20:14:40,712] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:14:40,725] {logging_mixin.py:104} INFO - [2021-08-18 20:14:40,725] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:14:40.725073+00:00
[2021-08-18 20:14:40,735] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.221 seconds
[2021-08-18 20:15:10,858] {scheduler_job.py:182} INFO - Started process (PID=1025) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:10,859] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:15:10,860] {logging_mixin.py:104} INFO - [2021-08-18 20:15:10,859] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:11,045] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:11,056] {logging_mixin.py:104} INFO - [2021-08-18 20:15:11,055] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:15:11,069] {logging_mixin.py:104} INFO - [2021-08-18 20:15:11,069] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:15:11.069523+00:00
[2021-08-18 20:15:11,080] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-08-18 20:15:41,207] {scheduler_job.py:182} INFO - Started process (PID=1028) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:41,208] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:15:41,209] {logging_mixin.py:104} INFO - [2021-08-18 20:15:41,208] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:41,410] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:15:41,422] {logging_mixin.py:104} INFO - [2021-08-18 20:15:41,422] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:15:41,439] {logging_mixin.py:104} INFO - [2021-08-18 20:15:41,439] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:15:41.439270+00:00
[2021-08-18 20:15:41,455] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.251 seconds
[2021-08-18 20:16:11,590] {scheduler_job.py:182} INFO - Started process (PID=1031) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:11,592] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:16:11,592] {logging_mixin.py:104} INFO - [2021-08-18 20:16:11,592] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:11,775] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:11,786] {logging_mixin.py:104} INFO - [2021-08-18 20:16:11,786] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:16:11,799] {logging_mixin.py:104} INFO - [2021-08-18 20:16:11,799] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:16:11.799093+00:00
[2021-08-18 20:16:11,809] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.221 seconds
[2021-08-18 20:16:41,936] {scheduler_job.py:182} INFO - Started process (PID=1034) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:41,937] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:16:41,938] {logging_mixin.py:104} INFO - [2021-08-18 20:16:41,937] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:42,122] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:16:42,133] {logging_mixin.py:104} INFO - [2021-08-18 20:16:42,133] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:16:42,146] {logging_mixin.py:104} INFO - [2021-08-18 20:16:42,145] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:16:42.145791+00:00
[2021-08-18 20:16:42,156] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 20:17:12,283] {scheduler_job.py:182} INFO - Started process (PID=1037) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:12,284] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:17:12,285] {logging_mixin.py:104} INFO - [2021-08-18 20:17:12,285] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:12,470] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:12,481] {logging_mixin.py:104} INFO - [2021-08-18 20:17:12,481] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:17:12,494] {logging_mixin.py:104} INFO - [2021-08-18 20:17:12,494] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:17:12.494328+00:00
[2021-08-18 20:17:12,504] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.224 seconds
[2021-08-18 20:17:42,630] {scheduler_job.py:182} INFO - Started process (PID=1040) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:42,632] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:17:42,632] {logging_mixin.py:104} INFO - [2021-08-18 20:17:42,632] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:42,816] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:17:42,826] {logging_mixin.py:104} INFO - [2021-08-18 20:17:42,826] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:17:42,841] {logging_mixin.py:104} INFO - [2021-08-18 20:17:42,841] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:17:42.840869+00:00
[2021-08-18 20:17:42,851] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 20:18:12,982] {scheduler_job.py:182} INFO - Started process (PID=1043) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:12,983] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:18:12,984] {logging_mixin.py:104} INFO - [2021-08-18 20:18:12,984] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:13,167] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:13,177] {logging_mixin.py:104} INFO - [2021-08-18 20:18:13,177] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:18:13,191] {logging_mixin.py:104} INFO - [2021-08-18 20:18:13,191] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:18:13.191035+00:00
[2021-08-18 20:18:13,201] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.222 seconds
[2021-08-18 20:18:43,347] {scheduler_job.py:182} INFO - Started process (PID=1046) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:43,348] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:18:43,349] {logging_mixin.py:104} INFO - [2021-08-18 20:18:43,349] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:43,534] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:18:43,544] {logging_mixin.py:104} INFO - [2021-08-18 20:18:43,544] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:18:43,558] {logging_mixin.py:104} INFO - [2021-08-18 20:18:43,557] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:18:43.557722+00:00
[2021-08-18 20:18:43,567] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.223 seconds
[2021-08-18 20:19:13,700] {scheduler_job.py:182} INFO - Started process (PID=1049) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:13,701] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:19:13,702] {logging_mixin.py:104} INFO - [2021-08-18 20:19:13,702] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:13,888] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:13,898] {logging_mixin.py:104} INFO - [2021-08-18 20:19:13,898] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:19:13,911] {logging_mixin.py:104} INFO - [2021-08-18 20:19:13,911] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:19:13.911335+00:00
[2021-08-18 20:19:13,923] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.227 seconds
[2021-08-18 20:19:44,050] {scheduler_job.py:182} INFO - Started process (PID=1052) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:44,051] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:19:44,052] {logging_mixin.py:104} INFO - [2021-08-18 20:19:44,052] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:44,236] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:19:44,247] {logging_mixin.py:104} INFO - [2021-08-18 20:19:44,246] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:19:44,261] {logging_mixin.py:104} INFO - [2021-08-18 20:19:44,261] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:19:44.261060+00:00
[2021-08-18 20:19:44,274] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-08-18 20:20:14,407] {scheduler_job.py:182} INFO - Started process (PID=1055) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:14,408] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:20:14,408] {logging_mixin.py:104} INFO - [2021-08-18 20:20:14,408] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:14,594] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:14,606] {logging_mixin.py:104} INFO - [2021-08-18 20:20:14,606] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:20:14,621] {logging_mixin.py:104} INFO - [2021-08-18 20:20:14,621] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:20:14.621150+00:00
[2021-08-18 20:20:14,638] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.234 seconds
[2021-08-18 20:20:44,759] {scheduler_job.py:182} INFO - Started process (PID=1058) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:44,760] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:20:44,761] {logging_mixin.py:104} INFO - [2021-08-18 20:20:44,761] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:44,950] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:20:44,961] {logging_mixin.py:104} INFO - [2021-08-18 20:20:44,961] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:20:44,974] {logging_mixin.py:104} INFO - [2021-08-18 20:20:44,974] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:20:44.974289+00:00
[2021-08-18 20:20:44,985] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 20:21:15,103] {scheduler_job.py:182} INFO - Started process (PID=1061) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:15,104] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:21:15,105] {logging_mixin.py:104} INFO - [2021-08-18 20:21:15,105] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:15,295] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:15,305] {logging_mixin.py:104} INFO - [2021-08-18 20:21:15,305] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:21:15,320] {logging_mixin.py:104} INFO - [2021-08-18 20:21:15,320] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:21:15.320467+00:00
[2021-08-18 20:21:15,330] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 20:21:45,451] {scheduler_job.py:182} INFO - Started process (PID=1064) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:45,452] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:21:45,452] {logging_mixin.py:104} INFO - [2021-08-18 20:21:45,452] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:45,645] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:21:45,655] {logging_mixin.py:104} INFO - [2021-08-18 20:21:45,655] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:21:45,669] {logging_mixin.py:104} INFO - [2021-08-18 20:21:45,669] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:21:45.669616+00:00
[2021-08-18 20:21:45,679] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 20:22:15,801] {scheduler_job.py:182} INFO - Started process (PID=1067) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:15,803] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:22:15,803] {logging_mixin.py:104} INFO - [2021-08-18 20:22:15,803] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:16,032] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:16,044] {logging_mixin.py:104} INFO - [2021-08-18 20:22:16,044] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:22:16,058] {logging_mixin.py:104} INFO - [2021-08-18 20:22:16,058] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:22:16.058344+00:00
[2021-08-18 20:22:16,066] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.268 seconds
[2021-08-18 20:22:46,194] {scheduler_job.py:182} INFO - Started process (PID=1070) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:46,195] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:22:46,196] {logging_mixin.py:104} INFO - [2021-08-18 20:22:46,195] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:46,387] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:22:46,397] {logging_mixin.py:104} INFO - [2021-08-18 20:22:46,397] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:22:46,411] {logging_mixin.py:104} INFO - [2021-08-18 20:22:46,411] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:22:46.411736+00:00
[2021-08-18 20:22:46,422] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 20:23:16,542] {scheduler_job.py:182} INFO - Started process (PID=1073) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:16,543] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:23:16,544] {logging_mixin.py:104} INFO - [2021-08-18 20:23:16,543] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:16,734] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:16,745] {logging_mixin.py:104} INFO - [2021-08-18 20:23:16,744] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:23:16,758] {logging_mixin.py:104} INFO - [2021-08-18 20:23:16,758] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:23:16.758557+00:00
[2021-08-18 20:23:16,769] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 20:23:46,910] {scheduler_job.py:182} INFO - Started process (PID=1076) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:46,911] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:23:46,912] {logging_mixin.py:104} INFO - [2021-08-18 20:23:46,912] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:47,106] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:23:47,118] {logging_mixin.py:104} INFO - [2021-08-18 20:23:47,118] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:23:47,132] {logging_mixin.py:104} INFO - [2021-08-18 20:23:47,132] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:23:47.131936+00:00
[2021-08-18 20:23:47,141] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.235 seconds
[2021-08-18 20:24:17,266] {scheduler_job.py:182} INFO - Started process (PID=1079) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:17,267] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:24:17,268] {logging_mixin.py:104} INFO - [2021-08-18 20:24:17,268] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:17,456] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:17,468] {logging_mixin.py:104} INFO - [2021-08-18 20:24:17,467] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:24:17,481] {logging_mixin.py:104} INFO - [2021-08-18 20:24:17,481] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:24:17.481379+00:00
[2021-08-18 20:24:17,492] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-08-18 20:24:47,618] {scheduler_job.py:182} INFO - Started process (PID=1082) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:47,619] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:24:47,620] {logging_mixin.py:104} INFO - [2021-08-18 20:24:47,620] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:47,811] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:24:47,823] {logging_mixin.py:104} INFO - [2021-08-18 20:24:47,823] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:24:47,837] {logging_mixin.py:104} INFO - [2021-08-18 20:24:47,836] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:24:47.836750+00:00
[2021-08-18 20:24:47,846] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.231 seconds
[2021-08-18 20:25:17,972] {scheduler_job.py:182} INFO - Started process (PID=1085) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:17,973] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:25:17,974] {logging_mixin.py:104} INFO - [2021-08-18 20:25:17,974] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:18,166] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:18,178] {logging_mixin.py:104} INFO - [2021-08-18 20:25:18,178] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:25:18,191] {logging_mixin.py:104} INFO - [2021-08-18 20:25:18,191] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:25:18.191201+00:00
[2021-08-18 20:25:18,202] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.233 seconds
[2021-08-18 20:25:48,322] {scheduler_job.py:182} INFO - Started process (PID=1088) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:48,323] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:25:48,324] {logging_mixin.py:104} INFO - [2021-08-18 20:25:48,324] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:48,512] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:25:48,524] {logging_mixin.py:104} INFO - [2021-08-18 20:25:48,524] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:25:48,538] {logging_mixin.py:104} INFO - [2021-08-18 20:25:48,537] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:25:48.537854+00:00
[2021-08-18 20:25:48,548] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 20:26:18,673] {scheduler_job.py:182} INFO - Started process (PID=1091) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:18,674] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:26:18,675] {logging_mixin.py:104} INFO - [2021-08-18 20:26:18,675] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:18,870] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:18,881] {logging_mixin.py:104} INFO - [2021-08-18 20:26:18,881] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:26:18,895] {logging_mixin.py:104} INFO - [2021-08-18 20:26:18,895] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:26:18.894925+00:00
[2021-08-18 20:26:18,905] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.235 seconds
[2021-08-18 20:26:49,025] {scheduler_job.py:182} INFO - Started process (PID=1094) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:49,026] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:26:49,027] {logging_mixin.py:104} INFO - [2021-08-18 20:26:49,027] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:49,220] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:26:49,231] {logging_mixin.py:104} INFO - [2021-08-18 20:26:49,230] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:26:49,244] {logging_mixin.py:104} INFO - [2021-08-18 20:26:49,244] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:26:49.244185+00:00
[2021-08-18 20:26:49,255] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 20:27:19,375] {scheduler_job.py:182} INFO - Started process (PID=1097) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:19,377] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:27:19,377] {logging_mixin.py:104} INFO - [2021-08-18 20:27:19,377] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:19,571] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:19,581] {logging_mixin.py:104} INFO - [2021-08-18 20:27:19,581] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:27:19,594] {logging_mixin.py:104} INFO - [2021-08-18 20:27:19,594] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:27:19.594607+00:00
[2021-08-18 20:27:19,605] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.232 seconds
[2021-08-18 20:27:49,725] {scheduler_job.py:182} INFO - Started process (PID=1100) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:49,727] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:27:49,727] {logging_mixin.py:104} INFO - [2021-08-18 20:27:49,727] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:49,920] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:27:49,931] {logging_mixin.py:104} INFO - [2021-08-18 20:27:49,931] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:27:49,945] {logging_mixin.py:104} INFO - [2021-08-18 20:27:49,945] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:27:49.944883+00:00
[2021-08-18 20:27:49,955] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.233 seconds
[2021-08-18 20:28:20,081] {scheduler_job.py:182} INFO - Started process (PID=1103) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:20,082] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:28:20,083] {logging_mixin.py:104} INFO - [2021-08-18 20:28:20,082] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:20,271] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:20,282] {logging_mixin.py:104} INFO - [2021-08-18 20:28:20,282] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:28:20,295] {logging_mixin.py:104} INFO - [2021-08-18 20:28:20,295] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:28:20.295253+00:00
[2021-08-18 20:28:20,305] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.229 seconds
[2021-08-18 20:28:50,454] {scheduler_job.py:182} INFO - Started process (PID=1106) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:50,455] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:28:50,456] {logging_mixin.py:104} INFO - [2021-08-18 20:28:50,455] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:50,642] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:28:50,653] {logging_mixin.py:104} INFO - [2021-08-18 20:28:50,652] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:28:50,666] {logging_mixin.py:104} INFO - [2021-08-18 20:28:50,666] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:28:50.666180+00:00
[2021-08-18 20:28:50,676] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-08-18 20:29:20,799] {scheduler_job.py:182} INFO - Started process (PID=1109) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:20,800] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:29:20,800] {logging_mixin.py:104} INFO - [2021-08-18 20:29:20,800] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:20,991] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:21,002] {logging_mixin.py:104} INFO - [2021-08-18 20:29:21,002] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:29:21,015] {logging_mixin.py:104} INFO - [2021-08-18 20:29:21,015] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:29:21.015160+00:00
[2021-08-18 20:29:21,026] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.230 seconds
[2021-08-18 20:29:51,145] {scheduler_job.py:182} INFO - Started process (PID=1112) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:51,146] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:29:51,147] {logging_mixin.py:104} INFO - [2021-08-18 20:29:51,147] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:51,333] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:29:51,344] {logging_mixin.py:104} INFO - [2021-08-18 20:29:51,344] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:29:51,357] {logging_mixin.py:104} INFO - [2021-08-18 20:29:51,357] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:29:51.357313+00:00
[2021-08-18 20:29:51,368] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.226 seconds
[2021-08-18 20:30:21,488] {scheduler_job.py:182} INFO - Started process (PID=1115) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:30:21,489] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:30:21,489] {logging_mixin.py:104} INFO - [2021-08-18 20:30:21,489] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:30:21,678] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:30:21,688] {logging_mixin.py:104} INFO - [2021-08-18 20:30:21,688] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:30:21,702] {logging_mixin.py:104} INFO - [2021-08-18 20:30:21,702] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:30:21.702051+00:00
[2021-08-18 20:30:21,712] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.228 seconds
[2021-08-18 20:44:21,850] {scheduler_job.py:182} INFO - Started process (PID=1118) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:21,852] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:44:21,854] {logging_mixin.py:104} INFO - [2021-08-18 20:44:21,853] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:22,272] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:22,313] {logging_mixin.py:104} INFO - [2021-08-18 20:44:22,313] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:44:22,350] {logging_mixin.py:104} INFO - [2021-08-18 20:44:22,349] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:44:22.349376+00:00
[2021-08-18 20:44:22,372] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.527 seconds
[2021-08-18 20:44:52,513] {scheduler_job.py:182} INFO - Started process (PID=1121) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:52,516] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:44:52,517] {logging_mixin.py:104} INFO - [2021-08-18 20:44:52,517] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:52,918] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:44:52,936] {logging_mixin.py:104} INFO - [2021-08-18 20:44:52,936] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:44:52,960] {logging_mixin.py:104} INFO - [2021-08-18 20:44:52,959] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:44:52.959568+00:00
[2021-08-18 20:44:52,979] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.472 seconds
[2021-08-18 20:45:23,109] {scheduler_job.py:182} INFO - Started process (PID=1124) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:23,111] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:45:23,113] {logging_mixin.py:104} INFO - [2021-08-18 20:45:23,113] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:23,602] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:23,623] {logging_mixin.py:104} INFO - [2021-08-18 20:45:23,623] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:45:23,648] {logging_mixin.py:104} INFO - [2021-08-18 20:45:23,648] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:45:23.648442+00:00
[2021-08-18 20:45:23,666] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.562 seconds
[2021-08-18 20:45:53,786] {scheduler_job.py:182} INFO - Started process (PID=1127) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:53,788] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:45:53,789] {logging_mixin.py:104} INFO - [2021-08-18 20:45:53,789] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:54,129] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:45:54,147] {logging_mixin.py:104} INFO - [2021-08-18 20:45:54,147] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:45:54,171] {logging_mixin.py:104} INFO - [2021-08-18 20:45:54,171] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:45:54.171010+00:00
[2021-08-18 20:45:54,190] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.407 seconds
[2021-08-18 20:46:24,313] {scheduler_job.py:182} INFO - Started process (PID=1130) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:24,315] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:46:24,316] {logging_mixin.py:104} INFO - [2021-08-18 20:46:24,316] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:24,705] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:24,721] {logging_mixin.py:104} INFO - [2021-08-18 20:46:24,721] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:46:24,745] {logging_mixin.py:104} INFO - [2021-08-18 20:46:24,745] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:46:24.745067+00:00
[2021-08-18 20:46:24,764] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.456 seconds
[2021-08-18 20:46:54,873] {scheduler_job.py:182} INFO - Started process (PID=1133) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:54,875] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:46:54,876] {logging_mixin.py:104} INFO - [2021-08-18 20:46:54,875] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:55,198] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:46:55,215] {logging_mixin.py:104} INFO - [2021-08-18 20:46:55,215] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:46:55,232] {logging_mixin.py:104} INFO - [2021-08-18 20:46:55,232] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:46:55.232072+00:00
[2021-08-18 20:46:55,244] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.375 seconds
[2021-08-18 20:47:25,372] {scheduler_job.py:182} INFO - Started process (PID=1136) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:25,374] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:47:25,375] {logging_mixin.py:104} INFO - [2021-08-18 20:47:25,375] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:25,713] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:25,727] {logging_mixin.py:104} INFO - [2021-08-18 20:47:25,727] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:47:25,745] {logging_mixin.py:104} INFO - [2021-08-18 20:47:25,744] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:47:25.744669+00:00
[2021-08-18 20:47:25,755] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.387 seconds
[2021-08-18 20:47:55,891] {scheduler_job.py:182} INFO - Started process (PID=1139) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:55,893] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:47:55,894] {logging_mixin.py:104} INFO - [2021-08-18 20:47:55,894] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:57,019] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:47:57,158] {logging_mixin.py:104} INFO - [2021-08-18 20:47:57,154] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:47:57,290] {logging_mixin.py:104} INFO - [2021-08-18 20:47:57,287] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:47:57.287190+00:00
[2021-08-18 20:47:57,393] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 1.507 seconds
[2021-08-18 20:48:27,646] {scheduler_job.py:182} INFO - Started process (PID=1143) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:48:27,648] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:48:27,649] {logging_mixin.py:104} INFO - [2021-08-18 20:48:27,649] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:48:28,604] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:48:28,756] {logging_mixin.py:104} INFO - [2021-08-18 20:48:28,743] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:48:28,890] {logging_mixin.py:104} INFO - [2021-08-18 20:48:28,876] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:48:28.876615+00:00
[2021-08-18 20:48:29,326] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 1.683 seconds
[2021-08-18 20:48:59,896] {scheduler_job.py:182} INFO - Started process (PID=1146) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:48:59,898] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:48:59,899] {logging_mixin.py:104} INFO - [2021-08-18 20:48:59,899] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:49:00,435] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:49:00,468] {logging_mixin.py:104} INFO - [2021-08-18 20:49:00,468] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:49:00,507] {logging_mixin.py:104} INFO - [2021-08-18 20:49:00,507] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:49:00.506907+00:00
[2021-08-18 20:49:00,543] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 0.654 seconds
[2021-08-18 20:49:30,745] {scheduler_job.py:182} INFO - Started process (PID=1149) to work on /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:49:30,749] {scheduler_job.py:629} INFO - Processing file /opt/airflow/dags/pipeline_spark.py for tasks to queue
[2021-08-18 20:49:30,753] {logging_mixin.py:104} INFO - [2021-08-18 20:49:30,753] {dagbag.py:451} INFO - Filling up the DagBag from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:49:33,548] {scheduler_job.py:639} INFO - DAG(s) dict_keys(['Pipeline_Spark_Orchestrator']) retrieved from /opt/airflow/dags/pipeline_spark.py
[2021-08-18 20:49:33,596] {logging_mixin.py:104} INFO - [2021-08-18 20:49:33,595] {dag.py:1824} INFO - Sync 1 DAGs
[2021-08-18 20:49:33,643] {logging_mixin.py:104} INFO - [2021-08-18 20:49:33,642] {dag.py:2280} INFO - Setting next_dagrun for Pipeline_Spark_Orchestrator to 2021-08-17 20:49:33.642554+00:00
[2021-08-18 20:49:33,675] {scheduler_job.py:190} INFO - Processing /opt/airflow/dags/pipeline_spark.py took 2.952 seconds
