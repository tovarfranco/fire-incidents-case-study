AWSTemplateFormatVersion: "2010-09-09"

Transform: AWS::Serverless-2016-10-31

Parameters:
  Stage:
    Type: String
    AllowedValues:
      - dev
      - uat
      - prod
    Default: dev
    Description: "Suffix to add to the Bucket Prefixes. Can correspond dev, stage, or prod."
  ProjectName:
    Type: String
    Default: "fire-incidents"
    Description: "Project name for tagging resources"
  WheelName:
    Type: String
    Default: "fire_incidents"
    Description: "Project name for tagging resources"
  Version:
    Type: String
    Default: "1"
    Description: "Version number to separate paths in S3"
  RawDatabase:
    Type: String
    Default: "incidents_raw"
    Description: "Database for raw data"
  RefinedDatabase:
    Type: String
    Default: "incidents_refined"
    Description: "Database for refined data"
  BucketNameConfig:
    Type: String
    Default: "fire-incidents-config-dev"
    Description: "S3 bucket config"
  BucketNameRaw:
    Type: String
    Default: "fire-incidents-raw-dev"
    Description: "S3 bucket raw"
  BucketNameRefined:
    Type: String
    Default: "fire-incidents-refined-dev"
    Description: "S3 bucket refined"

Description: >
  fire-incidents Demo

Globals:
  Function:
    Runtime: python3.7
    MemorySize: 4096
    Timeout: 900

Resources:
  PipelineRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub ${ProjectName}-role-${Stage}
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service:
                - "glue.amazonaws.com"
                - "lambda.amazonaws.com"
                - "redshift.amazonaws.com"
                - "athena.amazonaws.com"
                - !Sub states.${AWS::Region}.amazonaws.com
            Action:
              - "sts:AssumeRole"
      Tags:
        - Key: "project"
          Value: !Ref ProjectName       
        - Key: "version"
          Value: !Ref Version
        - Key: "stage"
          Value: !Ref Stage

  PipelineAccessPolicy:
    Type: AWS::IAM::Policy
    Properties:
      Roles:
        - !Ref PipelineRole
      PolicyName: !Sub ${ProjectName}-policy-${Stage}
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action: "s3:*"
            Resource:
              - !Sub "arn:aws:s3:::${BucketNameConfig}"
              - !Sub "arn:aws:s3:::${BucketNameConfig}/*"
              - !Sub "arn:aws:s3:::${BucketNameRaw}"
              - !Sub "arn:aws:s3:::${BucketNameRaw}/*"
              - !Sub "arn:aws:s3:::${BucketNameRefined}"
              - !Sub "arn:aws:s3:::${BucketNameRefined}/*"
          - Effect: "Allow"
            Action:
              - "lambda:InvokeFunction"
              - "logs:*"
              - "glue:StartJobRun"
              - "glue:GetJobRun"
              - "glue:GetJobRuns"
              - "glue:BatchStopJobRun"
              - "states:StartExecution"
              - "athena:getQueryResults"
              - "athena:startQueryExecution"
              - "athena:getQueryExecution"
            Resource: "*"

  # Glue Job
  PipelineRawRefined:
    Type: AWS::Glue::Job
    Properties:
      Connections:
        Connections:
          - "redshift-connection"
      Name: !Sub ${ProjectName}-raw-refined-${Stage}
      ExecutionProperty:
        MaxConcurrentRuns: 3
      WorkerType: G.1X
      NumberOfWorkers: 3
      GlueVersion: "3.0"
      Timeout: 2880
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: "src/raw_refined.py"
      DefaultArguments:
        "--extra-py-files": !Sub "s3://${BucketNameConfig}/lib/${WheelName}-1.0-py3-none-any.whl"
        "--enable-metrics": ""
        "--enable-spark-ui": "true"
        "--spark-event-logs-path": !Sub "s3://${BucketNameConfig}/logs/spark"
        "--enable-s3-parquet-optimized-committer": "true"
        "--user-jars-first": "true"
        "--enable-glue-datacatalog": ""
      Description: "Template Spark job"
      Role: !GetAtt PipelineRole.Arn
      Tags:
        version: !Ref Version
        stage: !Ref Stage
        project: !Ref ProjectName

  PipelineRefinedStg:
    Type: AWS::Glue::Job
    Properties:
      Connections:
        Connections:
          - "redshift-connection"
      Name: !Sub ${ProjectName}-refined-stg-${Stage}
      ExecutionProperty:
        MaxConcurrentRuns: 3
      WorkerType: G.1X
      NumberOfWorkers: 3
      GlueVersion: "3.0"
      Timeout: 2880
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: "src/refined_stg.py"
      DefaultArguments:
        "--extra-py-files": !Sub "s3://${BucketNameConfig}/lib/${WheelName}-1.0-py3-none-any.whl"
        "--enable-metrics": ""
        "--enable-spark-ui": "true"
        "--spark-event-logs-path": !Sub "s3://${BucketNameConfig}/logs/spark"
        "--enable-s3-parquet-optimized-committer": "true"
        "--user-jars-first": "true"
        "--enable-glue-datacatalog": ""
      Description: "Template Spark job"
      Role: !GetAtt PipelineRole.Arn
      Tags:
        version: !Ref Version
        stage: !Ref Stage
        project: !Ref ProjectName
  
  PipelineStgDwh:
    Type: AWS::Glue::Job
    Properties:
      Connections:
        Connections:
          - "redshift-connection"
      Name: !Sub ${ProjectName}-stg-dwh-${Stage}
      ExecutionProperty:
        MaxConcurrentRuns: 3
      WorkerType: G.1X
      NumberOfWorkers: 3
      GlueVersion: "3.0"
      Timeout: 2880
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: "src/stg_dwh.py"
      DefaultArguments:
        "--extra-py-files": !Sub "s3://${BucketNameConfig}/lib/${WheelName}-1.0-py3-none-any.whl"
        "--enable-metrics": ""
        "--enable-spark-ui": "true"
        "--spark-event-logs-path": !Sub "s3://${BucketNameConfig}/logs/spark"
        "--enable-s3-parquet-optimized-committer": "true"
        "--user-jars-first": "true"
        "--enable-glue-datacatalog": ""
      Description: "Template Spark job"
      Role: !GetAtt PipelineRole.Arn
      Tags:
        version: !Ref Version
        stage: !Ref Stage
        project: !Ref ProjectName

  PipelineDimDate:
    Type: AWS::Glue::Job
    Properties:
      Connections:
        Connections:
          - "redshift-connection"
      Name: !Sub ${ProjectName}-dim-date-${Stage}
      ExecutionProperty:
        MaxConcurrentRuns: 3
      WorkerType: G.1X
      NumberOfWorkers: 3
      GlueVersion: "3.0"
      Timeout: 2880
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: "src/dim_date.py"
      DefaultArguments:
        "--extra-py-files": !Sub "s3://${BucketNameConfig}/lib/${WheelName}-1.0-py3-none-any.whl"
        "--enable-metrics": ""
        "--enable-spark-ui": "true"
        "--spark-event-logs-path": !Sub "s3://${BucketNameConfig}/logs/spark"
        "--enable-s3-parquet-optimized-committer": "true"
        "--user-jars-first": "true"
        "--enable-glue-datacatalog": ""
      Description: "Template Spark job"
      Role: !GetAtt PipelineRole.Arn
      Tags:
        version: !Ref Version
        stage: !Ref Stage
        project: !Ref ProjectName
  
  GlueAnalyticsDatabaseRaw:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Sub "${RawDatabase}_${Stage}"
        Description: !Sub "${ProjectName} Raw Database"
  
  GlueAnalyticsDatabaseRefined:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Sub "${RefinedDatabase}_${Stage}"
        Description: !Sub "${ProjectName} Refined Database"

  GlueAnalyticsCrawlerRaw:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub "${ProjectName}_raw_crawler_${Stage}"
      Role: !GetAtt PipelineRole.Arn
      DatabaseName: !Ref GlueAnalyticsDatabaseRaw
      Targets:
        S3Targets:
          - Path: !Sub "s3://${BucketNameRaw}/fire_incidents"
      SchemaChangePolicy:
        UpdateBehavior: "UPDATE_IN_DATABASE"
        DeleteBehavior: "LOG"

  GlueAnalyticsCrawlerRefined:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub "${ProjectName}_refined_crawler_${Stage}"
      Role: !GetAtt PipelineRole.Arn
      DatabaseName: !Ref GlueAnalyticsDatabaseRefined
      Targets:
        S3Targets:
          - Path: !Sub "s3://${BucketNameRefined}/fire_incidents"
      SchemaChangePolicy:
        UpdateBehavior: "UPDATE_IN_DATABASE"
        DeleteBehavior: "LOG"


  #State Machine
  PipelineStepFunction:
    Type: AWS::Serverless::StateMachine
    Properties:
      Role: !GetAtt PipelineRole.Arn
      Name: !Sub ${ProjectName}-orchestrator-${Stage}
      DefinitionUri: src/state_machine/definition.asl.json
      DefinitionSubstitutions:
        RawRefined: !Sub ${ProjectName}-raw-refined-${Stage}
        RefinedStg: !Sub ${ProjectName}-refined-stg-${Stage}
        StgDwh: !Sub ${ProjectName}-stg-dwh-${Stage}